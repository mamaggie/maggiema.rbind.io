[{"authors":["maggie"],"categories":null,"content":"I am graduating from the University of Toronto this April with two majors in Statistics and Human Geography, and a minor in Geographic Information System (GIS).\nMy research interests lie at the intersection of spatial statistics and data viz/human-computer interaction (HCI). My previous professional and academic experience mostly involved predictive Bayesian modeling, spatial analysis (GIS \u0026amp; INLA in R), interactive map design, and Engineering consulting. My career goal is to leverage spatial data and visualization design principles to generate data-driven insights and solutions which deliver tangible social impact and drive businesses decisions.\n  Download my resum√©.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8f4371ba27c66bb24bcee9628a4905fe","permalink":"https://maggie-98.github.io/authors/maggie/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/maggie/","section":"authors","summary":"I am graduating from the University of Toronto this April with two majors in Statistics and Human Geography, and a minor in Geographic Information System (GIS).\nMy research interests lie at the intersection of spatial statistics and data viz/human-computer interaction (HCI).","tags":null,"title":"Maggie Ma","type":"authors"},{"authors":null,"categories":["workshop"],"content":"‚ÄúYou should have a website!‚Äù You may have heard this one before, or even said it yourself. In this workshop, you‚Äôll learn how to build and customize a website from the comfort of the RStudio IDE using the blogdown package. We‚Äôll also cover basic website care and feeding like using R Markdown to create content, and how to use GitHub and Netlify to improve your workflow. Pre-work will be shared with participants ahead of time, but to get the most out of this workshop, you‚Äôll want to have a GitHub account and be able to push and pull files from a GitHub repository using your local RStudio IDE.\nThe goal of this workshop is to equip participants with tools that amplify their own contributions, build a more visible presence in the R/data community, and share their knowledge and insights with others.\n","date":1611579600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560676801,"objectID":"f58f46cdb61f47d280f8d484fd0b1ba8","permalink":"https://maggie-98.github.io/talk/2021-rstudio-global/","publishdate":"2020-02-01T00:00:00Z","relpermalink":"/talk/2021-rstudio-global/","section":"talk","summary":"A special workshop for rstudio::global() diversity scholars","tags":["rmarkdown","blogdown"],"title":"Introduce yourself online","type":"talk"},{"authors":["alison"],"categories":["hugo","blogdown","netlify","rmarkdown"],"content":" Welcome    Hi! Hello! Welcome. Bienvenidos.\nAbout 3.5 years ago, I wrote my first blog post and published it on my first website. Since then, that single post has been viewed over 27,557 times. That may not seem like a lot to some folks, but it is to me! Even more meaningful to me, though, has been watching the launches of so many people\u0026rsquo;s personal websites.\nHowever, the process of creating and maintaining a Hugo website using blogdown was not always pain-free. Sometimes we have Hugo \u0026ldquo;improvements\u0026rdquo; to thank, other times your Hugo theme is at fault, and sometimes we could blame blogdown. Regardless of where the pain came from, there was definitely room for improvement.\nHere are some great blog posts that document pretty common user experiences and frustrations:\n   Ma√´lle Salmon\u0026rsquo;s post: What to know before you adopt Hugo/blogdown\n   Athanasia Mowinckel\u0026rsquo;s post: Changing your blogdown workflow\n   Claus Wilke\u0026rsquo;s post: Writing a blogdown post for the ages\n  All of this, combined with my own experiences teaching and using blogdown for over 3.5 years led me to\u0026hellip;my giant blogdown wishlist. I had a lot of ideas to help beginners get started, but just as important, to improve the quality of life for existing users. You can see my mega-wishlist that Yihui Xie (the blogdown conceptor and author) asked me to share with him: https://github.com/rstudio/blogdown/issues/476\nI\u0026rsquo;m very happy to report that our team has been working very hard to address these issues, and many others raised by users, to make blogdown easier to learn and use. Just in time for the new year, we have a new and improved release of the blogdown package for you to test. I know a lot of folks are itching to introduce themselves into online communities and conversations, so I thought it would be fun to take my original blogdown post, and trace the same process of building a Hugo website with the same theme (now named \u0026ldquo;Wowchemy\u0026rdquo; instead of Hugo Academic- don\u0026rsquo;t get me started).\nSo if you are feeling fearless and want to live on the bleeding edge, read on to give the development version of blogdown a spin along with me.\ntl;dr    If you already know what you are doing, this entire post can be condensed into just a few lines of code:\nremotes::install_github(\u0026quot;rstudio/blogdown\u0026quot;) usethis::create_project() blogdown::new_site(theme = \u0026quot;wowchemy/starter-academic\u0026quot;) blogdown::serve_site() blogdown::new_post(title = \u0026quot;Hi Hugo\u0026quot;, ext = '.Rmarkdown', subdir = \u0026quot;post\u0026quot;) usethis::use_git() usethis::use_github() # requires a GitHub PAT  The above sequence is a slightly more advanced workflow than the steps I follow below, but is fairly magical- attempt at your own risk! For everyone else, read on\u0026hellip;\nPre-requisites    Getting any website up and running with all the moving parts (RStudio, GitHub, Hugo, Netlify) can take a few tries. In this post, I\u0026rsquo;m passing along what works for me, and the workflow that I use when I teach Hugo website development. Everyone\u0026rsquo;s mileage may vary, though, depending on your operating system and your approach.\nFor this blog post, I\u0026rsquo;m assuming you have basic familiarity with:\n R, the RStudio IDE, and GitHub.  If that is not you, you will need to work through Happy Git with R by Jenny Bryan et al. first, then come back here when you are ready.\nSince the development version of blogdown is currently only available on GitHub, you may need to setup a GitHub Personal Access Token to install it.\nIn my original 2017 post, I mentioned that at that time, I was a new mom, and just in the process of writing all that up, I filled up my tea mug twice with ice cold water, and filled my water bottle with scalding hot water. This time around isn\u0026rsquo;t too different! Fast forward to 2020: there is a global pandemic, I\u0026rsquo;ve been under stay-at-home orders with a child under 5 years of age at home for months. So buckle up ü§†\n I\u0026rsquo;ve included code chunks below using the rstudioapi package to help you navigate to the right file at the right time. Hugo sites have a dizzying and heavily nested directory structure! You\u0026rsquo;ll need to run install.packages(\u0026quot;rstudioapi\u0026quot;) to use those code chunks, but you can also navigate on your own to the file you need too.   Step 0: Set your intentions    During workshops, I try to set aside some time at the start for folks to set their website intentions. This might feel a bit like navel-gazing, but trust me here. I know you just want to jump in and get started!\nHear me out though, and don\u0026rsquo;t skim or skip this step. The process of actually building and deploying a personal site can be complicated, and it is easy to get lost in the weeds.\nIt is very easy to run out of steam when it is time to do the most fun and important piece: dreaming about the kind of site you want to make!\n Do this right now! Take 10 minutes to set your website intentions\u0026mdash;grab a pen and notepad and a cup of üçµ and read on\u0026hellip;   1. Content    Hugo is made for blogs. But, in addition to a blog, the starter-academic theme provides a unique system of widgets. You can have one or many widgets on pages in your site. I like to think of widgets like Mr. Potato Head where:\n Each page is a potato head, and Each widget is a piece you could place on the potato head.  Take the homepage for example, seen on the Academic demo site. Each band or section you see is a widget. Widgets can be stand-alone pages, or can be combined on a single page.\nExamples:\n Multiple widget page: my resume and about pages Single widget page: my projects   Look at the Academic demo site and write down some widgets you see that you like, and the ones you definitely don\u0026rsquo;t.   2. Menu    Now that you have a sense of the content you want, how do you want a visitor to be able to explore your content? I typically recommend limiting the top navbar to 5 links max (excluding the search icon).\nUse some of my favorite personal sites (that do not use our theme) as inspiration too:\n https://www.jason.af/ https://www.nistara.net https://third-bit.com/ https://maggieappleton.com/ https://www.drcathicks.com/ https://amber.rbind.io/ https://dscott.netlify.app/ https://drmowinckels.io/  Think about how the menu \u0026ldquo;prewires\u0026rdquo; you to know what to expect as you dig deeper into their site. How do you want people to get to know you online?\n Write down up to 5 items to appear in your upper navbar.   3. Homepage    This is the first page a visitor lands on when they find your site. Think of it like a welcome mat. Do you like a single page site where you scroll and see everything on one page? Or do you prefer a short and sweet homepage? Do you want a photo and a bio to be the first thing visitors see? What else?\nHere are some examples of personal websites built with the Hugo Academic theme to inspire you:\n https://malco.io/ https://isabella-b.com/ https://www.connorrothschild.com/ https://silvia.rbind.io/ https://maya.rbind.io/ https://www.allisonhorst.com/ https://juliasilge.com/ https://desiree.rbind.io/   Write down the widgets you want to see on your homepage. It can be one, or many.   OK, keep these notes handy! We are ready to make something.\nStep 1: Create repo      Go online to your GitHub account, and create a new repository (check to initialize with a README but don\u0026rsquo;t add .gitignore- this will be taken care of later). For naming your repo, consider your future deployment plan:\n   Netlify. I recommend using Netlify to both build and host your site. In this case, you can name the repository anything you want!\n   GitHub Pages. I recommend Netlify over GitHub Pages for blogdown/Hugo sites. But, if you want to host your site with GitHub Pages, you should name your repository yourgithubusername.github.io (so mine would have been apreshill.github.io). This post won\u0026rsquo;t be able to help you with publishing.\n     You can see some of the repo names used by members of the rbind organization here.    Go to the main page of your new repository, and under the repository name, click the green Clone or download button.\n  Choose either SSH or HTTPS (if you don\u0026rsquo;t know which, choose HTTPS). Choose by clicking on the clipboard icon to copy the remote URL for your new repository. You\u0026rsquo;ll paste this text into RStudio in the next section.\n  Step 2: Create project    We just created the remote repository on GitHub. To make a local copy on our computer that we can actually work in, we\u0026rsquo;ll clone that repository into a new RStudio project. This will allow us to sync between the two locations: your remote (the one you see on github.com) and your local desktop.\nOpen up RStudio to create a new project where your website\u0026rsquo;s files will live.\n  Click File \u0026gt; New Project \u0026gt; Version Control \u0026gt; Git.\n  Paste the copied URL from the previous step.\n  Be intentional about where you tell RStudio to create this new Project on your workstation.\n  Click Create Project.\n  Step 3: Create site      The latest version of blogdown will not be available on CRAN until January 2021, but you can install the development version from GitHub with:\n\u0026gt; if (!requireNamespace(\u0026quot;remotes\u0026quot;)) install.packages(\u0026quot;remotes\u0026quot;) \u0026gt; remotes::install_github(\u0026quot;rstudio/blogdown\u0026quot;) Using github PAT from envvar GITHUB_PAT Downloading GitHub repo rstudio/blogdown@master    Let\u0026rsquo;s use our first blogdown function to create a website with the Hugo Wowchemy \u0026ldquo;starter-academic\u0026rdquo; project:\n\u0026gt; library(blogdown) \u0026gt; new_site(theme = \u0026quot;wowchemy/starter-academic\u0026quot;)    You should now see something like this. Take a moment to read through these messages - importantly, it tells you how to start and stop the server so you can preview your site. Importantly, when you come back to your project, note that you can use blogdown::serve_site() or the \u0026ldquo;Serve Site\u0026rdquo; addin to preview it locally.\nLet\u0026rsquo;s select y to let blogdown start a server for us.\nExciting, isn\u0026rsquo;t it? Now, don\u0026rsquo;t trap your site in the RStudio Viewer pane. Let it out! Click to \u0026ldquo;Show in new window\u0026rdquo; (to the right of the üßπ icon) to preview it in a normal browser window. When you do that, you\u0026rsquo;ll be re-directed to the site\u0026rsquo;s main homepage. Let\u0026rsquo;s find our way back to the R Markdown post. Click on Posts \u0026gt; Hello R Markdown to read it:\nThis is what blogdown gives you- everything else in the site is given to you by Hugo and your Wowchemy Hugo theme. But this post, and your ability to see output and plots rendered with  is what blogdown adds!\n  Step 4: Create content    Let\u0026rsquo;s use more R Markdown üéâ\nBlogdown allows you to create new two kinds of R Markdown posts that are knittable:\n  .Rmd üß∂ to .html or\n  .Rmarkdown üß∂ to .markdown\n  Once knitted, both are then previewable in your Hugo site.\n I used to agonize over which file extension to use. But now I am squarely in .Rmarkdown camp with Ma√´lle- I like knitting to .markdown and wish this was easier in blogdown; see: https://github.com/rstudio/blogdown/issues/530   Use the console to author a new .Rmarkdown post; I\u0026rsquo;ll name my post \u0026ldquo;Hi Hugo\u0026rdquo;:\n\u0026gt; blogdown::new_post(title = \u0026quot;Hi Hugo\u0026quot;, ext = '.Rmarkdown', subdir = \u0026quot;post\u0026quot;)  This takes the path to where you want your post to live, relative to the content/ folder (so that piece of the path is assumed, rightly so!). In the Academic theme, the example site organizes blog posts into the content/post/ folder, but the name of this folder varies across Hugo themes.\n A rule that is true 90% of the time: folders in content/ are singular, not plural\u0026mdash; ‚úîÔ∏è post; ‚ùå posts   You can add an option to your .Rprofile to save these settings so you don\u0026rsquo;t have to remember them:\n# if exists, opens; if not, creates new blogdown::config_Rprofile()  Then add the blogdown options to that file, save, and RESTART YOUR R SESSION for changes to take effect:\noptions( # to automatically serve the site on RStudio startup, set this option to TRUE blogdown.serve_site.startup = FALSE, # to disable knitting Rmd files on save, set this option to FALSE blogdown.knit.on_save = FALSE \u0026lt;- change blogdown.author = \u0026quot;Alison Hill\u0026quot;, \u0026lt;- add blogdown.ext = \u0026quot;.Rmarkdown\u0026quot;, \u0026lt;- add blogdown.subdir = \u0026quot;post\u0026quot; \u0026lt;- add )   Always restart your R session after editing your .Rprofile for changes to take effect. Don\u0026rsquo;t forget to run serve_site() after a restart.   If you look in your Files pane, you can see that this creates a folder with the date and the \u0026ldquo;slug\u0026rdquo; name of my post (\u0026quot;hi-hugo\u0026quot;). The actual R Markdown file is named index.Rmarkdown.\nThis is a Hugo page bundle. Each post gets its own bundle, or folder. Inside the post bundle is where all your static images, static data files like .csv files should go.\ncontent/ ‚îú‚îÄ‚îÄ posts ‚îÇ ‚îú‚îÄ‚îÄ 2021-01-01-hi-hugo ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ bakers.csv ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ image1.jpg ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ image2.png ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ index.Rmarkdown  In the post itself, use the relative file path like:\n![my-first-image](image1.jpg)  Let\u0026rsquo;s look at the index.Rmarkdown. We\u0026rsquo;ll knit this .Rmarkdown to a .markdown file. You may üß∂ knit üß∂ freely now in blogdown!\nTo knit an .Rmarkdown post, you can either:\n  Use the Knit button to knit to the correct output format, or\n  Use the keyboard shortcut Cmd+Shift+K (Mac) or Ctrl+Shift+K (Windows/Linux).\n  After knitting, you should now see:\ncontent/ ‚îú‚îÄ‚îÄ posts ‚îÇ ‚îú‚îÄ‚îÄ hi-hugo ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ bakers.csv ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ image1.jpg ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ image2.png ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ index.Rmarkdown ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ index.markdown \u0026lt;- üÜï  Go ahead and add an R code chunk like:\n```{r} summary(Orange) ```  After you edit your .Rmarkdown post, knit. Note that knitting automatically saves the file for you. You also can just save the file without knitting- this is good for when your code still needs work and won\u0026rsquo;t run as is.\n The most important thing here is to realize that the act of knitting creates an index.markdown file in the same post bundle as index.Rmarkdown. Because Hugo doesn\u0026rsquo;t know R or R Markdown, The index.markdown version is what then feeds into the Hugo static site generator.   Try it again! Add another R code chunk like:\n```{r echo=FALSE} library(ggplot2) oplot \u0026lt;- ggplot(Orange, aes(x = age, y = circumference, colour = Tree)) + geom_point() + geom_line() + guides(colour = FALSE) + theme_bw() oplot ```  Knit, and you should see something like:\n Many R Markdown output options for HTML documents are not going to be possible here, like tabbed sections, floating table of contents, the code_download button, etc. Also, HTML widgets are a little dicey currently.   This is a single page. It is made with R Markdown, and happens to be a blog post, although you can use R Markdown to create content for any other content section too.\nIf you want a featured image to accompany your post and show up on your listing page (the clickable list of all your posts), you\u0026rsquo;ll want to add an image with the word featured in the filename:\ncontent/ ‚îú‚îÄ‚îÄ posts ‚îÇ ‚îú‚îÄ‚îÄ hi-hugo ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ bakers.csv ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ image1.jpg ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ image2.png ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ index.Rmarkdown ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ index.markdown ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ featured-bakers.jpg \u0026lt;- ‚ûï  Workflow    My workflow in RStudio at this point (again, just viewing locally because we haven\u0026rsquo;t deployed yet) works best like this:\n  Open the RStudio project for the site.\n  Start the Hugo server using blogdown::serve_site() (only once due to the magic of LiveReload).\n  View site in the RStudio viewer pane, and open in a new browser window while I work.\n  Select existing files to edit using the file pane in RStudio.\n  After making changes, save if a plain .md file, or if working with an .Rmd or an .Rmarkdown document, knit to preview! You can now use the Knit button to knit to the correct output format. You can also use the keyboard shortcut Cmd+Shift+K (Mac) or Ctrl+Shift+K (Windows/Linux).\n  The console will detect the change (it will print Change detected, rebuilding site.), the viewer pane will update, and (in a few seconds) your local view in your browser will also refresh. Try to avoid hitting the refresh button in your browser.\n  When happy with changes, add/commit/push changes to GitHub.\n  Having blogdown::serve_site running locally with LiveReload is especially useful as you can immediately see if you have totally screwed up. For example, in editing my about.md file, this error popped up in my console after making a change and I was able to fix the error right away:\nStarted building sites ... ERROR 2017/06/08 16:22:34 failed to parse page metadata for home/about.md: (18, 6): missing comma Error: Error building site: Errors reading pages: Error: failed to parse page metadata for home/about.md: (18, 6): missing comma for about.md  Using GitHub    Let\u0026rsquo;s go ahead and push our changes to GitHub. First, let\u0026rsquo;s make a .gitignore file:\nfile.edit(\u0026quot;.gitignore\u0026quot;)  Add this content:\n.Rproj.user .Rhistory .RData .Ruserdata .DS_Store Thumbs.db  Check yourself before you wreck yourself    Let\u0026rsquo;s use blogdown to check this file before we do our first commit:\nblogdown::check_gitignore()  You should see something like:\n\u0026gt; check_gitignore() ‚Äï Checking .gitignore | Checking for items to remove... ‚óã Nothing to see here - found no items to remove. | Checking for items you can safely ignore... ‚óã Found! You have safely ignored: .DS_Store, Thumbs.db | Checking for items to ignore if you build the site on Netlify... ‚óè [TODO] When Netlify builds your site, you can safely add to .gitignore: public, resources ‚Äï Check complete: .gitignore  You have a [TODO] item- go ahead and add public and resources on their own lines in your .gitignore file. We\u0026rsquo;ll be configuring Netlify to build our site shortly, so go right ahead while the file is open.\nWhile we are at it, let\u0026rsquo;s check out our content too:\nblogdown::check_content()  You may notice a few pieces of content are flagged as draft. This is good to know! Read up on drafts in Hugo here.\nOur checks are pretty clean, so you can freely add/commit your project files to GitHub. You now should have the basic mechanics of your site working.\nStep 5: Publish site    Thus far, we\u0026rsquo;ve only been previewing our site locally, then pushing the source files (but not the built site) to GitHub. This workflow works, but I assume you want to ride this bike. Let\u0026rsquo;s skip the training wheels ‚Äî we are going one step more advanced by using GitHub with Netlify now.\n Note that you could use blogdown::build_site(), then publish the public/ folder using Netlify drag \u0026amp; drop. Watch this webinar called \u0026ldquo;Sharing on Short Notice\u0026rdquo; to learn more - but this is a less advanced workflow.   To get started using Netlify for real (which has a free plan that should largely cover recreational blogging use!):\n  Go online to Netlify.\n  Click on the Sign Up button and sign up using your existing GitHub account (no need to create another account).\n  Log in, and select: New site from Git \u0026gt; Continuous Deployment: GitHub.\n  From there, Netlify will allow you to select from your existing GitHub repositories. You\u0026rsquo;ll pick the repo you\u0026rsquo;ve been working from with blogdown. Leave all settings as they are and select Deploy Site.\n  You should see something like this:\nWhen it is done, you can click on the link to your new site! And the most magical thing of all, every time you push any changes to your site to GitHub, Netlify will detect the push, re-build, then update your published site. It\u0026rsquo;s a good thing. It\u0026rsquo;s called continuous deployment, and it is the main reason to use Netlify for a blogdown site.\nWith a new site, Netlify will deploy your site and assign you a random subdomain name of the form random-word-12345.netlify.app. Mine was particularly unfortunate, with the random word garbage-collector-janice. You should know that you can change this; I changed mine to apreshill.netlify.app. Do this by navigating to your site on Netlify, then click on Settings. Under Site information, click on the Change site name button.\nWhether you change your Netlify site name or use the random one, go back to your configuration file and cchange the baseurl there to match where Netlify is publishing your site:\nrstudioapi::navigateToFile(\u0026quot;config.yaml\u0026quot;, line = 3)  You actually have most of the necessary wiring laid out for you already in your repo, which is why this worked. Our site has a netlify.toml file, which sets us the necessary settings for letting Netlify build our site for us and then publish it. You can read more about this file here, and check it out using:\n# if exists, opens; if not, creates new blogdown::config_netlify()  Now, back in your local blogdown project, let\u0026rsquo;s check this file with blogdown:\n\u0026gt; blogdown::check_netlify() ‚Äï Checking netlify.toml... ‚óã Found HUGO_VERSION = 0.79.1 in [build] context of netlify.toml. | Checking that Netlify \u0026amp; local Hugo versions match... | Mismatch found: blogdown is using Hugo version (0.79.0) to build site locally. Netlify is using Hugo version (0.79.1) to build site. ‚óè [TODO] Option 1: Change HUGO_VERSION = \u0026quot;0.79.0\u0026quot; in netlify.toml to match local version. ‚óè [TODO] Option 2: Use blogdown::install_hugo(\u0026quot;0.79.1\u0026quot;) to match Netlify version, and set options(blogdown.hugo.version = \u0026quot;0.79.1\u0026quot;) in .Rprofile to pin this Hugo version. | Checking that Netlify \u0026amp; local Hugo publish directories match... ‚óã Good to go - blogdown and Netlify are using the same publish directory: public ‚Äï Check complete: netlify.toml  I recommend going with Option 1 here, so follow that [TODO] and then run the function again to get a clean check.\nWhen you are ready to deploy, commit your changes and push to GitHub! Watch as your site rebuilds üéâ\n To get an *.rbind.io URL, follow these instructions.\nAnytime you change your subdomain name, you need to update the baseurl in your config.toml file (so I changed mine to baseurl = \u0026ldquo;https://apreshill.netlify.com/\u0026quot;).\n  Step 6: Sculpt site    Now, we\u0026rsquo;ll leave blogdown and R Markdown behind. We\u0026rsquo;ll just be using Hugo and Wowchemy (I think it is said like alchemy? Why??) to build your personal website.\nLet\u0026rsquo;s start by running another blogdown check to check_hugo():\n\u0026gt; blogdown::check_hugo() ‚Äï Checking Hugo | Checking Hugo version... ‚óã Found 4 versions of Hugo. You are using Hugo 0.79.0. | Checking .Rprofile for Hugo version used by blogdown... ‚óã blogdown is using Hugo 0.79.0 to build site locally. ‚óè [TODO] Also run blogdown::check_netlify() to check for possible problems with Hugo and Netlify. ‚Äï Check complete: Hugo  All set! We\u0026rsquo;ve already checked out our Netlify set-up ‚úîÔ∏è If you wish to clean up your local Hugo installations, check out:\nblogdown::remove_hugo()  Configure your site    Let\u0026rsquo;s start with the last thing you typically do to your home- decorate.\nOpen up the file config/_default/params.toml. Play with any of these configurations, but especially fonts/themes.\nrstudioapi::navigateToFile(\u0026quot;config/_default/params.toml\u0026quot;)   If you want deeper customization of the styling, you can create a new CSS file assets/scss/custom.scss and use it to override any existing styles. You can see mine here; heavily borrowing from my former intern Desir√©e De Leon!   While you are at it, edit the other configuration files:\n You can also view my config.toml file  Remember our menu intentions? Go ahead and edit those too:\nrstudioapi::navigateToFile(\u0026quot;config/_default/menus.toml\u0026quot;)  Let\u0026rsquo;s run a blogdown check on the configuration file before we leave:\n\u0026gt; blogdown::check_config() ‚Äï Checking config.yaml | Checking \u0026quot;baseURL\u0026quot; setting for Hugo... ‚óã Found baseURL = \u0026quot;https://silly-dubinsky-de5482.netlify.app\u0026quot;; nothing to do here! | Checking \u0026quot;ignoreFiles\u0026quot; setting for Hugo... ‚óè [TODO] Add these items to the \u0026quot;ignoreFiles\u0026quot; setting: \u0026quot;\\\\.Rmd$\u0026quot;, \u0026quot;\\\\.Rmarkdown$\u0026quot;, \u0026quot;\\\\.knit\\\\.md$\u0026quot;, \u0026quot;\\\\.utf8\\\\.md$\u0026quot; | Checking setting for Hugo's Markdown renderer... ‚óã All set! Found the \u0026quot;unsafe\u0026quot; setting for goldmark. ‚Äï Check complete: config.yaml  Looks like we have a few [TODO] items to add to our config.yaml file:\nrstudioapi::navigateToFile(\u0026quot;config.yaml\u0026quot;, line = 15)  Goodbye Nelson B.    Let\u0026rsquo;s say goodbye to Nelson Bighetti. Everything in this single markdown file populates what is called the about widget; a customized one looks like this:\nFind and open the file content/authors/admin/_index.md:\nrstudioapi::navigateToFile(\u0026quot;content/authors/admin/_index.md\u0026quot;)  Edit the YAML metadata to change:\n  The icons and where they link to\n  Your current role and organization\n  Your interests\n  Your education\n  The text under the YAML is your bio; you can use markdown here. Add an avatar.jpg file too (it must be named this) to the same folder.\nPrune widgets    Remember how we started with thinking about your content? We are ready to prune out some of our unwanted widgets.\nRecall that on the Academic demo site, the entire home page is filled with widgets! The default example site is the exact same as the demo. It sets almost every available widget to active to show you the range of what you could do.\nDeactivating the widgets you don\u0026rsquo;t need and only activating the ones you want will help you avoid having your home page feel like the üíÄ \u0026ldquo;scroll of death,\u0026rdquo; as my friend Jackie Wirz called it.\nRemember my Mr. Potato Head analogy? The home page is your most prominent potato, and the widgets are all the pieces you could use.\nEach widget you see is a *.md file in the content/home/ folder. The metadata at the top helps you configure each widget; namely whether it is active (true or false) and the widgets weight (ordering, actual numbers doesn\u0026rsquo;t matter- only relative to the other weights).\nFor example, to turn off the hero widget, use this code in your console and set active = false:\nrstudioapi::navigateToFile(\u0026quot;content/home/hero.md\u0026quot;, line = 5, column = 10)  Take about 10 minutes about try out turning widgets off and on, and changing their order to see what you like!\n You can also delete a widget file. You can always recover *.md widget files by going into your themes/hugo-academic/exampleSite/content/home/ folder.   For my own site, I use 4 main home page widgets:\n  about (photo / icons / bio / interests / education)  slider (used to showcase some feedback from my workshops)  posts (set to show only the most recent)  talks (set to show only the most recent)  Transplant widgets    If you opted for a more streamlined home page with fewer widgets, you may experience widget pruning regret. Many are very useful, and you may wish to use widgets on other pages that are not the home page. In this theme, this is possible! Even if you turn off a widget on the home page, you can create what is called a widget page and add or even combine widgets there. I make heavy use of widget pages in my own site. Here are the steps (following the docs):\n  Create a new folder in content/; let\u0026rsquo;s call it resume\n  Inside content/resume/, add a file named index.md\n  Populate content/resume/index.md with a YAML, like this:\n--- summary: More about my work experience title: \u0026quot;Resume\u0026quot; type: widget_page ---     The very critical line here is the type: widget_page\u0026mdash;this sets you up to now copy over widgets from content/home/ in this new folder.    Copy the widget *.md files you\u0026rsquo;d like to use into this content/resume/ folder. Edit their metadata (weights, other info), and be sure to set active = true. For my own resume, I copied the experience and accomplishments widgets over.\n  If you want to access this new widget page from your top navbar, open up your config/_default/menus.toml and add it there, like:\n[[main]] name = \u0026quot;Resume\u0026quot; url = \u0026quot;/resume\u0026quot; weight = 50     You can link to any specific widget by taking your baseurl and appending /#{name-of-widget}, so /#slider links to my homepage slider. And /resume/#accomplishments links to my honors \u0026amp; awards   Let\u0026rsquo;s run one final check, which wraps all 5 checking functions we\u0026rsquo;ve used so far into a single final checklist:\n\u0026gt; blogdown::check_site()  This is immensely comforting to me; read more about these new checking functions here.\nWe made it!    At this point, you should be up and running with blogdown, GitHub, and Netlify. You now have the scaffold up and ready for your ideas, your style, and your voice. If you made it this far, please share your site- I\u0026rsquo;d love to see it!\n","date":1609372800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609372800,"objectID":"c63332ebc9a22efd30941ea3f170d594","permalink":"https://maggie-98.github.io/post/new-year-new-blogdown/","publishdate":"2020-12-31T00:00:00Z","relpermalink":"/post/new-year-new-blogdown/","section":"post","summary":"New year, new blogdown! A guide to getting up and running with blogdown, the Hugo Wowchemy starter-academic theme, GitHub, and Netlify. Not brief.","tags":["hugo","blogdown","netlify","rmarkdown"],"title":"Up \u0026 running with blogdown in 2021","type":"post"},{"authors":null,"categories":null,"content":"This holiday season, the R Markdown elves at RStudio have been busy at work wrapping up the next release of the blogdown package. Blogdown is a package close to my own heart, as it was the subject of my very first blog post, and that led to co-authoring the book on blogdown.\nFast-forward more than three years later, and I have built, borked, and torched more blogdown/Hugo sites than I care to admit.\nBut, I\u0026rsquo;ve also learned a lot about how to use and learn blogdown/Hugo, and how to help other people troubleshoot their sites too.\nFor anyone thinking about dipping their toes into blogdown and making their first Hugo site, the vocabulary alone can be wildly intimidating. I remember being skeptical about Netlify, and also not fully understanding how exactly I had entered into a relationship with Hugo and what our boundaries were. There are so many moving pieces, and many possible missteps for new and even \u0026ldquo;more senior\u0026rdquo; users like myself. I\u0026rsquo;ve seen it all- users trying to serve a site from within an empty repo, having a missing theme folder, ignoring all rendered files, accidentally knitting an R Markdown file ( but now you can!). The list goes on and on and on.\nI admit- I originally thought education could solve these issues at first. We just needed to improve the documentation, I thought. Maybe the book could be better. But, in truth, we needed to think inside the package box, because that is the only failsafe way to reach users. So, the package itself needed to do more. The blogdown package had already implemented several printed warnings and error messages intended to help guide users toward the happy path. However, we got feedback that many users were unsure how to act on the messages and sometimes just ignored them (myself included!). Then I asked my colleague Jenny Bryan about her approach to package warnings and error messages, and she said something very simple (paraphrased from my notes!):\n When possible, it is much better to offer users control over when and how they can solve their own problems.\n When you force users to wait for an error to occur, you are putting the user in a reactive stance. This is typically not a great mental space to be in to learn. Learning is highly unlikely in a reactive stance too, because messages focus on informing the user what the error is, but often fail to say how to make it go away. On the other hand, giving users targeted functions can help them feel proactive and empowered. Well-designed functions can give you as the package developer an opportunity to offer opinionated advice, and at the same time, help the user gain a mental model of a complicated situation. This idea is the driver behind the usethis::git_sitrep() and usethis::proj_sitrep() functions.\nAfter this conversation with Jenny, I sketched out an idea for a series of \u0026ldquo;checking\u0026rdquo; functions for blogdown. I wasn\u0026rsquo;t sure all of these were actually possible, but with the amazing help of Yihui Xie and Christophe Dervieux, we came up with five functions to help ensure user success:\n check_config() check_gitignore() check_hugo() check_content() check_netlify()  Each of these functions is meant to be used interactively as you build and edit your blogdown site. A clean pre-flight checklist still unfortunately cannot ensure website success, but it will help users sidestep the most common and avoidable pitfalls.\nA sixth function, check_site(), wraps all five up in a single function, which I suspect will be most useful for existing blogdown users who are already familiar with GitHub, Netlify, and Hugo.\nWe ended up doing a lot of massaging of the output formatting ( see my PR), and finally settled on the following:\n---------------------------------------------------------- ‚óã A successful check looks like this. ‚óè [TODO] A check that needs your attention looks like this. | Let's check out your blogdown site! ----------------------------------------------------------  I\u0026rsquo;m really happy with the end result, and I hope users are as well. I not-so-secretly hope these functions help educators feel braver about teaching blogdown too. So, without further ado\u0026hellip;\n| Let's check out your blogdown site!  To do this on your own, you\u0026rsquo;ll want to use the remotes package to install the development version of blogdown:\nremotes::install_github(\u0026quot;rstudio/blogdown\u0026quot;)  Check your site\u0026rsquo;s configuration    Your Hugo site\u0026rsquo;s main configuration file is located in the project root of your website, called config.toml or config.yaml. This file is your most direct line of communication with Hugo itself, and settings in this file are usually the first I check when trying to help users troubleshoot their build.\nblogdown::check_config()  ‚Äï Checking config.toml | Checking \u0026quot;baseURL\u0026quot; setting for Hugo... ‚óã Found baseURL = \u0026quot;https://alison.rbind.io\u0026quot;; nothing to do here! | Checking \u0026quot;ignoreFiles\u0026quot; setting for Hugo... ‚óè [TODO] Add these items to the \u0026quot;ignoreFiles\u0026quot; setting: \u0026quot;\\\\.Rmd$\u0026quot;, \u0026quot;\\\\.Rmarkdown$\u0026quot;, \u0026quot;\\\\.knit\\\\.md$\u0026quot;, \u0026quot;\\\\.utf8\\\\.md$\u0026quot; | Checking setting for Hugo's Markdown renderer... ‚óã All set! Found the \u0026quot;unsafe\u0026quot; setting for goldmark. ‚Äï Check complete: config.toml  You can see I have one [TODO] item. Below, I\u0026rsquo;ll bork up my own config.toml file a bit more:\n‚Äï Checking config.toml | Checking \u0026quot;baseURL\u0026quot; setting for Hugo... ‚óè [TODO] Update \u0026quot;baseURL\u0026quot; to your actual URL when ready to publish. | Checking \u0026quot;ignoreFiles\u0026quot; setting for Hugo... ‚óè [TODO] Add these items to the \u0026quot;ignoreFiles\u0026quot; setting: \u0026quot;\\\\.Rmd$\u0026quot;, \u0026quot;\\\\.Rmarkdown$\u0026quot;, \u0026quot;\\\\.knit\\\\.md$\u0026quot;, \u0026quot;\\\\.utf8\\\\.md$\u0026quot; | Checking setting for Hugo's Markdown renderer... | You are using the Markdown renderer 'goldmark'. ‚óè [TODO] Allow goldmark to render raw HTML by adding this setting to config.toml (see https://github.com/rstudio/blogdown/issues/447 for more info): [markup] [markup.goldmark] [markup.goldmark.renderer] unsafe = true ==\u0026gt; Do you want blogdown to set this for you? (y/n) n ‚Äï Check complete: config.toml  A few more [TODO] items here, but all are actionable, and originate from a single file (config.toml) which the function also opens for you interactively. üéâ\nCheck your .gitignore file    If you are using blogdown, you\u0026rsquo;ll likely need a version control system like Git. Files named in a .gitignore file will always be ignored whenever you add and commit files to your remote repository, but having the wrong files listed here can easily sink you a few hours (I\u0026rsquo;ve had this happen several times with collaborators!). Now, we can run a tidy little check:\nblogdown::check_gitignore()  ‚Äï Checking .gitignore | Checking for items to remove... ‚óã Nothing to see here - found no items to remove. | Checking for items you can safely ignore... ‚óã Found! You have safely ignored: .DS_Store ‚óè [TODO] You can safely add to .gitignore: Thumbs.db | Checking for items to ignore if you build the site on Netlify... ‚óã Found! You have safely ignored: public, resources ‚Äï Check complete: .gitignore  This function screens for items you should remove, and for items you can safely add. It also checks if you are using Netlify, which we assume based on the presence of a netlify.toml file in your project.\nCheck your Hugo versions    Hugo versions were by far my biggest pain point. Earlier this year, I had added some kind of Hugo versioning system built into blogdown to my giant feature wishlist. I am so relieved that this latest release of blogdown includes this, but that meant we also needed to provide users with ways to inspect and maintain their Hugo versions.\nblogdown::check_hugo()  ‚Äï Checking Hugo | Checking Hugo version... ‚óã Found 4 versions of Hugo. You are using Hugo 0.79.0. | Checking .Rprofile for Hugo version used by blogdown... | Hugo version not set in .Rprofile. ‚óè [TODO] Set options(blogdown.hugo.version = \u0026quot;0.79.0\u0026quot;) in .Rprofile. ‚óè [TODO] Also run blogdown::check_netlify() to check for possible problems with Hugo and Netlify. ‚Äï Check complete: Hugo  Note that the new blogdown Hugo versioning system now relies on a .Rprofile file that you probably want to keep in the project root. These files are a bit annoying, because anytime you need to edit them, you\u0026rsquo;ll want to restart your R session for changes to take effect. If you don\u0026rsquo;t have a project-level .Rprofile file, try the newly added blogdown::config_Rprofile() function to create one (see ?config_Rprofile for help).\nCheck your Hugo content    Your Hugo site\u0026rsquo;s content predictably lives inside the content/ folder of your project. But there are lots of unpredictable things Hugo can do (or not do) with your content. For example, I think every blogdown user at some point has stumbled into the draft: TRUE minefield, or the future dated content abyss. As well, many users accidentally end up with duplicate rendered output files (Hugo will prefer the .html if present). This function checks these things for you:\nblogdown::check_content()  ‚Äï Checking content files | Checking for previewed content that will not be published... ‚óè [TODO] Found 1 file with a future publish date: content/talk/2021-rstudio-global/index.md If you want to publish today, change a file's YAML key to 'date: 2020-12-27' ‚óã Found 0 files marked as drafts. | Checking your R Markdown content... ‚óã All R Markdown files have been knitted. ‚óã All R Markdown output files are up to date with their source files. | Checking for .html/.md files to clean up... ‚óã Found 0 duplicate .html output files. ‚óã Found 0 incompatible .html files to clean up. ‚Äï Check complete: Content  Note that this also checks that all R Markdown files have some kind of knitted rendered output present. This is üÜï, and we believe is a better default. Think: save-on-knit. You now only need to knit R Markdown files (the previous behavior was knit-on-save, which sometimes led to an error-filled render vortex if your code did not run).\nCheck your Netlify setup    Almost done with your pre-flight checklist! The last one helps set you up for deployment success:\nblogdown::check_netlify()  ‚Äï Checking netlify.toml... ‚óã Found HUGO_VERSION = 0.79.0 in [build] context of netlify.toml. | Checking that Netlify \u0026amp; local Hugo versions match... ‚óã It's a match! Blogdown and Netlify are using the same Hugo version (0.79.0). | Checking that Netlify \u0026amp; local Hugo publish directories match... ‚óã Good to go - blogdown and Netlify are using the same publish directory: public ‚Äï Check complete: netlify.toml  No [TODO]s! Now let\u0026rsquo;s bork things up:\n‚Äï Checking netlify.toml... ‚óã Found HUGO_VERSION = 0.69.0 in [build] context of netlify.toml. | Checking that Netlify \u0026amp; local Hugo versions match... | Mismatch found: blogdown is using Hugo version (0.79.0) to build site locally. Netlify is using Hugo version (0.69.0) to build site. ‚óè [TODO] Option 1: Change HUGO_VERSION = \u0026quot;0.79.0\u0026quot; in netlify.toml to match local version. ‚óè [TODO] Option 2: Use blogdown::install_hugo(\u0026quot;0.69.0\u0026quot;) to match Netlify version, and set options(blogdown.hugo.version = \u0026quot;0.69.0\u0026quot;) in .Rprofile to pin this Hugo version. | Checking that Netlify \u0026amp; local Hugo publish directories match... ‚óã Good to go - blogdown and Netlify are using the same publish directory: public ‚Äï Check complete: netlify.toml  Whoops! You can see that a mismatch was found: I\u0026rsquo;m using a newer version of Hugo on Netlify than I am using to build locally. You want these to match, so that you can be reasonably sure that what you see on your public site will not be a surprise üò±\nCheck your site    If you don\u0026rsquo;t want to go file-by-file and step-by-step, and you\u0026rsquo;re into more of a \u0026ldquo;kitchen sink\u0026rdquo; approach, give check_site() a try. It will wrap all these checks up for you in a single function call.\nPlease give the development version of the blogdown package a try, and help us make it better by filing issues on GitHub. And I hope these new functions help you have more fun actually working with your site!\nYou can watch my recent talk at the LA R User Group meetup on YouTube to see learn more about the new features you can look forward to with this latest blogdown release here.\n","date":1609027200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609027200,"objectID":"07ac65ee096e437bcfda7e07bddcbe59","permalink":"https://maggie-98.github.io/post/2020-12-27-blogdown-checks/","publishdate":"2020-12-27T00:00:00Z","relpermalink":"/post/2020-12-27-blogdown-checks/","section":"post","summary":"The latest release of the blogdown package (not yet on CRAN) includes new checking functions to help users make less breakable Hugo sites.","tags":["rmarkdown","blogdown"],"title":"Unbreak your blogdown site","type":"post"},{"authors":null,"categories":null,"content":"This is a very brief \u0026ldquo;postcard to myself\u0026rdquo; about how to use the new postcards package by Sean Kross. What problem does postcards solve?\n \u0026ldquo;Create simple, beautiful personal websites and landing pages using only R Markdown.\u0026rdquo;\n\u0026mdash; postcards README.md\n Postcards includes four templates:\n  Jolla,  Jolla Blue,  Trestles, and  Onofre.  You can see postcards::trestles in action here: http://jtleek.com/\nAnd here (this is where we are headed!):\n Distill is a package that also helps you make simple, beautiful websites and blogs using only R Markdown. They are M-F-E-O (\u0026lsquo;made for each other\u0026rsquo;: this is a \u0026ldquo;Sleepless in Seattle\u0026rdquo; reference with sadly, a complete lack of video to support). But if you\u0026rsquo;ve seen the movie this scene may sound familiar:\n Becky: So I mailed your letter.\nAnnie: \u0026ldquo;Dear Annie, thanks for your letter. It was great. You sound neat. We\u0026rsquo;re very excited about meeting you in New York on Valentine\u0026rsquo;s Day and seeing if we are M-F-E-O. See you soon. Sleepless in Seattle.\u0026rdquo;\nBecky: M-F-E-O?\nAnnie: \u0026ldquo;Made for each other.\u0026rdquo;\nBecky: It\u0026rsquo;s cute. It\u0026rsquo;s like a little clue. So he can\u0026rsquo;t write. Big deal. Verbal ability is a highly over-rated thing in a guy and our pathetic need for it is what gets us into so much trouble.\n\u0026mdash; Sleepless in Seattle, script from https://plantyourstory.com/mfeo-its-like-a-little-clue/\n Consider this post like a little clue (I\u0026rsquo;m using it as a sandbox before updating our distill documentation for this new feature). Here is our existing signpost in the distill docs. With the development versions (currently) of three packages now, you can embed a postcards page within your distill site. This means the page will come with all your distill goodies like site navigation, theme, and google-analytics support.\n You can see the demo site I made alongside this post here: https://apreshill.github.io/mfeo/ (source: https://github.com/apreshill/mfeo).   Pre-requisites    You\u0026rsquo;ll need the development versions of two packages:\n distill (v \u0026gt;= 1.2) (see: https://pkgs.rstudio.com/distill/news/index.html#distill-v12-development) rmarkdown  Use the remotes package to install development versions:\nremotes::install_github(\u0026quot;rstudio/distill\u0026quot;) remotes::install_github(\u0026quot;rstudio/rmarkdown\u0026quot;)  Plus the CRAN version (v \u0026gt;= 0.2.0) of the postcards package.\ninstall.packages(\u0026quot;postcards\u0026quot;)  Make a website    In RStudio, create a new project using File \u0026gt; New Project \u0026gt; New Directory \u0026gt; New Project. Then, inside your new empty project, use your R console to do the following:\nlibrary(distill) create_website(dir = \u0026quot;.\u0026quot;, title = \u0026quot;mfeo\u0026quot;, gh_pages = TRUE)  At this point, I recommend closing RStudio completely and opening up your project again. This way you should see the \u0026ldquo;Build\u0026rdquo; tab.\nNow build your site! You should see the \u0026ldquo;boilerplate\u0026rdquo; website template at this point.\nAdd a postcard    In your R console, use the postcards package to create a new postcard:\ncreate_postcard(file = \u0026quot;tobi.Rmd\u0026quot;) # future name of .Rmd file  Alternatively, you could use distill::create_article() to make a new page. To make a postcard, specify the template (one of: jolla, jolla-blue, onofre, trestles) and package = 'postcards':\ncreate_article(file = \u0026quot;tobi\u0026quot;, # future name of .Rmd file template = \u0026quot;jolla\u0026quot;, # name of template package = \u0026quot;postcards\u0026quot;) # package that includes the template  Let\u0026rsquo;s add a link to our new file in the top navbar. Open up your _site.yml file and add:\nname: \u0026quot;.\u0026quot; title: \u0026quot;mfeo\u0026quot; description: | mfeo output_dir: \u0026quot;docs\u0026quot; navbar: right: - text: \u0026quot;Home\u0026quot; href: index.html - text: \u0026quot;About\u0026quot; href: about.html - text: \u0026quot;Tobi\u0026quot; # add href: tobi.html # add output: distill::distill_article  Since my file is named tobi.Rmd, that means the rendered file will be tobi.html, so that is my href key in the _site.yml. If you save that file, you should see your website refresh, and look something like this!\nAdd a theme    For fun, let\u0026rsquo;s go ahead and add a custom distill theme while we\u0026rsquo;re at it.\ncreate_theme(\u0026quot;postcards\u0026quot;)   You can see copy my theme file from here: https://github.com/apreshill/mfeo/blob/master/postcards.css.   This should print to your R console:\nv Created CSS file at postcards.css o TODO: Customize it to suit your needs o TODO: Add 'theme: postcards.css' to your site or article YAML See docs at \u0026lt;https://rstudio.github.io/distill/website.html#theming\u0026gt;  I want a full-site theme, so I added theme: postcards.css to my _site.yml file. I followed the distill docs on theming here. Re-build my website, and now I see:\nSwitch the homepage    Now you may be wishing that your postcards page was your homepage- the place where visitors first land when they visit your website. The homepage in a distill website is named index.Rmd, so we need to remove the current index.Rmd file and replace it with tobi.Rmd. But we cannot just rename the files\u0026hellip;\nIf you open up index.Rmd, you should see this yaml:\n--- title: \u0026quot;mfeo\u0026quot; description: | Welcome to the website. I hope you enjoy it! site: distill::distill_website ---  That site key is very important to keep in the index.Rmd file. Steps:\n Let\u0026rsquo;s start by adding site: distill::distill_website to the yaml of your postcards page, mine is named tobi.Rmd. After doing that, you can delete index.Rmd. Next, rename tobi.Rmd -\u0026gt; index.Rmd. Finally, clean up your _site.yml - you can remove the link we added above to tobi.html.  Re-build your site and Tobi\u0026rsquo;s shining face should greet you from the homepage!\nFill-in your postcard    Of course, you can add your own image file to the project root at this point, and then personalize your index.Rmd using the postcards template:\n--- title: \u0026quot;Alison Hill\u0026quot; image: \u0026quot;alison.jpg\u0026quot; links: - label: LinkedIn url: \u0026quot;https://www.linkedin.com/in/alisonpresmaneshill/\u0026quot; - label: Twitter url: \u0026quot;https://twitter.com/apreshill\u0026quot; - label: GitHub url: \u0026quot;https://github.com/apreshill\u0026quot; - label: ORCID iD url: \u0026quot;https://orcid.org/0000-0002-8082-1890\u0026quot; site: distill::distill_website output: postcards::jolla ---  Here is my \u0026ldquo;after\u0026rdquo;:\nAdd a blog    Back in your console, we can add a blog, using distill:\ncreate_post(\u0026quot;welcome\u0026quot;)  If you do this with a blog already, it just adds a single post. But if you do this without posts set up, it does some nice things for you:\n  Creates a directory called _posts/ to hold all your future blog posts.\n  Creates a new post with a \u0026ldquo;slug\u0026rdquo; including the date and the name of the post (here, mine was \u0026quot;welcome\u0026quot;).\n  Your new post should open up - go ahead and knit this post. Posts in distill need to be knit intentionally, so they will never be automatically built when you rebuild your website.\nWe also probably want to add a listing page to list all our blog posts. Do this by adding a blank .Rmd file to your project root, I\u0026rsquo;ll call mine blog.Rmd but there is no magic to this file name:\nfile.edit(\u0026quot;blog.Rmd\u0026quot;)  Then open up your new blog.Rmd and add a YAML (no content below the YAML):\n--- title: \u0026quot;Blog\u0026quot; # any name you want here listing: posts # do this exactly ---  Finally, add a link to your blog in your upper navbar so people can actually find it! Do this by editing _site.yml one last time (remember, since my listing .Rmd is named blog.Rmd, then the href I want to link to is blog.html):\nnavbar: right: - text: \u0026quot;Home\u0026quot; href: index.html - text: \u0026quot;About\u0026quot; href: about.html - text: \u0026quot;Blog\u0026quot; # add href: blog.html # add  Now, admire your final polished product!\n Switch your postcard    Let\u0026rsquo;s say you decide you want to switch it up and use the trestles theme, instead of jolla. Easy. Open up your index.Rmd and find these lines in the YAML:\n--- output: postcards::jolla ---  And change to:\n--- output: postcards::trestles ---  Re-build your site!\nPublishing    I won\u0026rsquo;t be able to cover all the publishing options here, but you can read up on the options for publishing distill websites here. If you want to take a site like mine that you built, I recommend GitHub Pages. You can use the usethis package to run:\nusethis::use_git() usethis::use_github()   I also just learned about the new usethis::use_github_pages() to turn on and/or (re)configure GitHub Pages!   Then in the GitHub project, navigate over to \u0026ldquo;Settings\u0026rdquo; and scroooooooll down to choose:\nFor this to work, make sure your site is building to docs/ locally, and that you are committing and pushing the docs/ directory to GitHub.\n","date":1608595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608595200,"objectID":"febef11e457a028007e461ffaed0d6b1","permalink":"https://maggie-98.github.io/post/2020-12-22-postcards-distill/","publishdate":"2020-12-22T00:00:00Z","relpermalink":"/post/2020-12-22-postcards-distill/","section":"post","summary":"The new postcards package and distill are M-F-E-O (made for each other). Here is a brief walk-through to add a postcards personal profile page to your distill website or blog, using only R Markdown.","tags":["rmarkdown","distill","postcards"],"title":"M-F-E-O: postcards + distill","type":"post"},{"authors":null,"categories":null,"content":"Last summer (üò¨), I was invited to give a talk at the Joint Statistical Meetings on data science education. The session I was invited to join included Shannon Ellis, Stephanie Hicks, and Michael Love as the other speakers, and I immediately knew what I wanted to talk about!\nFigure 1: L to R: Shannon Ellis, Stephanie Hicks, Michael Love, me\n  If you just want to skip to my actual slides, they are here.   Teaching students to talk about data science    One of the things I spent a lot of time thinking about in my 12 years as a professor was how to teach students how to communicate about data science with other human beings. It is sometimes all too easy to focus on \u0026ldquo;just\u0026rdquo; the practical skills like being able to wrangle, explore, analyze, and visualize data (preferably using code). But, teaching students to be able to describe, document, plan, collaborate, question, and communicate effectively about data science? That is way harder than it sounds.\nFor example, you may know learners like this:\nYou can ask them focused questions on an assignment, and they do fine. Maybe even great.\nFigure 2: A+ writing\n Then you may ask them to present their work. Also fine. Maybe even great.\nFigure 3: A+ presenting\n Then comes the Q\u0026amp;A, and maybe a colleague you invited or another student asks a good question\u0026hellip;and your star student freezes. Or maybe they tell you about a job interview they had, and they fumbled it.\nFigure 4: Oh no\n As a former language researcher, I like to compare this to learning the semantics versus pragmatics of language. So semantics is concerned with getting vocabulary and meaning correct. But pragmatics is all about language use in real life. And to get a job, to engage with and contribute to the data science community, learners need pragmatics.\nFigure 5: The semantics \u0026 pragmatics of data science communication\n So how did I start getting them there? Sort of by accident! One day, I happened to stumble upon a syllabus by Hal Daum√© from his machine learning class. I noticed something intriguing in there called \u0026ldquo;self-assessments.\u0026rdquo;\nFigure 6: From Hal Daum√©'s syllabus\n This slide was all I could find out about it, but it was enough to get my wheels turning right away. Having a Ph.D. in developmental psychology, I\u0026rsquo;d spent a lot of time studying the literature on the science of learning, and the idea of a self-assessment made me think:\nWhy might this actually work? It reinforces some tried and true self-directed learning strategies that are actually evidence-based like:\n retrieval practice! distributed practice! elaborative interrogation! self-explanation!  All that to say, self-assessment would help students talk to themselves and to me about data science- in a way that I hadn\u0026rsquo;t enabled before.\n I won\u0026rsquo;t bore with all the edu literature, but if you want to know more you might enjoy reading:\n http://www.indiana.edu/~pcl/rgoldsto/courses/dunloskyimprovinglearning.pdf http://tguilfoyle.cmswiki.wikispaces.net/file/view/What_works,_What_doesn%27t.pdf https://www.apa.org/science/about/psa/2016/06/learning-memory    I had also had this little bee in my bonnet for awhile, and that was that I spent an inordinate amount of time crafting the most beautiful homework answer keys for my students\u0026hellip;that no one seemed to read. No one used my answer keys for learning. It bothered me because I knew there was value in reviewing these answer keys, but I hadn\u0026rsquo;t made them into an actual learning tool. When I saw Hal\u0026rsquo;s slide, it dawned on me: the solution to my problem was to give my answer keys away, and make them into a usable learning tool.^[I later found out that my palmerpenguins co-author Dr. Allison Horst does this too! https://www.allisonhorst.com/post/share-keys/]\nThe truth is, providing the answer keys or feedback at the end is not actually helpful for learners. Students have high motivation and set aside time for what matters for their grade, not necessarily their learning. So it\u0026rsquo;s no surprise that motivation was low and time was limited for students to devote to \u0026ldquo;extracurricular\u0026rdquo; learning.\nWhat if the homework was less about how well students could do with little support, and more about how much they could learn with all my support?\nI decided to find out. The next time I taught my statistics course, I began requiring students to turn in self-assessments. Here is my version of Hal\u0026rsquo;s slide with my rough plan:\nFigure 7: Self-assessment plan\n If you look carefully there, you\u0026rsquo;ll see that there are in fact two ways to succeed while really trying in my class, and I was very proud of this. At the beginning of class, I would tell students that some over-achievers might find this annoying at first, but that for me, my ultimate goal was that every single person learned. I didn\u0026rsquo;t care whether you got it right off the bat, or whether you needed more time and resources to get it right. Either way, my grades mapped onto actual learning.\nAlso note that the 0/1/2 points for the initial submission had nothing to do with accuracy of their initial solutions. And the accuracy for the self-assessment had only to do with the accuracy of their self-assessment! So really, we washed away the grading effect of getting it right in 1 week alone or in 2 weeks with the key. The students who got it right on the initial submission bought themselves every other week free and clear from assignments, though.\nHow to succeed while really trying    Submit a perfectly accurate initial solution.    If your initial submission was a good faith effort (2 points) and happened to be perfectly accurate when you reviewed the answer key (3 points), you got a 5/5 for that question.\n \u0026ldquo;I found the same results as the answer key. Bada bing, bada boom.\u0026rdquo;\n Submit a perfectly accurate self-assessment.    If your initial submission was a good faith effort (2 points) but you did a bang-up job analyzing all of your mistakes and misunderstandings after thoroughly reviewing the key (3 points), you got a 5/5 for that question.\n \u0026ldquo;Well, well, well. I was really confused about interaction effects.\u0026rdquo;\n  \u0026ldquo;Gah! I didn\u0026rsquo;t actually understand the null hypothesis here.\u0026rdquo;\n  \u0026ldquo;I forgot to set a seed for my permutation test, so now I see why my results kept changing!\u0026rdquo;\n Sample self-assessments     \u0026ldquo;Most of my code matches the answer key - there were only one or two sections where I didn‚Äôt make the correct plot or write the correct code for the desired output, but I think a good portion of my narrative was accurate, which is encouraging.\u0026rdquo;\n  \u0026ldquo;After doing this self-assessment, I‚Äôm realizing that I had a better grasp on this analysis than I had previously thought. I made a couple small errors, but after seeing the answer key, I think I understood why I made them and how to avoid those errors in the future. \u0026quot;\n  \u0026ldquo;I liked that the self-assessment allowed me to see where I was close and what parts I was really far off.\u0026rdquo;\n  \u0026ldquo;I found that, while generating this model was straightforward, interpretation of the results was more difficult than I expected.\u0026rdquo;\n Logistics    OK, at this point, you may also be credibly curious. But you are probably wondering, how on earth did this actually work?\nTurning it in    We advised students to color their text in R Markdown files knitted to HTML. The self-assessment portion always needed to be colored. You can find guidance on how to do that in the R Markdown cookbook: https://bookdown.org/yihui/rmarkdown-cookbook/font-color.html\nTrade-offs    Yes, I did have to cut back significantly on my homeworks. Whereas I would have anywhere from 6-8 homeworks before, I went down to four per quarter (plus a final project). This was because I typically allowed 1 week for the initial submission and another for the self-assessment, with no overlap. So each homework took 2 weeks. I trimmed homework length down, and I cut out anything that wasn\u0026rsquo;t essential.\nTime spent by TAs    Honestly, I would have loved for self-assessments to have saved myself and my TAs time. I cannot say this was my experience. It was about the same amount of time overall.\nBut, what our teaching team did notice was that we felt better with our own grade assignments, and we enjoyed the grading process more. Rather than feeling like you were searching for mistakes to remove points, you were searching for true insights gained to add points. Small code errors or typos were usually caught by the students themselves, so TAs felt less personally responsible for making sure students were made aware of everything they did wrong. Also, student self-assessments were funny, charming, and allowed us to get to know them better. We also were better able to identify students who could use 1-on-1 help\u0026hellip;because they would tell us that.\nAnd that brings me to the most common question I get: how did I assign grades? Truth be told, grading was my absolute least favorite part of teaching in academia. But self-assessments actually helped me get to a place where I felt like my grades mapped onto my goals. Here is an excerpt from my syllabus that describes my system:\nHomework    A total of 4 homeworks will be assigned; your lowest score will be dropped at the end of the quarter. Some homeworks will require you to use R to analyze data. Although no prior R experience is required for this course, be prepared to do a lot of self-guided learning. Students are expected to run R on their own computer or a computer they have plenty of access to and control over. Please attempt to do all homeworks on your own, but you may work with other students. However, you may not submit homework assignments as a group. You should submit your own original work.\nYou will have 1 week to complete each homework assignment, and your initial solutions must be submitted to Sakai by 2pm on the due date (at the start of class on Thursdays). Late homeworks will not be accepted.\nHomework self-assessment    After the initial solutions are due, you will be provided a solution key. Using that key, you will be asked to assess your own initial solutions for accuracy and thoroughness; where you made mistakes, you must discuss and analyze where you went wrong, and correct them without copying/pasting directly from the key (this typically means that you need to include more narrative than we provide in the key). A good self-assessment will include:\n Assessment of the accuracy and completeness of your \u0026ldquo;initial solutions\u0026rdquo; Correct worked solutions with some discussion and analysis of why your initial solution was incorrect, and reflection on the source of your confusion (if you got an answer correct, this is not necessary) Attributions as appropriate to other students who helped you, or other sources such as lecture notes, readings, online resources, etc. that helped you  Homework grades    Homework grades will be based on:\n Was your initial solution a good faith effort? Did you catch all of your own errors in your self-assessment? Is your updated solution correct?  Each homework includes 3 questions, worth 5 points per question, scored as follows:\n2 points for each initial solution being ‚Äúin-good-faith‚Äù.\n  2 (Strong attempt): answer reflects strong independent problem solving, with clearly thought out attempts to approach the problem and a diligent and honest effort to find the solution\n  1 (Weak attempt): answer reflects some attempt to approach the problem, but approach appears to be superficial and lacks depth of analysis\n  0 (No attempt)\n  3 points for the quality of the final answer / discussion.\n  3 (Exceptional): answer is thorough, concise, and clearly demonstrates ability to analyze and interpret statistics as well as theoretical understanding of statistical concepts\n  2 (Adequate): answer addresses the question with moderate inaccuracies in analysis and/or interpretation, or offers a correct but incomplete answer\n  1 (Inadequate): answer attempts to address question with substantial inaccuracies in analysis and/or interpretation\n  0 (Insufficient): answer does not attempt to address question or answer is insufficient to grade\n  This means that:\n You can get 100% of the points if you either:  Submit perfectly accurate initial solutions, or Submit a perfectly accurate self-assessment,   If you simply cannot submit any homework solutions on time, after the homework due date, you will receive the solutions key and can submit a self-assessment for a max score of 60% (3 out of 5 points per problem). We feel this is fair given that:  You did not attempt a good faith effort, and We will drop your lowest homework grade.    What is a \u0026ldquo;good faith effort\u0026rdquo;?    Simply submitting nonsense or saying ‚ÄúI can‚Äôt do this‚Äù for each problem will not meet our criteria for a good faith effort, because there is no attempt on your part to show us why you are struggling, what you tried but didn‚Äôt work, what specific part of the problem you got stuck on, which other examples in the text/lecture you tried to work through to get a grasp on the problem, etc. ^[This is especially true if you don‚Äôt attend any office hours, post on Sakai, or otherwise seek out help before the due date.] The good faith effort is just that- we are interested in seeing evidence of a diligent and honest effort on your part, made with deliberate intention, to understand the problem and attempt an answer.\n In the talk I gave at JSM, I talked about self-assessments as just one out of three strategies I used to get students talking about data science. My students often had a final project and/or presentation at the end of a course, which I also think helps them to think out loud and on their feet. I sincerely hope other educators try these kinds of methods out! I can honestly say I wouldn\u0026rsquo;t teach a university-level course any other way.\nFigure 8: All three strategies\n ","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"62fe2ea576acb983fdf8491fd10d2f41","permalink":"https://maggie-98.github.io/post/2020-12-13-self-assessments/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/2020-12-13-self-assessments/","section":"post","summary":"How I used self-reflection to boost student learning and engagement.","tags":["teaching"],"title":"Teaching students to talk about data science","type":"post"},{"authors":["alison"],"categories":["blogdown","hugo"],"content":"Greetings and happy holidays! As many folks are looking forward to down time over the holidays, my inbox naturally starts filling in with questions like \u0026ldquo;What is the difference between blogdown and X?\u0026rdquo;, \u0026ldquo;How hard is Hugo to learn?\u0026rdquo;, and \u0026ldquo;Which Hugo theme do you recommend?\u0026rdquo; These are all great questions. But the best one in my mind that one needs to ask is:\n \u0026ldquo;How much Hugo do I need to know right now?\u0026rdquo;\n And the answer, of course, depends on where you are starting from and where you\u0026rsquo;d like to end up.\nIn this post, I\u0026rsquo;ll share when and why I think a typical R blogdown user needs to learn Hugo. I\u0026rsquo;ll tell you a secret: I enjoyed learning Hugo. But I learned blogdown first, and frankly was blissfully unaware of the complexity of the underlying Hugo templating language. I was a happy blogdown user for about 1.5 years before taking the plunge to actually learn Hugo. Why did I do it? I needed to build a website for the RStudio Education team, and for sustainability and maintenance, I had been burned by external themes in various ways too many times for my personal site.\nWe decided as a team that we didn\u0026rsquo;t want our site to depend on a third-party Hugo theme. What can go wrong with using third-party Hugo themes? For one, if you choose a not very active or well-maintained theme, then you could get stuck with a not well-maintained theme. Or worse, your theme could get orphaned, with no maintainer. But, on the flip-side, if you pick a very active and well-maintained theme, you might find yourself dealing with theme and Hugo updates more than you would like (cough cough like the Wowchemy/Academic theme).\nThe tidyverse.org site was built with a lot of custom HTML, CSS, and some Hugo layout files. I decided to turn that site into a real Hugo theme, and use that theme across teams. You may not have noticed any change when we switched to the new theme- at least I hope you didn\u0026rsquo;t! That site and the RStudio Education site both use the same Hugo theme I built.\nNow that I\u0026rsquo;ve gone from casual Hugo user to theme developer, I have some advice. Generally, as a blanket rule, here is what you should and should not touch:\nAn #rstats #blogdown file hierarchy cheatsheet:\n‚îú‚îÄ archetypes \u0026lt;- edit me! ‚îú‚îÄ config.toml \u0026lt;- edit me! ‚îú‚îÄ content \u0026lt;- edit me! ‚îú‚îÄ data \u0026lt;- edit me! ‚îú‚îÄ layouts \u0026lt;- edit me! ‚îú‚îÄ public \u0026lt;- ignore me!\n‚îú‚îÄ static \u0026lt;- use me! (png/pdf/csv/xls)\n‚îú‚îÄ themes \u0026lt;- don\u0026#39;t touch! pic.twitter.com/gvVA703Lwa\n\u0026mdash; Alison Hill (@apreshill) December 28, 2018   But what can you do with blogdown before learning Hugo? When and how do you know when you need to get to know Hugo better? Hopefully this post will help answer these questions.\nInspired by Jenny Bryan\u0026rsquo;s talk on lazy evaluation, I\u0026rsquo;m framing these learning decision points based on what you want to get done.\nYou want to: make a website with blogdown     You need to know this much Hugo: Hugo takes a collection of files (called content) and generates a collection of static HTML files as a single, cohesive, navigable website (plopped in your public/ folder). How it looks depends on which Hugo theme you pick r emo::ji(\u0026quot;paint\u0026quot;)\n You\u0026rsquo;ll need to:\n  pick a Hugo theme, which dictates the style and layout of your content.  build and serve your site locally. deploy your site! If you are just starting out, I recommend everyone starts by first dragging and dropping your project\u0026rsquo;s public/ folder into Netlify. There is your site r emo::ji(\u0026quot;boom\u0026quot;). With a link. That you can send to your best friend right now.  realize this is a static site. Read up on static sites!  But you probably want to do more\u0026hellip;\nYou want to: customize your site     You need to know this much more Hugo: Hugo themes typically use one or more metadata files (TOML or YAML) to set up global variables to use to build your site. This is usually the way to add a site url, a site name, link social accounts for personal websites, basically take any of the default content you see and customize it for you.\n The main files to edit are:\n  configuration files  To get familiar with TOML, I recommend:\n  a brief intro from the blogdown book, and  Learn TOML in Y Minutes.  But, since the time we published the blogdown book, Hugo introduced configuration directories, which allowed us to no longer have one giant config.toml file, and instead have multiple configuration files, like this:\n‚îú‚îÄ‚îÄ config.toml \u0026lt;- Hugo-defined variables ‚îú‚îÄ‚îÄ config ‚îÇ ‚îú‚îÄ‚îÄ _default ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ menus.toml \u0026lt;- menus :) ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ params.toml \u0026lt;- theme-specific variables  Here is how you can think of these:\n  config.toml/config.yaml: your most direct communication with Hugo. These are standard Hugo-defined variables that have defaults you can override in this file. You can view all of them here. These are universal across themes.\n  menus.toml: your way of editing the content in a side or upper navigation menu bar; see example here. These work the same way across themes (with the exception of drop-down menus, which work in some themes but not others).\n  params.toml: your theme\u0026rsquo;s way of providing an API for Hugo. These are variables that your theme creator has made for you! This is a gift, but not the kind you can re-gift easily. This file will not work with any other theme.\n  If your theme uses only a single config.toml file, you can infer these subsections as you scroll down:\n# before the first use of [[]] # are all the Hugo variables # Menu Configuration- same as menus.toml [[menu.main]] # Theme Configuration- same as params.toml [params]  You still don\u0026rsquo;t need to learn Hugo\u0026hellip;yet.\nYou want to: add content to your site     You need to know this much more Hugo: Remember how the input to Hugo is a \u0026ldquo;collection of files\u0026rdquo;? The input is more specifically a collection of markdown files. Hugo themes use content written in markdown files (for blogdown users, R Markdown files work too) to generate your site\u0026rsquo;s content; with one very important rule ‚Äî the same structure that works to organize your site content is used to organize the rendered site.\n But, what does that mean?\nThe main files to edit are:\n files in the content/ folder (and see my post on page bundles)  First, the structure and the names inside your content/ folder is meaningful. The names of each folder determine what Hugo layout will be applied. Why do you care? If you change the content name, things may not look good because Hugo can\u0026rsquo;t find the right layout. Think of your site like going to a party at a friend\u0026rsquo;s house- you can bring food, wine, maybe a board game- your host knows what to do with these things. But if you bring a monkey, for example, your host has no idea what to do with it!\nYuo can override this by adding a layout key to your file\u0026rsquo;s YAML, as described here. The relevant bit is here:\n \u0026ldquo;layout: the layout Hugo should select from the lookup order when rendering the content. If a type is not specified in the front matter, Hugo will look for the layout of the same name in the layout directory that corresponds with a content‚Äôs section.\u0026rdquo;\n The subfolders also tell you where you can find your content on your site.\n. ‚îú‚îÄ‚îÄ content/ ‚îÇ ‚îú‚îÄ‚îÄ authors/ # =\u0026gt; https://example.com/authors/ ‚îÇ ‚îú‚îÄ‚îÄ privacy/index.md # =\u0026gt; https://example.com/privacy/ ‚îÇ ‚îî‚îÄ‚îÄ home/ # =\u0026gt; https://example.com/  You should take a bit of time to get the \u0026ldquo;cook\u0026rsquo;s tour\u0026rdquo; of your site. Try looking at each file and guessing the URL you\u0026rsquo;ll use to see it in the rendered site. Do this now and it will become like second nature.\nYou\u0026rsquo;ll no doubt run into one question: what is the difference between index.md and _index.md files? index.md are simple pages; the single file goes into the site and a single file comes back out when you view the site. This is called a leaf bundle in Hugo.\n. ‚îú‚îÄ‚îÄ content/ ‚îÇ ‚îú‚îÄ‚îÄ privacy/index.md # =\u0026gt; a leaf bundle ‚îÇ ‚îî‚îÄ‚îÄ blog/ # =\u0026gt; a branch bundle ‚îÇ ‚îú‚îÄ‚îÄ _index.md # =\u0026gt; AHA! ‚îÇ ‚îú‚îÄ‚îÄ gorillas/index.md # =\u0026gt; a leaf bundle ‚îÇ ‚îú‚îÄ‚îÄ baboons/index.md # =\u0026gt; another leaf bundle ‚îÇ ‚îî‚îÄ‚îÄ monkeys/index.md # =\u0026gt; yet another leaf bundle  An _index.md file, on the other hand, signals that this folder has a listing page activated. This is called a branch bundle in Hugo. Listing pages are a bit magical, so make sure you understand them now. Typically, if you edit the _index.md file at all, you edit the YAML of this file- often the page content below the YAML isn\u0026rsquo;t revealed by the theme (this is a bit hand-wavy and I\u0026rsquo;m sorry for that).\nSo if you have content/blog/gorillas/index.md, you get not one but two pages. Let\u0026rsquo;s pretend my baseurl is alison.rbind.io. You get a list page that will render at alison.rbind.io/blog/, and indexes all the index.md files inside that content folder. You also get a single page that will render at alison.rbind.io/blog/gorillas/, which shows you the full content of the index.md file.\nYou want to: customize colors and fonts on your site     You need to know this much more Hugo: It depends on your theme :) You may need to learn CSS, and you may need to learn to read Hugo now.\n Many Hugo themes enable users to edit aesthetic elements like colors and fonts. So, depending on your Hugo theme, you may not need to know CSS. Other themes provide a way to ‚Äúplug in‚Äù a custom CSS file to change those things and more (like spacing, font sizing, etc.). Guess where that is? Usually it is in your config.toml file in the [params] section (if no configuration directory) or the params.toml file. The theme author should leave you a breadcrumb to figure out what you should name and where you should place your custom CSS file.\nFor example, the Hugo academic theme provides a few ways in. In the params.toml file, you can use an included site color theme or make your own, and customize your fonts. You can also provide your own custom CSS file by including it here: https://github.com/gcushen/hugo-academic/blob/master/assets/scss/custom.scss\nIf your theme doesn\u0026rsquo;t provide this level of support, then you may need to learn Hugo. Sometimes the options are tough to find, unfortunately, but many theme designers provide at least a plug-in option. Others may require you to dig into some of your theme\u0026rsquo;s partial layouts (i.e., themes/theme_name/layouts/partials/) and learn to read them. Here are some examples:\n  Plug-in CSS: Hugo Tranquil Peak theme tells you to place the file inside your static/ folder then provide the path and filename in the config.toml file:\n[params] # Custom CSS. Put here your custom CSS files. They are loaded after the theme CSS; # they have to be referred from static root. Example # [[params.customCSS]] # href = \u0026quot;css/mystyle.css\u0026quot; \u0026lt;- AHA!    Go Fish: Hugo I Am Sam theme doesn\u0026rsquo;t give you this in the config.toml file, but looking at one of the layout partials you can see that the theme is actually built to plug-in your custom CSS:\n\u0026lt;!-- Custom css --\u0026gt; {{ range .Site.Params.customCSS -}} \u0026lt;- AHA! {{ $style := resources.Get . }} \u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;{{ $style.RelPermalink }}\u0026quot; integrity=\u0026quot;{{ $style.Data.Integrity }}\u0026quot; crossorigin=\u0026quot;anonymous\u0026quot; media=\u0026quot;screen\u0026quot;\u0026gt; {{- end }}    You want to: renovate the layout of content on your site     You need to know this much more Hugo: You need to learn to use Hugo variables.\n I say renovate, but these can be anywhere from small to big renovation projects. The key word here is renovate, which in Hugo world, means you want to override your site\u0026rsquo;s theme. Let\u0026rsquo;s say you want different information to show up in your site\u0026rsquo;s footer. Or maybe you want add something new to the metadata for your blog posts.\nHere is a great blog post to get you started:\n  Override a Hugo theme  tl;dr: If you adapt your existing theme\u0026rsquo;s Hugo layout files, be sure to make a copy of the layout you want to edit first and add it to your project root\u0026rsquo;s layouts/ folder before editing. Please do not edit any files anywhere in your themes/ folder.\nNow, the hardest part of doing is often figuring out which layout file is the one you need to edit. Often you\u0026rsquo;ll need to do some digging to figure out which file is the one to touch.\n. ‚îú‚îÄ‚îÄ layouts/ ‚îÇ ‚îú‚îÄ‚îÄ _default/ # edit me! ‚îÇ ‚îú‚îÄ‚îÄ authors/ # edit me! ‚îÇ ‚îî‚îÄ‚îÄ partials/ # edit me! ‚îú‚îÄ‚îÄ themes/ ‚îÇ ‚îú‚îÄ‚îÄ theme_name/ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ layouts ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ _default/ # do not touch ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ authors/ # do not touch (seriously) ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ partials/ # `r emo::ji(\u0026quot;fire\u0026quot;)`  You\u0026rsquo;ll also want to learn about Hugo variables, especially:\n  Site variables  The .Site.Params variable  Page variables  The .Param method for page variables  You also might need to understand Hugo logic like:\n  iteration and  conditionals   Important: I learned this the hard way, but you cannot wrap your Hugo code in HTML comments to deactivate it; all Hugo code even inside of HTML comments will still be evaluated when you build your site.   You want to: create your own Hugo theme     You need to know this much more Hugo: Welcome to the wizarding world of Hugo! r emo::ji(\u0026quot;wizard\u0026quot;) You now need to learn to write Hugo templates.\n Here are some resources for writing Hugo templates:\n  Context (aka ‚Äúthe dot‚Äù)   Hugo, the scope, the context and the dot  Lookup order  Base templates  Single page templates  List page templates  These resources were especially helpful to me:\n The blogdown book section on templates The blogdown book section on customizing layouts The Hugo docs are pretty strong  Make a Hugo blog from scratch | zwbetz  Hugo Community Discourse Forum  All of Mike Dane\u0026rsquo;s Hugo tutorials  I spent a lot of time looking at other Hugo themes; here are some quality ones to learn from:\n   Ma√´lle Salmon\u0026rsquo;s ROpenSci Hugo theme: https://github.com/ropensci/roweb2/tree/master/themes/ropensci\n   Amber Thomas\u0026rsquo;s Data Science Hugo theme: https://github.com/ProQuestionAsker/hugo-data-science\n   Danielle Navarro\u0026rsquo;s slum Hugo theme: https://github.com/djnavarro/hugo-slum\n  My own humble Hugo theme: https://github.com/rstudio/hugo-graphite\n   Again, this is all just based on my own experiences- your mileage may vary as always.\n","date":1607731200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607731200,"objectID":"82a33d34c9c7f338f4bc0ba22d5546a2","permalink":"https://maggie-98.github.io/post/2020-12-12-how-much-hugo/","publishdate":"2020-12-12T00:00:00Z","relpermalink":"/post/2020-12-12-how-much-hugo/","section":"post","summary":"When and why you need to learn Hugo as an R blogdown user.","tags":["blogdown","hugo"],"title":"A Spoonful of Hugo: How much Hugo do I need to know?","type":"post"},{"authors":["alison"],"categories":["talk"],"content":"The R Markdown family of packages has grown a lot over the past few years! While each new package is truly a bundle of joy, the past few months we have worked hard to make our family of existing packages more consistent, supportive, and intuitive. In this talk, I‚Äôll share some of what we are up to lately and what to expect, with highlights from the distill, blogdown, bookdown, and xaringan packages.\n","date":1607459400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607459400,"objectID":"669b0a3d82782f482ee701cf74ba0338","permalink":"https://maggie-98.github.io/talk/2020-larug/","publishdate":"2020-02-01T00:00:00Z","relpermalink":"/talk/2020-larug/","section":"talk","summary":"Recent updates in the R Markdown family","tags":["rmarkdown"],"title":"The download","type":"talk"},{"authors":null,"categories":["R"],"content":" R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932  Including Plots You can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;), col = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;), init.angle = -50, border = NA )  Figure 1: A fancy pie chart.   ","date":1606875194,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606875194,"objectID":"bf1eb249db79f10ace7d22321494165a","permalink":"https://maggie-98.github.io/post/2020-12-01-r-rmarkdown/","publishdate":"2020-12-01T21:13:14-05:00","relpermalink":"/post/2020-12-01-r-rmarkdown/","section":"post","summary":"R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.","tags":["R Markdown","plot","regression"],"title":"Hello R Markdown","type":"post"},{"authors":["alison"],"categories":["talk"],"content":"Someone in your department, company, or class comes to you and says: \u0026ldquo;I want to learn R; where do I start?\u0026rdquo; Or, \u0026ldquo;how do I take my R skills to the next level?\u0026rdquo;\nCome hear from 3 R-Ladies on how to make R pedagogy work for different groups of people!\n","date":1605171600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605171600,"objectID":"cfb269de70323cf143f0f936ef198fd0","permalink":"https://maggie-98.github.io/talk/2020-rladies-chicago-panel/","publishdate":"2020-11-12T09:00:00Z","relpermalink":"/talk/2020-rladies-chicago-panel/","section":"talk","summary":"Come hear from 3 R-Ladies on how to make R pedagogy work for different groups of people!","tags":["teaching"],"title":"InspiRing InstRuction: A panel on teaching #rstats for all audiences","type":"talk"},{"authors":null,"categories":null,"content":"","date":1604188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604188800,"objectID":"2cb67d83b78a7f1203725af8ed4b934b","permalink":"https://maggie-98.github.io/project/distill/","publishdate":"2020-11-01T00:00:00Z","relpermalink":"/project/distill/","section":"project","summary":"Distill for R Markdown is a web publishing format optimized for scientific and technical communication.","tags":["R","software"],"title":"distill","type":"project"},{"authors":null,"categories":["workshop"],"content":"A four-hour workshop that will take you on a tour of how to get from data to manuscript using R Markdown. You\u0026rsquo;ll learn:\n  The basics of Markdown and knitr\n  How to add tables for different outputs\n  Workflows for working with data\n  How to include and style graphics\n  Presented with Tom Mock from RStudio.\n","date":1602075600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560676801,"objectID":"447628219676c5f360e9147b0263f7b3","permalink":"https://maggie-98.github.io/talk/2020-rmd4pharma/","publishdate":"2020-02-01T00:00:00Z","relpermalink":"/talk/2020-rmd4pharma/","section":"talk","summary":"A four-hour workshop for R / Pharma 2020 that will take you on a tour of how to get from data to manuscript using R Markdown.","tags":["rmarkdown"],"title":"R Markdown for Pharma","type":"talk"},{"authors":["alison"],"categories":["talk"],"content":"In this talk, I shared my experiences learning new data science skills on my own, and some broader strategies for learning when you have to do it by yourself.\n","date":1602061200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602061200,"objectID":"ece9a543a478def493a7ab468047d4ac","permalink":"https://maggie-98.github.io/talk/2020-latinr-learn/","publishdate":"2020-10-07T09:00:00Z","relpermalink":"/talk/2020-latinr-learn/","section":"talk","summary":"Aprendiendo sin una red","tags":["learning","teaching"],"title":"Learning without a net","type":"talk"},{"authors":["alison"],"categories":["talk"],"content":"This goal of this workshop is to equip educators with the tools that can help them make their teaching more robust and reproducible with R Markdown.\nTrainings offered:\n 2020-09-23 2020-09-20  ","date":1600851600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600851600,"objectID":"cc3ab40be08fa09a547815cbd94e7ff6","permalink":"https://maggie-98.github.io/talk/2020-rstudio-tip/","publishdate":"2020-09-23T09:00:00Z","relpermalink":"/talk/2020-rstudio-tip/","section":"talk","summary":"A 2-hour workshop for RStudio certified trainers on how to make shareable slides and websites with R Markdown.","tags":["learning","teaching","rmarkdown","xaringan","distill"],"title":"Teaching in Production","type":"talk"},{"authors":null,"categories":null,"content":"","date":1600819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600819200,"objectID":"2e252418e8c6969e0d859cabd4969dc9","permalink":"https://maggie-98.github.io/project/rstudio-tip/","publishdate":"2020-09-23T00:00:00Z","relpermalink":"/project/rstudio-tip/","section":"project","summary":"A 2-hour workshop for RStudio certified trainers on how to make shareable slides and websites with R Markdown.","tags":["R","workshop"],"title":"RStudio Teaching in Production","type":"project"},{"authors":null,"categories":["workshop"],"content":"This four-hour workshop will provide a gentle introduction to machine learning with R using the modern suite of predictive modeling packages called tidymodels. We will build, evaluate, compare, and tune predictive models. Along the way, we‚Äôll learn about key concepts in machine learning including overfitting, the holdout method, the bias-variance trade-off, ensembling, cross-validation, and feature engineering. Learners will gain knowledge about good predictive modeling practices, as well as hands-on experience using tidymodels packages like parsnip, rsample, recipes, yardstick, tune, and workflows.\nThe workshop was adapted from a 2-day in-person workshop delivered at rstudio::conf(2020) in San Francisco, CA.\n","date":1598533200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560676801,"objectID":"5da95cd3b22cc8c5051aa68fda25ac3e","permalink":"https://maggie-98.github.io/talk/2020-rmedicine-tidyml/","publishdate":"2020-02-01T00:00:00Z","relpermalink":"/talk/2020-rmedicine-tidyml/","section":"talk","summary":"R / Medicine 2020: A 4-hour workshop to introduce the basics of machine learning in R using tidymodels.","tags":["tidymodels","machine learning"],"title":"Introduction to Machine Learning with the Tidyverse","type":"talk"},{"authors":null,"categories":null,"content":"","date":1591833600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591833600,"objectID":"e41cf5868d81db6f94bc8bdd4163fc6b","permalink":"https://maggie-98.github.io/project/palmerpenguins/","publishdate":"2020-06-11T00:00:00Z","relpermalink":"/project/palmerpenguins/","section":"project","summary":"An R data package with data about 3 penguin species from the Palmer Station in Antarctica","tags":["R","software"],"title":"palmerpenguins","type":"project"},{"authors":[],"categories":[],"content":"A few weeks ago, I wrapped up teaching tidymodels for the third time. We say third time\u0026rsquo;s the charm, right? Even during a global pandemic? I don\u0026rsquo;t know, but this time around was fun in new ways and hard in new ways, so I wanted to take the time to write some thoughts down about how it went.\nBut why?    Why teach tidymodels virtually? I\u0026rsquo;ve already taught it as a 2-day workshop at rstudio::conf(2020). I had already agreed to teach intro to machine learning with tidymodels as a full-day workshop for the Cascadia R Conf (which unfortunately was cancelled due to COVID), and the R / Medicine conference (still on, and 100% virtual!).\nI had three main goals:\n First, I wanted to do a good job for the R / Medicine conference workshop in August. This seemed like an interesting teaching challenge. One of the best compliments I\u0026rsquo;ve ever gotten from a colleague is that I \u0026ldquo;teach with heart\u0026rdquo; ‚Äî so the challenge was, can a virtual workshop have a ‚ù§Ô∏è?    Second, given current events, I saw an opportunity to document a good system (tooling + pedagogy + logistics) around virtual workshops. I don\u0026rsquo;t see them going away anytime soon. My colleague, Greg Wilson, had also been giving our RStudio certified instructor workshops virtually for over a year, so I trusted that he could help me navigate.\n  Third, help out the R / Medicine conference organizers. My partner-in-crime for this particular workshop, Dr. Stephan Kadauke, wanted to join me for some reconnaissance work. He is one of the conference organizers and will be leading his own workshop there, so he wanted to test out the tooling and the pedagogy too.\n  So we thought, three birds, one stone: I get to pilot a much shorter version of my conf workshop materials, we get to test doing it virtually, and the R / Medicine conference organizers learn how this could all work in August.\nHow we planned it    Starting out, I knew I had two main hurdles:\n Shaving two days of workshop content into X days Logistics (like figuring out what X should be!)  The first decision based on conversations with Greg was to offer the workshop across two half-days. This is how the RStudio instructor training is timed, and it works well because there are few people who can (or want to) be tied up for a full day, especially if under stay-at-home orders. We asked Stephan if his group at the Children\u0026rsquo;s Hospital of Philadelphia (CHOP) would be up for two 4-hour sessions. Stephan\u0026rsquo;s feedback was yes, but given that these folks at CHOP typically have weekly schedules, having two consecutive days would not work. So we opted for:\n Two 4-hour sessions that were\u0026hellip; exactly one week apart.  I\u0026rsquo;m in Oregon, they were in Philly, so we decided to start at 9am my time (1pm for them) and wrap up at 1pm my time (5pm for them). After making this call, and again with Greg\u0026rsquo;s sage advice to take a break every hour, I started working on a rough schedule. I had about 8 hours total to work with; about half of my conf workshop. We decided on:\n 50 minute chunks, and 10 minute breaks at 10 till the hour every single hour.  I didn\u0026rsquo;t try to make sure my materials for each session filled exactly 50 minutes. Instead, I promised the group that I would break wherever I was at the same time, and after each break we just picked up where left off.\nHere was the new topic outline:\nDay 1      Session 00: Intro (include a tooling tour- orient to Google doc + Zoom)  Session 01: Build a model (mainly parsnip package)  Session 02: Resample a model (add rsample package, plus tune package for fit_resamples())  Session 03: Build a better training set (add recipes and workflows packages)  Day 2      Session 04: Build an ensemble model (back to parsnip, now with model arguments)  Session 05: Tune a model (heavy tune package)  Session 06: The Great Model-Off (a Kaggle-like group activity)  The final decision was about tooling. Luckily, Greg had advice here too. We went with:\n Google doc as the \u0026ldquo;home page\u0026rdquo; + chat (no workshop website!) RStudio Cloud for all exercises Zoom for video  Pre-workshop launch list     Make shared Google doc and prepopulate with: Zoom link, RStudio Cloud link, bulleted list of participant names (be sure to make this editable for anyone!) Email everyone with a Google calendar invite that includes the Zoom link and a link to a shared Google doc (be sure to make this editable for anyone!) Ask everyone to fill in their 2-sentence bios ahead of time to ensure that you\u0026rsquo;ve done this correctly!  The Zoom link and the Google doc link should be the only links that attendees see ahead of time. Then, the Google doc is the one true source for everything. Too many links at first leads to confusion later. I also prepopulated the doc with my session outline with HTML links to each session\u0026rsquo;s slide deck.\nActual launch    In Zoom, I set it up to mute everyone as they joined. We started with an orientation of the tools, the schedule, and the general plan for how they would work and interact with each other. We tried to keep questions per session in the Google doc, which my TA Stephan fielded in real time, which now is a great resource for me as I prepare for this again in August.\nWhat I should have done:\n Have a Code of Conduct. I will next time. We didn\u0026rsquo;t have any issues, but what came up later was that I asked participants to turn on their cameras. I wished that part of my Code of Conduct was that we would not videotape or take screenshots at any point to protect the privacy of all participants. Asked folks to make sure they had an updated version of Zoom. In particular, some newer security issues have been addressed recently, so this is nice for everyone to take advantage of. Plus the interface looked different for some. Locked down the Zoom room. After a few minutes of starting, it was super distracting to have late arrivals who kept sending me personal chats asking for the links. In addition to locking down after the first 10-15 minutes, I also should have assigned my TA as a co-host, so that he could have helped me manage that. We did this on day 2 and it worked great.  How did it go?    So, I\u0026rsquo;m not going to lie here. The first session of teaching spooked me a bit. This was because all attendees left their videos off and I felt like:\nIt was eerie to teach to a silent void. On day 2, I asked for two volunteers to turn on their cameras for a single 50 minute block each because it really helped me to see faces. Participants probably kept their own view as \u0026ldquo;speaker only\u0026rdquo;, but for me it really helped to be able to have some human feedback, even if they were muted. Much love to the head nodders out there. This conversation on day 2 broke my heart though, because several participants indicated they felt they couldn\u0026rsquo;t turn on their cameras because they had young children at home. It is hard.\nInterestingly, the participants didn\u0026rsquo;t sense my discomfort at all. In fact, I heard from several that it was nice to see me up close and so personal. It actually felt more personal than a large in-person workshop, to my surprise.\nOn day 1, I started by asking participants to use Zoom reactions (like thumbs up) to answer questions, give me progress updates, etc. I ended up retiring this- it was distracting and the reactions disappear so it wasn\u0026rsquo;t actually useful. Instead, I asked people to use the Zoom chat to indicate \u0026ldquo;done\u0026rdquo; or give quick one-word answers (a or b, yes or no).\nStephan also had a great idea for the breaks. On day 2, I started using Garrick Aden-Buie\u0026rsquo;s countdown app to show the 10 minute break countdown full-screen. I used the hosted version here.\nWhat can I do better?    Logistically, I got really frustrated because I kept losing my Zoom meeting controls. Later I found out about this accessibility setting, which would have helped!\nMore substantively, as I mentioned, I would have a Code of Conduct at the very beginning. I also think virtual workshops offer a unique opportunity to include some more creative exercise types. Here are a few I brainstormed with Greg Wilson after the fact‚Äîexpect to see these at R / Medicine if you attend with me!\n  Spot the bug- do in groups\n  Unscramble code\n  Predict what is going to happen\n  Fill in the blank with the flair package\n  Verdict    Transitioning from primarily teaching in person to teaching virtually is hard, and I\u0026rsquo;m in awe of all the instructors I know who have had to do this on very short notice. But, can it be done with heart? Yes, I think so ‚ù§Ô∏è\nThanks    Thanks to the participants, who were the loveliest guinea pigs. It is a hard time to learn and a hard time to find time. I appreciate that you took time out of your lives to spend 8 hours with me.\nThanks also to Greg Wilson for his support, and Stephan Kadauke for being an awesome co-pilot. Extra special thanks to Desir√©e De Leon, who has the biggest heart of all. Knowing that I didn\u0026rsquo;t have time for creativity with my slides, she surprised me with the most beautiful xaringan slide deck theme based on tidymodels.org. I merged in her PR with glee and delight, I know the participants felt those same emotions too (while learning about machine learning, no less!) üåº\n      Feedback    If you are curious, here is some of the feedback I collected at the bottom of our Google doc:\nTwo half days?     worked well for me. A full day would be tough. Worked well for me also and I also think having all in one day would be a lot. worked well. worked well for me too.  Separated by one week?     seemed fine. I liked this! good. Enough time to digest the previous session yes.  Pace: too fast, too slow?     good pace I liked the pace. It felt like we covered a lot of ground quickly, but also like we have great resources to come back to for refreshing on what we learned. good pace, except at ‚Äúdata leakage‚Äù. I still have hard time to understand that part. good pace.  Scope: too small, too big?     nice scope Nice scope very nice and practical. nice scope.  Timing in 50 min chunks: too many or too few breaks?     The 50 min chunks were great! I thought perfect length. Perfect break up. And the 10 min breaks gave enough time to make tea, grab a snack, etc. I am fine with that. works well.  Timed code exercises: too easy, too hard?     good Neither, I thought they were appropriate good. good.  In-between homework/reading?     maybe some light reading or practice In theory I think I would have liked some ‚Äòhomework‚Äô, but the week turned out to be so busy that I don‚Äôt know if I would‚Äôve made time to complete it before the workshop. will be helpful to give some reading about different model descriptions in-between.  Final take-home project (+/- feedback)?     optional I think this could be fun if we had access to a few different datasets to choose from. With maybe some pointers on what to look out for as we explore the data. Is it unbalanced? Could any two variables be collinear? Etc. i would vote for take-home project to play with.  Zoom: video on/off?     I find video distracting while working/listening/learning. I like being able to see the presenter/speaker‚Äôs video. I tend to choose ‚ÄúSpeaker View‚Äù so that I don‚Äôt see all the participant videos (which I would find distracting). i am fine with either. I know, from the speaker‚Äôs perspective, it will be good to have video on. I think it was nice and respectful to ask volunteers to turn video on part time! (Kudos to Stephan for having it on the whole time!)  Google doc as our ‚Äúhome page‚Äù and ‚Äúdiscussion forum‚Äù?     Great! Yes! I thought it was a really helpful tool and ‚Äòhomebase‚Äô to come to for all of the things (slides, R Studio Cloud project, etc.) very good! Much easier to track. works!  Rstudio.cloud?     pretty good except for crashing at end. ditto. I really enjoyed using R Studio Cloud. It makes it easier when I don‚Äôt have to worry about pre-installing packages or updating my version of R in order to go into a workshop. Having everything already set up for you in there is super convenient. I like Rstudio cloud generally. Just not suitable for complicated model training.  ","date":1591056000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591056000,"objectID":"e55fbb1e1fbfd9c7d301525253850c35","permalink":"https://maggie-98.github.io/post/2020-06-02-tidymodels-virtually/","publishdate":"2020-06-02T00:00:00Z","relpermalink":"/post/2020-06-02-tidymodels-virtually/","section":"post","summary":"Some reflections on my third time teaching tidymodels for machine learning, and doing it virtually.","tags":["rmarkdown"],"title":"How I Taught Tidymodels, Virtually","type":"post"},{"authors":[],"categories":[],"content":"Ah, R Markdown. I love teaching R Markdown. But this was not a love at first sight story. When I first started teaching with R at Oregon Health \u0026amp; Science University many moons ago, my students used R Markdown for their homework assignments and in-class labs. This is a great way to start for beginners, to be honest- just use it! I found that most people are not very disoriented by a file that mixes text and code; a concern I had at first and one that I\u0026rsquo;ve heard voiced by other educators. It seems natural to use if it is your first exposure to all the data science things, especially if you\u0026rsquo;ve never used an R script.\nI did notice, though, that over the course of even just a few weeks, many of my students would reach unbearable levels of R Markdown curiosity. I would see signs of growing pains in their assignments, like how can I turn off these messages and warnings when I load packages? This is so long- how can I make it easier to find things? How can I make it look better?\nFor all learners, there comes an uncomfortable point where you simply cannot just continue to use this awesome tool without learning how to use it. And I realized when I was teaching that ultimately it was unfair of me to assume that they would just learn an entire ecosystem while I stood idly by, clutching the secrets of being an \u0026ldquo;R Markdown Whisperer\u0026rdquo; close to my chest.\nLike, why can\u0026rsquo;t you just find the pi√±ata, kid? But more importantly, what happens when you can\u0026rsquo;t? I think the risk is that learners either won\u0026rsquo;t like or won\u0026rsquo;t appreciate a tool that I genuinely think would make their working lives better. If I believed it was worth their time to use it, it was worth my time to teach it.\nSo like any good educator, I evolved. I decided that the next year, I would teach R Markdown. And I did. I went from:\n \u0026ldquo;Just use it\u0026rdquo;\n To:\n \u0026ldquo;Just tell them how to use it already\u0026rdquo;\n I waited until a few weeks into a quarter, and I spent a full lab period walking students through \u0026ldquo;Hey- this bit where you put the title of each assignment and your name? That\u0026rsquo;s called YAML! Here is what it does\u0026hellip;\u0026rdquo; I showed them how to use bootswatch themes, make a floating table of contents, control their output using the power of knitr code chunks and chunk options.\nGuess what happened? The next batch of assignment my TA team and I received were\u0026hellip;stunning. Creative. Beautiful. Thoughtful and thought-provoking. Students had taken care with their markdown headers, they played with flatly/yeti/united, they cared about not printing the giant output of a code chunk. It was a thing of beauty. I remember one of my beloved TAs, Grace Lawley, commenting that one star student\u0026rsquo;s homework \u0026ldquo;brought tears to her eyes\u0026rdquo; (and yes, I trained Grace too as she was also my research assistant, so she was already baptized into the R Markdown family).\nBut I have to admit, the first time I taught it, I had a hard time teaching it! I realized that I lacked vocabulary around things I used everyday, but had never really talked about out loud with anyone in words.\nNow, in my role at RStudio, I\u0026rsquo;ve devoted a lot of time and energy trying to figure out how we can make R Markdown easier- easier to discover, easier to debug, easier to use, and easier to talk about.\nSo without further ado, here are some of my guiding principles when introducing R Markdown to beginners, for those who are ready to go beyond casual knitter:\n#1. Make it. Make it again.    Knit early. Knit often. That means starting with a pre-filled Rmd document usually that you know will knit. How do you motivate repeated knitting and make it satisfying? Teach the basics of output formats and options by editing mainly the YAML. Your goal is to show how small effort \u0026ndash;\u0026gt; high polish. For single docs, I love html_document() with a floating table of contents and a theme (like this), switching quickly to bookdown::html_document2() and distill::distill_article(). The latter two also enable automated figure numbering, which for scientific audiences is quite nice!\nYou can do something like this with #rmarkdown. Ask students to knit to HTML, then use the bootswatch themes https://t.co/J9ucdRWnIl\nBonus: you get the prettiest #rstats homeworks after this! üíêüñçÔ∏è\n---\ntitle: \u0026quot;Habits\u0026quot; output: html_document: theme: flatly\n--- https://t.co/wMQ3Uqhc7s\n\u0026mdash; Alison Presmanes Hill (@apreshill) March 2, 2019  Bonus when using a theme with html_document(): show off the code_download output option!\nTIL you can embed a \u0026quot;code download\u0026quot; button in an HTML #rmarkdown doc so that users can click to download your source .Rmd from the rendered HTML version...without GitHub ü§© #rstats\nYAML:\n---\noutput:\nhtml_document:\ncode_download: true\n---\nTest: https://t.co/bp7w7XKF8b pic.twitter.com/uMQK0mvYcF\n\u0026mdash; Alison Presmanes Hill (@apreshill) March 22, 2019  #2. Make it pretty.    The starting Rmd should have a nice ggplot2 graphic in there, and maybe a pretty gt table too. This is a motivational, aspirational document! I also try to use local data sets, so they can see how that actually works, as opposed to using a data package.\nNever underestimate the power of being able to make pretty #rstats things. ‚¨ÜÔ∏è polish/effort ratio ‚û°Ô∏è happier users ü¶ö https://t.co/LMbFRUiuLa\n\u0026mdash; Alison Presmanes Hill (@apreshill) March 2, 2019  #3. Make it snappy.    I aim to get to a shareable link in the first 20 minutes (at most!). I like to use Netlify Drop for this. No account sign-up needed, and everyone knows how to drag-and-drop (see video below). It is very satisfying to get a link they can share with their mom/best friend/arch nemesis (kidding). I like to have everyone drop their links in a chat too, like a Slack, Google Doc, or a Gitter channel if doing a workshop. My favorite motto: \u0026ldquo;if it knits, it ships\u0026rdquo; üö¢\n #4. Make it real.    Teach folks what they need to know to actually use the tool productively in real life. If you are an avid R Markdown user, this means that you know without a doubt that file paths will eventually be painful, for example. At the end of an intro, I go back and highlight things I just used to make sure they notice them like R Projects and the here package for data importing. I also love a good \u0026ldquo;Your Turn\u0026rdquo; exercise where you get a fresh data dump and all they have to do is re-knit. As in, \u0026ldquo;Surprise! Now instead of 3 sites, you have data from all 6 sites- what do you do?\u0026rdquo;\n#5. Make it easy.    People will only keep using R Markdown if they see it making their life easier. So show them how. For example, the RStudio IDE has some very nice built-in features that make it much easier to be an R Markdown user. I point out things having a global setup chunk, and IDE features like:\nWhat do I save until later?      Rendering with render(). I think knitting in the RStudio IDE can get you very far- this I consider an intermediate to advanced concept that is confusing if introduced too early. I\u0026rsquo;ve never heard someone say \u0026ldquo;Well there is this simple button, but how can I do the same thing from the command line?\u0026quot;\n   Parameterized reports. I actually do use parameters though! I\u0026rsquo;ll have at least one or two often in one of my Rmds, and mention them briefly in my wrap-up. I teach parameters explicitly with actual exercises when I have \u0026gt; 1 hour.\n  Multiple Rmd output formats. I tend to start with single output formats first. If I have \u0026gt; 1.5 hours and it matches my learning objectives, then I happily oblige- I love teaching bookdown, blogdown, and distill websites. But to start, I stay single.\n  Markdown. I skim markdown, and always provide a link to an interactive tutorial. This one is my favorite. Teaching markdown can be\u0026hellip;dry. I show some bits on the slides because I cannot count on everyone doing the interactive tutorial ahead of time, but I do not linger much.\n  If you are curious to see some of the materials I\u0026rsquo;ve used to teach R Markdown, click on the rmarkdown button just below this post! üöÄ\nBut remember: there is no one way to learn R Markdown, and no one way to teach it either. I love seeing the creativity of the community when introducing the R Markdown family- so keep them coming!\n","date":1590624000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590723957,"objectID":"7d1fe277811e23f76aa70a96138d0418","permalink":"https://maggie-98.github.io/post/2020-05-28-how-i-teach-r-markdown/","publishdate":"2020-05-28T00:00:00Z","relpermalink":"/post/2020-05-28-how-i-teach-r-markdown/","section":"post","summary":"A handful of guiding principles for introducing beginners to the R Markdown family of packages.","tags":["rmarkdown"],"title":"How I Teach R Markdown","type":"post"},{"authors":null,"categories":["workshop"],"content":"R Markdown is an authoring format that enables easy creation of dynamic documents, presentations, and reports from R. It combines the core syntax of markdown with embedded R code chunks that are run so their output can be included in the final document. R Markdown documents are fully reproducible and can be updated whenever underlying R code or data changes.\nThis is a great opportunity to learn and get inspired about the capabilities for generating reports in R.\nThis session will introduce flexible and powerful tools for sharing your research and reports, covering topics like:\n The basics of R Markdown and knitting Output formats Working with data Adding text Adding code Adding tables Adding plots Options for sharing R Markdown reports  The talk will introduce R Markdown and include an overview of the core content types one can create, such as websites, PDF\u0026rsquo;s, PowerPoints, and more.\nNo prior knowledge of R or RStudio is needed to attend this session. There is no registration required for this Webinar.\n","date":1589378400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560676801,"objectID":"26c8aa2f05a2a4c18981c5e23b8b49ba","permalink":"https://maggie-98.github.io/talk/2020-rmd4cdc/","publishdate":"2020-02-01T00:00:00Z","relpermalink":"/talk/2020-rmd4cdc/","section":"talk","summary":"A one-hour introduction to R Markdown.","tags":["rmarkdown"],"title":"An Introduction to R Markdown for the CDC","type":"talk"},{"authors":null,"categories":["website"],"content":"This online book contains a full course where users can learn to:\n  explore, groom, visualize, and analyze data,\n  make all of that reproducible, reusable, and shareable,\n  using R.\n  I led the effort, along with course author Jenny Bryan and RStudio intern Grace Lawley, to port a vintage R Markdown website into bookdown. I worked with my former intern, Desir√©e De Leon, to design the style of the bookdown website.\n","date":1587427200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587427200,"objectID":"d6f06fabb53ac901fc425d01a553add8","permalink":"https://maggie-98.github.io/project/stat545.com/","publishdate":"2020-04-21T00:00:00Z","relpermalink":"/project/stat545.com/","section":"project","summary":"A comprehensive course in data wrangling, exploration, and analysis with R","tags":["website","R","bookdown"],"title":"stat545.com","type":"project"},{"authors":null,"categories":["website"],"content":"The tidymodels framework is a collection of R packages for modeling and machine learning using tidyverse principles. This website was built with Hugo, using a theme I developed and maintain. I worked with my former intern, Desir√©e De Leon, to design the style of the website.\n","date":1587427200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587427200,"objectID":"230c3e33261fe2029cd6f2e4d901c82d","permalink":"https://maggie-98.github.io/project/tidymodels.org/","publishdate":"2020-04-21T00:00:00Z","relpermalink":"/project/tidymodels.org/","section":"project","summary":"The central location for learning and using the tidymodels R packages","tags":["website","R","blogdown","machine learning","tidymodels"],"title":"tidymodels.org","type":"project"},{"authors":["alison","Desir√©e De Leon"],"categories":["talk"],"content":" This webinar was designed to help educators who needed to quickly transition to remote teaching due to COVID-19.\n Educators create a lot of files for teaching- slides, exercises, solutions, assignments, data, figures- that all ultimately need to be shared with other people. Having a link for sharing your teaching materials can save you time and pain, but it is hard to get started if you‚Äôve never shared your resources online before. In this webinar, we‚Äôll give a tour of the R Markdown ecosystem for educators that you can start to use right away. We‚Äôll show how it can help you make your teaching more shareable, reproducible, and resilient.\nRead the accompanying Q\u0026amp;A blog post on the RStudio Education blog.\n","date":1585645200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585645200,"objectID":"10e49beba4816cc4d35e850e1344ec41","permalink":"https://maggie-98.github.io/talk/2020-sharing-short-notice/","publishdate":"2020-03-31T09:00:00Z","relpermalink":"/talk/2020-sharing-short-notice/","section":"talk","summary":"How to get your materials online on short notice.","tags":["rmarkdown"],"title":"Sharing on Short Notice","type":"talk"},{"authors":null,"categories":["machine learning","tidymodels"],"content":"A few years ago, I did a talk called \u0026ldquo;Take a Sad Plot \u0026amp; Make it Better,\u0026quot; where I showed how I took a single sad plot and tried to make it better. The process of making that plot better taught me a lot about data visualization, and about the ggplot2 package.\nFast-forward to 2019 when I started learning tidymodels, and I have accumulated some pretty sad predictive modeling scripts! And my sad plots are not so lonely anymore. Specifically, my old scripts for doing cross-validation with tidymodels are particularly sad. But, I\u0026rsquo;ve been able to make them better (one might even call them happy), primarily due to changes in the tune package and the addition of the fit_resamples() function. The process of making these scripts better taught me a lot about predictive modeling, and about the (evolving) tidymodels ecosystem. So, why write a blog post with outdated code?\n I want to remember that I did this \u0026ldquo;by hand.\u0026rdquo; I want to remember how I did this \u0026ldquo;by hand.\u0026rdquo; The code still works, even if there is now a happier path to doing the same thing. I want to share cute penguin art and gifs.  Let\u0026rsquo;s start with some cute penguin art by Rohan Chakravarty\u0026hellip;\n\nMy objective here is not to provide an introduction to using tidymodels, cross-validation, or to machine learning. If that is what you came for, check out the project button at the top of this post for my workshop materials for learners, and my associated blog post on the RStudio education site.\n Bottom line: If you are stumbling upon this blog post in the year 2020 or beyond, know that there is a better way!   A sad script symphony üéª üé∑ üéπ    I\u0026rsquo;m not the first person to write sad tidymodels scripts- there are many out in the wild. Here were the blog posts that I found most helpful when trying to solve this particular coding conundrum:\n   Modelling with Tidymodels and Parsnip: A Tidy Approach to a Classification Problem by Diego Usai\n   A tutorial on tidy cross-validation with R by Bruno Rodrigues\n   Modeling with parsnip and tidymodels by Benjamin Sorensen\n  Packages    library(tidyverse) library(tidymodels) library(rpart) # for decision tree library(ranger) # for random forest  Data    I\u0026rsquo;m going to use data that Allison Horst helped me source on penguins from the Palmer Station (Antarctica) Long Term Ecological Research Network.\n \u0026ldquo;sooo now I\u0026rsquo;m just looking at penguin pictures\u0026rdquo;\n  Allison Horst after slacking me this penguin data    Update! We have bundled the Palmer Station penguins data into an R data package named palmerpenguins. Enjoy üêß Here is the package website: https://allisonhorst.github.io/palmerpenguins/   install.packages(\u0026quot;remotes\u0026quot;) # to install from github remotes::install_github(\u0026quot;allisonhorst/palmerpenguins\u0026quot;)  After you\u0026rsquo;ve installed the package, load it and read about the variables with ?penguins. We\u0026rsquo;ll modify this dataset lightly by:\n casting all characters as factors, dropping any observations with missing data, and dropping the island variable.  library(palmerpenguins) tidypenguins \u0026lt;- penguins %\u0026gt;% select(-island) %\u0026gt;% drop_na() glimpse(tidypenguins) #\u0026gt; Rows: 333 #\u0026gt; Columns: 7 #\u0026gt; $ species \u0026lt;fct\u0026gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Ade‚Ä¶ #\u0026gt; $ bill_length_mm \u0026lt;dbl\u0026gt; 39.1, 39.5, 40.3, 36.7, 39.3, 38.9, 39.2, 41.1, 38.‚Ä¶ #\u0026gt; $ bill_depth_mm \u0026lt;dbl\u0026gt; 18.7, 17.4, 18.0, 19.3, 20.6, 17.8, 19.6, 17.6, 21.‚Ä¶ #\u0026gt; $ flipper_length_mm \u0026lt;int\u0026gt; 181, 186, 195, 193, 190, 181, 195, 182, 191, 198, 1‚Ä¶ #\u0026gt; $ body_mass_g \u0026lt;int\u0026gt; 3750, 3800, 3250, 3450, 3650, 3625, 4675, 3200, 380‚Ä¶ #\u0026gt; $ sex \u0026lt;fct\u0026gt; male, female, female, female, male, female, male, f‚Ä¶ #\u0026gt; $ year \u0026lt;int\u0026gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 200‚Ä¶  Penguins    Figure 1: Artwork by @allisonhorst\n This data included structural size measurements of penguins like their bill length, flipper length, and body mass. It also included each penguin\u0026rsquo;s species and sex. I\u0026rsquo;m going to use this data to try to predict penguin body mass. Sadly, we only have data for three distinct penguin species:\ntidypenguins %\u0026gt;% count(species) #\u0026gt; # A tibble: 3 x 2 #\u0026gt; species n #\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 Adelie 146 #\u0026gt; 2 Chinstrap 68 #\u0026gt; 3 Gentoo 119  Here is a lineup:\nFrom: https://www.bas.ac.uk/about/antarctica/wildlife/penguins/\nLooks like we have data for 3 of the smaller penguin species (of those pictured here).\nFirst, let\u0026rsquo;s build a simple linear regression model to predict body mass from flipper length.\nggplot(tidypenguins, aes(x = flipper_length_mm, y = body_mass_g)) + geom_point(color = \u0026quot;salmon\u0026quot;, size = 3, alpha = .9) + geom_smooth(method = \u0026quot;lm\u0026quot;) + theme_penguin()  Not bad! Looks promising. To actually fit a linear regression model, you might be used to something like this in R:\npenguin_mod \u0026lt;- lm(body_mass_g ~ flipper_length_mm, data = tidypenguins) summary(penguin_mod) #\u0026gt; #\u0026gt; Call: #\u0026gt; lm(formula = body_mass_g ~ flipper_length_mm, data = tidypenguins) #\u0026gt; #\u0026gt; Residuals: #\u0026gt; Min 1Q Median 3Q Max #\u0026gt; -1057.33 -259.79 -12.24 242.97 1293.89 #\u0026gt; #\u0026gt; Coefficients: #\u0026gt; Estimate Std. Error t value Pr(\u0026gt;|t|) #\u0026gt; (Intercept) -5872.09 310.29 -18.93 \u0026lt;2e-16 *** #\u0026gt; flipper_length_mm 50.15 1.54 32.56 \u0026lt;2e-16 *** #\u0026gt; --- #\u0026gt; Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #\u0026gt; #\u0026gt; Residual standard error: 393.3 on 331 degrees of freedom #\u0026gt; Multiple R-squared: 0.7621,\tAdjusted R-squared: 0.7614 #\u0026gt; F-statistic: 1060 on 1 and 331 DF, p-value: \u0026lt; 2.2e-16  But we aren\u0026rsquo;t going to stick with this. We are going to use tidymodels, with the goal of generating accurate predictions for future, yet-to-be-seen penguins.\ntidymodels 101    The code provided in the section below is not particularly sad üêß. If you are embarking on learning tidymodels, you\u0026rsquo;ll need to use this same kind of code as the building blocks for any predictive modeling pipeline.\nParsnip: build the model    This step is really three, using only the parsnip package:\nlm_spec \u0026lt;- linear_reg() %\u0026gt;% # pick model set_engine(\u0026quot;lm\u0026quot;) %\u0026gt;% # set engine set_mode(\u0026quot;regression\u0026quot;) # set mode lm_spec #\u0026gt; Linear Regression Model Specification (regression) #\u0026gt; #\u0026gt; Computational engine: lm  Things that are missing: data (we haven\u0026rsquo;t touched it yet) and a formula (no data, no variables, no twiddle ~). This is an abstract model specification. See other possible parsnip models here.\nRecipe: not happening here, folks    This is where you would normally insert some code for feature engineering using the recipes package. But previously this required functions named prep(), bake(), juice()- so I\u0026rsquo;m willfully ignoring that for now. There will be no recipes involving penguins.\nRsample: initial split    We\u0026rsquo;ll use the rsample package to split (ayee! I promise no penguins were hurt in the writing of this blog post) the penguins up into two datasets: training and testing. If you are unfamiliar with this practice, read up on the holdout method.\npenguin_split \u0026lt;- initial_split(tidypenguins, strata = species) penguin_train \u0026lt;- training(penguin_split) penguin_test \u0026lt;- testing(penguin_split)  Fitting the model once    Fitting a single model once is\u0026hellip;not exactly the hardest part.\nThis is essentially the workflow from this early blog post.\nset.seed(0) lm_spec %\u0026gt;% # train: get fitted model fit(body_mass_g ~ ., data = penguin_train) %\u0026gt;% # test: get predictions predict(new_data = penguin_test) %\u0026gt;% # compare: get metrics bind_cols(penguin_test) %\u0026gt;% rmse(truth = body_mass_g, estimate = .pred) #\u0026gt; # A tibble: 1 x 3 #\u0026gt; .metric .estimator .estimate #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 rmse standard 278.  Fitting the model with a function    If you squint, you might see that I could make this into a function like below:\nget_rmse \u0026lt;- function(model_spec, split) { model_spec %\u0026gt;% # train: get fitted model fit(body_mass_g ~ ., data = training(split)) %\u0026gt;% # test: get predictions predict(new_data = testing(split)) %\u0026gt;% # compare: get metrics bind_cols(testing(split)) %\u0026gt;% rmse(truth = body_mass_g, estimate = .pred) }  And I could use it to fit a linear regression model:\nset.seed(0) get_rmse(model_spec = lm_spec, split = penguin_split) #\u0026gt; # A tibble: 1 x 3 #\u0026gt; .metric .estimator .estimate #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 rmse standard 278.  I could also build up a tibble that includes the results, if I wanted to save the predicted values, for example:\nget_preds \u0026lt;- function(model_spec, split){ # train: get fitted model fit_model \u0026lt;- model_spec %\u0026gt;% fit(body_mass_g ~ ., data = training(split)) # test: get predictions preds \u0026lt;- fit_model %\u0026gt;% predict(new_data = testing(split)) %\u0026gt;% bind_cols(testing(split) %\u0026gt;% select(body_mass_g, species)) preds } set.seed(0) penguin_preds \u0026lt;- get_preds(model_spec = lm_spec, split = penguin_split)  Then I can work with the predicted values, like plotting the fitted body mass estimates against the residuals.\nggplot(penguin_preds, aes(x = .pred, y = (.pred - body_mass_g))) + geom_point(aes(colour = species), size = 3, alpha = .8) + geom_smooth(method = \u0026quot;lm\u0026quot;) + theme_penguin() + scico::scale_colour_scico_d(end = .8) + ggtitle(\u0026quot;Residuals vs Fitted\u0026quot;) #\u0026gt; `geom_smooth()` using formula 'y ~ x'  # compare: get metrics penguin_preds %\u0026gt;% rmse(truth = body_mass_g, estimate = .pred) #\u0026gt; # A tibble: 1 x 3 #\u0026gt; .metric .estimator .estimate #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 rmse standard 278.  Or I could fit a regression tree model with a new model spec:\n# regression tree model spec rt_spec \u0026lt;- decision_tree() %\u0026gt;% set_engine(\u0026quot;rpart\u0026quot;) %\u0026gt;% set_mode(\u0026quot;regression\u0026quot;) # get rmse set.seed(0) get_preds(model_spec = rt_spec, split = penguin_split) %\u0026gt;% rmse(truth = body_mass_g, estimate = .pred) #\u0026gt; # A tibble: 1 x 3 #\u0026gt; .metric .estimator .estimate #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 rmse standard 312.  Or a random forest:\n# random forest model spec rf_spec \u0026lt;- rand_forest() %\u0026gt;% set_engine(\u0026quot;ranger\u0026quot;) %\u0026gt;% set_mode(\u0026quot;regression\u0026quot;) # get rmse set.seed(0) get_preds(model_spec = rf_spec, split = penguin_split) %\u0026gt;% rmse(truth = body_mass_g, estimate = .pred) #\u0026gt; # A tibble: 1 x 3 #\u0026gt; .metric .estimator .estimate #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 rmse standard 300.  But, unfortunately, I shouldn\u0026rsquo;t be predicting with the test set over and over again like this. It isn\u0026rsquo;t good practice to predict with the test set \u0026gt; 1 time. What is a good predictive modeler to do? I should be saving (holding out) the test set and use it to generate predictions exactly once, at the very end ‚Äî after I\u0026rsquo;ve compared different models, selected my features, and tuned my hyperparameters. How do you do this? You do cross-validation with the training set, and you leave the testing set for the very last fit you do.\nHey Jude, don\u0026rsquo;t make it sad üé∂    Now, for the üò≠ part- let\u0026rsquo;s add cross-validation! To do this, we\u0026rsquo;ll use a function called rsample::vfold_cv().\n# add the cv step here set.seed(0) penguin_folds \u0026lt;- vfold_cv(data = penguin_train, strata = \u0026quot;species\u0026quot;) penguin_folds #\u0026gt; # 10-fold cross-validation using stratification #\u0026gt; # A tibble: 10 x 2 #\u0026gt; splits id #\u0026gt; \u0026lt;list\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 \u0026lt;split [225/26]\u0026gt; Fold01 #\u0026gt; 2 \u0026lt;split [226/25]\u0026gt; Fold02 #\u0026gt; 3 \u0026lt;split [226/25]\u0026gt; Fold03 #\u0026gt; 4 \u0026lt;split [226/25]\u0026gt; Fold04 #\u0026gt; 5 \u0026lt;split [226/25]\u0026gt; Fold05 #\u0026gt; 6 \u0026lt;split [226/25]\u0026gt; Fold06 #\u0026gt; 7 \u0026lt;split [226/25]\u0026gt; Fold07 #\u0026gt; 8 \u0026lt;split [226/25]\u0026gt; Fold08 #\u0026gt; 9 \u0026lt;split [226/25]\u0026gt; Fold09 #\u0026gt; 10 \u0026lt;split [226/25]\u0026gt; Fold10  The process of training, testing, and computing metrics gets a lot harder when you need to do this across 10 folds, each with a different data split. I eventually worked out three approaches, which I show below. All require some level of comfort with iteration using the purrr package.\nFunction with minimal purrr-ing    This approach is essentially a mega-function, that we then use purrr to map across each fold.\nI\u0026rsquo;m going to change a few things from my previous get_preds() function:\n training(split) -\u0026gt; analysis(split) testing(split) -\u0026gt; assessment(split) I also added the rsample::add_resample_id() function to keep track of the fold number. I saved the predictions now as a list column.  To build up this function, my strategy was to figure out how to work with one fold, then I knew I\u0026rsquo;d be able to use purrr::map_df() to apply it across multiple folds.\n# Figure it out for one fold get_fold_results \u0026lt;- function(model_spec, split){ # train: get fitted model for each fold fits \u0026lt;- model_spec %\u0026gt;% fit(body_mass_g ~ ., data = analysis(split)) # test: get predictions on for each fold preds \u0026lt;- fits %\u0026gt;% predict(new_data = assessment(split)) %\u0026gt;% bind_cols(assessment(split)) # compare: compute metric for each fold rmse \u0026lt;- assessment(split) %\u0026gt;% summarize(rmse = rmse_vec(truth = body_mass_g, estimate = preds$.pred)) rmse %\u0026gt;% # add fold identifier column rsample::add_resample_id(split = split) %\u0026gt;% as_tibble() %\u0026gt;% # add predictions mutate(preds = list(preds)) }  I tried this function with a single fold first:\nset.seed(0) get_fold_results( split = penguin_folds$splits[[1]], model_spec = rt_spec ) #\u0026gt; # A tibble: 1 x 3 #\u0026gt; rmse id preds #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; #\u0026gt; 1 419. Fold01 \u0026lt;tibble [26 √ó 8]\u0026gt;  Next, I used purrr- but just once. The function get_fold_results is doing most of the work for us, but I needed purrr to map it across each fold.\nset.seed(0) kfold_results \u0026lt;- map_df( penguin_folds$splits, ~get_fold_results(.x, model = rt_spec)) kfold_results #\u0026gt; # A tibble: 10 x 3 #\u0026gt; rmse id preds #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; #\u0026gt; 1 419. Fold01 \u0026lt;tibble [26 √ó 8]\u0026gt; #\u0026gt; 2 326. Fold02 \u0026lt;tibble [25 √ó 8]\u0026gt; #\u0026gt; 3 414. Fold03 \u0026lt;tibble [25 √ó 8]\u0026gt; #\u0026gt; 4 327. Fold04 \u0026lt;tibble [25 √ó 8]\u0026gt; #\u0026gt; 5 336. Fold05 \u0026lt;tibble [25 √ó 8]\u0026gt; #\u0026gt; 6 406. Fold06 \u0026lt;tibble [25 √ó 8]\u0026gt; #\u0026gt; 7 305. Fold07 \u0026lt;tibble [25 √ó 8]\u0026gt; #\u0026gt; 8 301. Fold08 \u0026lt;tibble [25 √ó 8]\u0026gt; #\u0026gt; 9 315. Fold09 \u0026lt;tibble [25 √ó 8]\u0026gt; #\u0026gt; 10 319. Fold10 \u0026lt;tibble [25 √ó 8]\u0026gt;  Here we are still left with 10 RMSE values- one for each of the 10 folds. We don\u0026rsquo;t care too much about by fold- the power is in the aggregate. Specifically, we mainly care about the central tendency and spread of these RMSE values. Let\u0026rsquo;s finish by combining (or aggregating) these metrics.\nkfold_results %\u0026gt;% summarize(mean_rmse = mean(rmse), sd_rmse = sd(rmse)) #\u0026gt; # A tibble: 1 x 2 #\u0026gt; mean_rmse sd_rmse #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 347. 46.8  So, this works. But, can you imagine doing it again? Without errors? Can you imagine teaching it?\nPurrr-to-the-max    This approach is purrr::map() (and friends) on steriods. We use vanilla map(), map2(), and map2_dbl() here. We also use anonymous functions as a formula, and the pipe operator within those anonymous functions.\nset.seed(0) penguin_res \u0026lt;- penguin_folds %\u0026gt;% mutate( # train: get fitted model for each fold train_set = map(splits, analysis), fit_models = map(train_set, ~rt_spec %\u0026gt;% fit(body_mass_g ~ ., data = .x)), # test: get predictions for each fold test_set = map(splits, assessment), estimates = map2(fit_models, test_set, ~.x %\u0026gt;% predict(.y)), # compare: compute metric for each fold rmse = map2_dbl(test_set, estimates, ~rmse_vec(truth = .x$body_mass_g, estimate = .y$.pred)) ) penguin_res #\u0026gt; # 10-fold cross-validation using stratification #\u0026gt; # A tibble: 10 x 7 #\u0026gt; splits id train_set fit_models test_set estimates rmse #\u0026gt; \u0026lt;list\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 \u0026lt;split [225‚Ä¶ Fold01 \u0026lt;tibble [225‚Ä¶ \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [26‚Ä¶ \u0026lt;tibble [26 ‚Ä¶ 419. #\u0026gt; 2 \u0026lt;split [226‚Ä¶ Fold02 \u0026lt;tibble [226‚Ä¶ \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25‚Ä¶ \u0026lt;tibble [25 ‚Ä¶ 326. #\u0026gt; 3 \u0026lt;split [226‚Ä¶ Fold03 \u0026lt;tibble [226‚Ä¶ \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25‚Ä¶ \u0026lt;tibble [25 ‚Ä¶ 414. #\u0026gt; 4 \u0026lt;split [226‚Ä¶ Fold04 \u0026lt;tibble [226‚Ä¶ \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25‚Ä¶ \u0026lt;tibble [25 ‚Ä¶ 327. #\u0026gt; 5 \u0026lt;split [226‚Ä¶ Fold05 \u0026lt;tibble [226‚Ä¶ \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25‚Ä¶ \u0026lt;tibble [25 ‚Ä¶ 336. #\u0026gt; 6 \u0026lt;split [226‚Ä¶ Fold06 \u0026lt;tibble [226‚Ä¶ \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25‚Ä¶ \u0026lt;tibble [25 ‚Ä¶ 406. #\u0026gt; 7 \u0026lt;split [226‚Ä¶ Fold07 \u0026lt;tibble [226‚Ä¶ \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25‚Ä¶ \u0026lt;tibble [25 ‚Ä¶ 305. #\u0026gt; 8 \u0026lt;split [226‚Ä¶ Fold08 \u0026lt;tibble [226‚Ä¶ \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25‚Ä¶ \u0026lt;tibble [25 ‚Ä¶ 301. #\u0026gt; 9 \u0026lt;split [226‚Ä¶ Fold09 \u0026lt;tibble [226‚Ä¶ \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25‚Ä¶ \u0026lt;tibble [25 ‚Ä¶ 315. #\u0026gt; 10 \u0026lt;split [226‚Ä¶ Fold10 \u0026lt;tibble [226‚Ä¶ \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25‚Ä¶ \u0026lt;tibble [25 ‚Ä¶ 319. penguin_res %\u0026gt;% summarise(mean_rmse = mean(rmse), sd_rmse = sd(rmse)) #\u0026gt; # A tibble: 1 x 2 #\u0026gt; mean_rmse sd_rmse #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 347. 46.8  The purrr mash-up    Another way I worked out was largely after reviewing Max\u0026rsquo;s slides from previous workshops. This is basically a mash-up of my previous two approaches, where we write laser-focused functions that each do one thing, then use purrr to apply those functions across the folds. This way is nice(r) for showing in slides as you can incrementally build up the results table. Let\u0026rsquo;s see this sad script in action\u0026hellip;\nRound 1    set.seed(0) # for reproducibility # train: get fitted model for a split get_fits \u0026lt;- function(split, model_spec){ model_spec %\u0026gt;% fit(body_mass_g ~ ., data = analysis(split)) } # train: get fitted models across folds penguin_purrr \u0026lt;- penguin_folds %\u0026gt;% mutate(rt_fits = map(splits, get_fits, rt_spec)) penguin_purrr #\u0026gt; # 10-fold cross-validation using stratification #\u0026gt; # A tibble: 10 x 3 #\u0026gt; splits id rt_fits #\u0026gt; \u0026lt;list\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; #\u0026gt; 1 \u0026lt;split [225/26]\u0026gt; Fold01 \u0026lt;fit[+]\u0026gt; #\u0026gt; 2 \u0026lt;split [226/25]\u0026gt; Fold02 \u0026lt;fit[+]\u0026gt; #\u0026gt; 3 \u0026lt;split [226/25]\u0026gt; Fold03 \u0026lt;fit[+]\u0026gt; #\u0026gt; 4 \u0026lt;split [226/25]\u0026gt; Fold04 \u0026lt;fit[+]\u0026gt; #\u0026gt; 5 \u0026lt;split [226/25]\u0026gt; Fold05 \u0026lt;fit[+]\u0026gt; #\u0026gt; 6 \u0026lt;split [226/25]\u0026gt; Fold06 \u0026lt;fit[+]\u0026gt; #\u0026gt; 7 \u0026lt;split [226/25]\u0026gt; Fold07 \u0026lt;fit[+]\u0026gt; #\u0026gt; 8 \u0026lt;split [226/25]\u0026gt; Fold08 \u0026lt;fit[+]\u0026gt; #\u0026gt; 9 \u0026lt;split [226/25]\u0026gt; Fold09 \u0026lt;fit[+]\u0026gt; #\u0026gt; 10 \u0026lt;split [226/25]\u0026gt; Fold10 \u0026lt;fit[+]\u0026gt;  Round 2    # test: get predictions for a split get_preds \u0026lt;- function(split, fit_df) { fit_df %\u0026gt;% predict(new_data = assessment(split)) %\u0026gt;% bind_cols(assessment(split)) } # test: get predictions across folds penguin_purrr \u0026lt;- penguin_purrr %\u0026gt;% mutate(rt_preds = map2(splits, rt_fits, get_preds)) penguin_purrr #\u0026gt; # 10-fold cross-validation using stratification #\u0026gt; # A tibble: 10 x 4 #\u0026gt; splits id rt_fits rt_preds #\u0026gt; \u0026lt;list\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; #\u0026gt; 1 \u0026lt;split [225/26]\u0026gt; Fold01 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [26 √ó 8]\u0026gt; #\u0026gt; 2 \u0026lt;split [226/25]\u0026gt; Fold02 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; #\u0026gt; 3 \u0026lt;split [226/25]\u0026gt; Fold03 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; #\u0026gt; 4 \u0026lt;split [226/25]\u0026gt; Fold04 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; #\u0026gt; 5 \u0026lt;split [226/25]\u0026gt; Fold05 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; #\u0026gt; 6 \u0026lt;split [226/25]\u0026gt; Fold06 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; #\u0026gt; 7 \u0026lt;split [226/25]\u0026gt; Fold07 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; #\u0026gt; 8 \u0026lt;split [226/25]\u0026gt; Fold08 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; #\u0026gt; 9 \u0026lt;split [226/25]\u0026gt; Fold09 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; #\u0026gt; 10 \u0026lt;split [226/25]\u0026gt; Fold10 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt;  aaaand Round 3    # compare: compute metric for a split get_rmse \u0026lt;- function(pred_df) { pred_df %\u0026gt;% rmse(truth = body_mass_g, estimate = .pred) %\u0026gt;% pluck(\u0026quot;.estimate\u0026quot;) } # compare: compute metric across folds penguin_purrr \u0026lt;- penguin_purrr %\u0026gt;% mutate(rt_rmse = map_dbl(rt_preds, get_rmse)) penguin_purrr #\u0026gt; # 10-fold cross-validation using stratification #\u0026gt; # A tibble: 10 x 5 #\u0026gt; splits id rt_fits rt_preds rt_rmse #\u0026gt; \u0026lt;list\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 \u0026lt;split [225/26]\u0026gt; Fold01 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [26 √ó 8]\u0026gt; 419. #\u0026gt; 2 \u0026lt;split [226/25]\u0026gt; Fold02 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 326. #\u0026gt; 3 \u0026lt;split [226/25]\u0026gt; Fold03 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 414. #\u0026gt; 4 \u0026lt;split [226/25]\u0026gt; Fold04 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 327. #\u0026gt; 5 \u0026lt;split [226/25]\u0026gt; Fold05 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 336. #\u0026gt; 6 \u0026lt;split [226/25]\u0026gt; Fold06 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 406. #\u0026gt; 7 \u0026lt;split [226/25]\u0026gt; Fold07 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 305. #\u0026gt; 8 \u0026lt;split [226/25]\u0026gt; Fold08 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 301. #\u0026gt; 9 \u0026lt;split [226/25]\u0026gt; Fold09 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 315. #\u0026gt; 10 \u0026lt;split [226/25]\u0026gt; Fold10 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 319.  Finally, summarizing as I did before:\npenguin_purrr %\u0026gt;% summarize(mean_rmse = mean(rt_rmse), sd_rmse = sd(rt_rmse)) #\u0026gt; # A tibble: 1 x 2 #\u0026gt; mean_rmse sd_rmse #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 347. 46.8  In practice, if you did all these at once instead of incrementally, it would look like:\nset.seed(0) penguin_folds %\u0026gt;% # train: get fitted model for a split mutate(rt_fits = map(splits, get_fits, rt_spec)) %\u0026gt;% # test: get predictions on for each fold mutate(rt_preds = map2(splits, rt_fits, get_preds)) %\u0026gt;% # compare: compute metric for each fold mutate(rt_rmse = map_dbl(rt_preds, get_rmse)) #\u0026gt; # 10-fold cross-validation using stratification #\u0026gt; # A tibble: 10 x 5 #\u0026gt; splits id rt_fits rt_preds rt_rmse #\u0026gt; \u0026lt;list\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 \u0026lt;split [225/26]\u0026gt; Fold01 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [26 √ó 8]\u0026gt; 419. #\u0026gt; 2 \u0026lt;split [226/25]\u0026gt; Fold02 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 326. #\u0026gt; 3 \u0026lt;split [226/25]\u0026gt; Fold03 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 414. #\u0026gt; 4 \u0026lt;split [226/25]\u0026gt; Fold04 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 327. #\u0026gt; 5 \u0026lt;split [226/25]\u0026gt; Fold05 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 336. #\u0026gt; 6 \u0026lt;split [226/25]\u0026gt; Fold06 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 406. #\u0026gt; 7 \u0026lt;split [226/25]\u0026gt; Fold07 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 305. #\u0026gt; 8 \u0026lt;split [226/25]\u0026gt; Fold08 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 301. #\u0026gt; 9 \u0026lt;split [226/25]\u0026gt; Fold09 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 315. #\u0026gt; 10 \u0026lt;split [226/25]\u0026gt; Fold10 \u0026lt;fit[+]\u0026gt; \u0026lt;tibble [25 √ó 8]\u0026gt; 319.  When you put it like that, it doesn\u0026rsquo;t look like so much work! But, this way hides how much work it takes to write those 3 custom functions: get_fits(), get_preds(), and get_rmse(). And we still had to use vanilla map(), map2(), and map2_dbl().\nMake it better    I kept a learning log while working through the all the above code, and I wrote down these notes to myself:\n  It is very easy to do the wrong thing; it is very hard to do the right thing.\n  I lost sight many times of what the code I was writing was doing, because I was using up so much cognitive energy on getting the code to just work.\n  I thought I knew how to use purrr\u0026hellip;\n  If you have made it this far, I\u0026rsquo;m pretty sure I don\u0026rsquo;t need to convince you that a better way to do cross-validation using tidymodels would be more pleasant to do more than once. It would also be less prone to error due to me copying-and-pasting repeatedly, and making stupid mistakes that would be difficult to spot with so much cluttered code. Luckily, tune::fit_resamples() came along to take a sad script and make it better:\npenguin_party \u0026lt;- tune::fit_resamples( rt_spec, body_mass_g ~ ., resamples = penguin_folds )  Here is the beautiful output from that function:\npenguin_party #\u0026gt; # Resampling results #\u0026gt; # 10-fold cross-validation using stratification #\u0026gt; # A tibble: 10 x 4 #\u0026gt; splits id .metrics .notes #\u0026gt; \u0026lt;list\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;list\u0026gt; \u0026lt;list\u0026gt; #\u0026gt; 1 \u0026lt;split [225/26]\u0026gt; Fold01 \u0026lt;tibble [2 √ó 3]\u0026gt; \u0026lt;tibble [0 √ó 1]\u0026gt; #\u0026gt; 2 \u0026lt;split [226/25]\u0026gt; Fold02 \u0026lt;tibble [2 √ó 3]\u0026gt; \u0026lt;tibble [0 √ó 1]\u0026gt; #\u0026gt; 3 \u0026lt;split [226/25]\u0026gt; Fold03 \u0026lt;tibble [2 √ó 3]\u0026gt; \u0026lt;tibble [0 √ó 1]\u0026gt; #\u0026gt; 4 \u0026lt;split [226/25]\u0026gt; Fold04 \u0026lt;tibble [2 √ó 3]\u0026gt; \u0026lt;tibble [0 √ó 1]\u0026gt; #\u0026gt; 5 \u0026lt;split [226/25]\u0026gt; Fold05 \u0026lt;tibble [2 √ó 3]\u0026gt; \u0026lt;tibble [0 √ó 1]\u0026gt; #\u0026gt; 6 \u0026lt;split [226/25]\u0026gt; Fold06 \u0026lt;tibble [2 √ó 3]\u0026gt; \u0026lt;tibble [0 √ó 1]\u0026gt; #\u0026gt; 7 \u0026lt;split [226/25]\u0026gt; Fold07 \u0026lt;tibble [2 √ó 3]\u0026gt; \u0026lt;tibble [0 √ó 1]\u0026gt; #\u0026gt; 8 \u0026lt;split [226/25]\u0026gt; Fold08 \u0026lt;tibble [2 √ó 3]\u0026gt; \u0026lt;tibble [0 √ó 1]\u0026gt; #\u0026gt; 9 \u0026lt;split [226/25]\u0026gt; Fold09 \u0026lt;tibble [2 √ó 3]\u0026gt; \u0026lt;tibble [0 √ó 1]\u0026gt; #\u0026gt; 10 \u0026lt;split [226/25]\u0026gt; Fold10 \u0026lt;tibble [2 √ó 3]\u0026gt; \u0026lt;tibble [0 √ó 1]\u0026gt;  Now, to see all the stuff inside this penguin_party, we can use tune\u0026rsquo;s collect_* functions.\npenguin_party %\u0026gt;% collect_metrics() #\u0026gt; # A tibble: 2 x 5 #\u0026gt; .metric .estimator mean n std_err #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; #\u0026gt; 1 rmse standard 347. 10 14.8 #\u0026gt; 2 rsq standard 0.839 10 0.0141  To see the predictions, we need to add use control_resamples():\npenguin_party \u0026lt;- tune::fit_resamples( rt_spec, body_mass_g ~ ., resamples = penguin_folds, control = control_resamples(save_pred = TRUE) # add this line )  Then we collect the predictions.\npenguin_party %\u0026gt;% collect_predictions() #\u0026gt; # A tibble: 251 x 4 #\u0026gt; id .pred .row body_mass_g #\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 Fold01 3402. 4 3625 #\u0026gt; 2 Fold01 3402. 11 3325 #\u0026gt; 3 Fold01 3988. 14 3950 #\u0026gt; 4 Fold01 3988. 41 3700 #\u0026gt; 5 Fold01 3402. 54 3700 #\u0026gt; 6 Fold01 3988. 65 3950 #\u0026gt; 7 Fold01 3988. 70 4450 #\u0026gt; 8 Fold01 3402. 71 3300 #\u0026gt; 9 Fold01 3402. 76 3075 #\u0026gt; 10 Fold01 3402. 85 2900 #\u0026gt; # ‚Ä¶ with 241 more rows  Now, isn\u0026rsquo;t that better?\n","date":1582761600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582761600,"objectID":"3f6d21755f6210ccc450575422f58ff0","permalink":"https://maggie-98.github.io/post/2020-02-27-better-tidymodels/","publishdate":"2020-02-27T00:00:00Z","relpermalink":"/post/2020-02-27-better-tidymodels/","section":"post","summary":"Taking a sad script and making it better for model cross-validation.","tags":["tidymodels"],"title":"Take a Sad Script \u0026 Make it Better: Tidymodels Edition","type":"post"},{"authors":null,"categories":["workshop"],"content":"This two-day workshop provided a gentle introduction to supervised machine learning: concepts, methods, and R code. Participants learned how to train and assess predictive models with several common machine learning algorithms, as well as how to do feature engineering to improve the predictive accuracy of their models. We focused on teaching intuitive explanations of the models and best practices for predictive modeling. Along the way, we introduced several core tidymodels packages, which provide a grammar for modeling that makes it easy to the right thing, and harder to accidentally do the wrong thing.\n","date":1580115600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560676801,"objectID":"198f28f4fb8fbce956d2beb2a807e38c","permalink":"https://maggie-98.github.io/talk/2020-rsc-tidyml/","publishdate":"2020-02-01T00:00:00Z","relpermalink":"/talk/2020-rsc-tidyml/","section":"talk","summary":"rstudio::conf(2020) two-day workshop to introduce the basics of machine learning and tidymodels.","tags":["tidymodels","machine learning"],"title":"Introduction to Machine Learning with the Tidyverse","type":"talk"},{"authors":null,"categories":["workshop"],"content":"These workshops provide a gentle introduction to supervised machine learning: concepts, methods, and R code. Participants learn how to train and assess predictive models with several common machine learning algorithms, as well as how to do feature engineering to improve the predictive accuracy of their models. We focus on teaching intuitive explanations of the models and best practices for predictive modeling. Along the way, we introduce several core tidymodels packages, which provide a grammar for modeling that makes it easy to the right thing, and harder to accidentally do the wrong thing.\nSee the workshop websites for more, including links to the GitHub repositories for all workshop materials.\n","date":1580083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580083200,"objectID":"680a92ce0fb594ea27cf4fc0d00ea101","permalink":"https://maggie-98.github.io/project/tidyml/","publishdate":"2020-01-27T00:00:00Z","relpermalink":"/project/tidyml/","section":"project","summary":"Introducing the basics of machine learning in R using tidymodels","tags":["workshop","R","blogdown","machine learning","tidymodels"],"title":"Introduction to Machine Learning with the Tidyverse","type":"project"},{"authors":[],"categories":[],"content":"I\u0026rsquo;m excited to be teaching a new workshop at the upcoming rstudio::conf in January called \u0026ldquo;Introduction to Machine Learning with the Tidyverse\u0026rdquo;, with my colleague Garrett Grolemund. Our workshop just sold out over the weekend! üéâ\nIt is always hard to develop an entirely new workshop, especially if you are doing it at the same time as learning how to use a new API. It is even harder when that API is under active development like the tidymodels ecosystem! I\u0026rsquo;ve been so lucky to be able to work with the tidymodels team at RStudio, Max Kuhn and Davis Vaughan, to help shape how we tell the tidymodels story to ML beginners. But my favorite part of developing a new workshop like this has been studying how others teach machine learning. Spoiler alert: there are a lot of materials intended for learners that make things seem harder than they actually are! Below, I\u0026rsquo;m sharing my bookmarked resources, organized roughly in the order I think they are most helpful for beginners.\n   Machine Learning for Everyone. In simple words. With real-world examples. Yes, again. In my experience, the biggest hurdle to getting started is sifting through both the hype and the math. This is a readable illustrated introduction to key concepts that will help you start building your own mental model of this space. For example, \u0026ldquo;the only goal of machine learning is to predict results based on incoming data. That\u0026rsquo;s it.\u0026quot; There you go! Start here.\n\n   A Visual Introduction to Machine Learning by r2d3. This is a wonderful two-part series (that I wish would be extended!):\n  Part I: A Decision Tree  Part II: Model Tuning and the Bias-Variance Tradeoff      Supervised Machine Learning course by Julia Silge Taught with R and the caret package (the precursor to the in-development tidymodels ecosystem), this is a great next step in your machine learning journey as you\u0026rsquo;ll start doing ML right away in your browser using an innovative course delivery platform. You\u0026rsquo;ll also get to play with data that is not iris, titanic, or AmesHousing. This will be sweet relief because you\u0026rsquo;ll find the rest of my recommended resources all basically build models to predict home prices in Ames, Iowa.\n\n   Hands-on Machine Learning with R by Bradley Boehmke \u0026amp; Brandon Greenwell. Another great way to learn concepts plus code, although another one that focuses on the caret package (pre-tidymodels). Each chapter maps onto a new learning algorithm, and provides a code-through with real data from building to tuning. The authors also offer practical advice for each algorithm, and the \u0026ldquo;final thoughts\u0026rdquo; sections at the end of each chapter will help you tie it all together.\n\nDon\u0026rsquo;t skip the \u0026ldquo;Fundamentals\u0026rdquo; section, even if you feel like you\u0026rsquo;ve got that down by now. The second chapter on the modeling process is especially good.\n\n   Interpretable Machine Learning: A Guide for Making Black Box Models Explainable by Christoph Molnar. If you only have time to read a single chapter, skip ahead to Chapter 4: Interpretable Models. I also appreciated the introduction section on terminology. But the whole book is excellent and well-written.\n\n  Model evaluation, model selection, and algorithm selection in machine learning- a 4-part series by Sebastian Raschka. I found this to be a great evidence-based, thorough overview of the methods for machine learning. I especially liked how he walks you step-by-step from the simplest methods like the holdout method up to nested cross-validation:\n  Part I: The Basics  Part II: Bootstrapping \u0026amp; uncertainties  Part III: Cross-validation and hyperparameter tuning  Part IV: Comparing the performance of machine learning models and algorithms using statistical tests and nested cross-validation    At this point, if you can read through the above resources and you are no longer feeling awash in new terminology, I think your vocabulary and mental model are in pretty good shape! That means you are ready for the next step, which is to read Max Kuhn and Kjell Johnson\u0026rsquo;s new book Feature Engineering and Selection: A Practical Approach for Predictive Models\n\nIn my experience, the later chapters in this book filled in a lot of lingering questions I had about certain methods, like whether to use factor or dummy variables in tree-based models. But also don\u0026rsquo;t miss the section on \u0026ldquo;important concepts\u0026rdquo; at the beginning- this should feel like a nice review if you\u0026rsquo;ve gotten this far!\n   Elements of Statistical Learning. The entire PDF of the book is available online. A great resource for those with a strong statistics background, and for those looking for more math and formulas.\n  Other note-worthy resources      For the highly visual learner, you may want to cue up some YouTube videos from Udacity\u0026rsquo;s \u0026ldquo;Machine Learning for Trading\u0026rdquo; course. I found these illustrations especially helpful:\n  Cross-validation  Overfitting  Ensemble learners  Bootstrap aggregating (bagging)  Boosting    Chris Albon\u0026rsquo;s Machine Learning Flashcards ($12)\n    Shirin Elsinghorst\u0026rsquo;s blog (free! and so good).\n\nI love her sketchnotes.\n   I also found Rafael Irizarry\u0026rsquo;s \u0026ldquo;Introduction to Machine Learning\u0026rdquo;, a chapter from his Introduction to Data Science book, to have some helpful discussion.\n   Machine Learning: A primer by Danilo Bzdok, Martin Krzywinski \u0026amp; Naomi Altman, from the Nature Methods Points of Significance collection- this collection in general is always straight-forward with great visuals. Start with the primer, then skim these:\n  Statistics versus machine learning  Machine learning: supervised methods  Classification and regression trees (decision trees are the \u0026ldquo;base learner\u0026rdquo; for many ensemble methods - this is a good intro)  Ensemble methods: bagging and random forests    That\u0026rsquo;s all for now- if you are taking my workshop in January I look forward to meeting you in person! If not, rest assured that all code and materials will be shared openly after the workshop. Until then, happy learning ü§ñ\n","date":1577059200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577119901,"objectID":"ed95a4940fd870c538b12c1237cc9c64","permalink":"https://maggie-98.github.io/post/2019-12-23-learning-to-teach-machines-to-learn/","publishdate":"2019-12-23T00:00:00Z","relpermalink":"/post/2019-12-23-learning-to-teach-machines-to-learn/","section":"post","summary":"I\u0026rsquo;m excited to be teaching a new workshop at the upcoming rstudio::conf in January called \u0026ldquo;Introduction to Machine Learning with the Tidyverse\u0026rdquo;, with my colleague Garrett Grolemund. Our workshop just sold out over the weekend!","tags":[],"title":"Learning to Teach Machines to Learn","type":"post"},{"authors":null,"categories":["talk"],"content":"Using data from 10 series of The Great British Bake Off, we will walk through eleven ways to visualize the same data using the ggplot2 package. We\u0026rsquo;ll talk a lot about geoms and variable mappings, but also about what it means to \u0026ldquo;tidy your data\u0026rdquo;, plus the new pivot functions in the tidyr package.\nYou won\u0026rsquo;t need your laptops but you will get the most out of this talk if you know some basics about using ggplot2. To brush up (or start learning now), you may want to play with the free RStudio.cloud data visualization primer (you may use an existing Google or GitHub account to log in). Or of course you can check out R-Ladies Sydney\u0026rsquo;s own VizW(h)iz Module of #RYouWithMe!\n","date":1570212000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570212000,"objectID":"b3e93a5d5a74347c959e04f4f64d3d9c","permalink":"https://maggie-98.github.io/talk/2019-rladies-sydney/","publishdate":"2019-06-15T00:00:00Z","relpermalink":"/talk/2019-rladies-sydney/","section":"talk","summary":"Making it tidy isn't the end of your data's story...","tags":["oz2019","xaringan","ggplot2","data visualization","tidy data"],"title":"Plot Twist: 10 Bake Offs, Visualized 11 Ways","type":"talk"},{"authors":["alison"],"categories":["talk","keynote"],"content":"   ‚ÄúLiterate programming‚Äù is an approach to writing software programs that weaves together the source code and documentation at the time of creation. The idea is to create programs that are easier for users to understand. But they are also easier for programmers to work on and maintain. In this talk, I will describe how data scientists can be inspired by this programming approach and start what I refer to as ‚Äúliterate projecting.‚Äù Literate projects are not only more pleasant to work on ‚Äî they are also easier for others to discover and explore. In my experiences as a researcher and now a data scientist at RStudio, I‚Äôve had the pleasure to work on many literate projects, and I‚Äôve felt the pain of working on illiterate ones too. What is the difference? What are the benefits? Based on my experiences, I‚Äôll share good literate projecting practices that have the potential to shift your mindset and reshape your workflow.\n","date":1570006800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560676801,"objectID":"48ecf1cd224d356e6ccdb477054b7c5b","permalink":"https://maggie-98.github.io/talk/2019-ysc-keynote/","publishdate":"2019-06-15T00:00:00Z","relpermalink":"/talk/2019-ysc-keynote/","section":"talk","summary":"‚ÄúLiterate programming‚Äù is an approach to writing software programs that weaves together the source code and documentation at the time of creation. The idea is to create programs that are easier for users to understand.","tags":["oz2019","xaringan"],"title":"The Art of Literate Projecting","type":"talk"},{"authors":["alison"],"categories":["workshop"],"content":"   A full-day workshop for  users who want to get more out of R Markdown (and friends). In this workshop, you will create, publish, and share some beautiful data products. You‚Äôll learn to make:\n Parameterized reports Version-controlled R Markdown projects Templates within a package Shareable scientific/technical articles, slides, dashboards, and websites  ","date":1569834000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560676801,"objectID":"ee3e8b157c41dccee8dc3321a125a577","permalink":"https://maggie-98.github.io/talk/2019-ysc-workshop/","publishdate":"2019-06-15T00:00:00Z","relpermalink":"/talk/2019-ysc-workshop/","section":"talk","summary":"A workshop for R Markdown users who want to get more out of R Markdown (and friends).","tags":["oz2019","rmarkdown"],"title":"Communicating with R Markdown Workshop","type":"talk"},{"authors":null,"categories":["talk"],"content":"In this talk, Alison will talk about one plot‚Äôs life cycle, from a sad Powerpoint slide to an Excel chart and finally to the finished product made with the ggplot2 package in R. Along the way, she will discuss why each version of the plot fails in different ways and how each iteration improved on the last one.\nLatest event     This talk was most recently given at the University of South Wales on 2019/10/04.\n","date":1569521700,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569521700,"objectID":"9eabf590ab5fbb6c07a7a0bffac8fedc","permalink":"https://maggie-98.github.io/talk/2019-rladies-melbourne/","publishdate":"2019-06-15T00:00:00Z","relpermalink":"/talk/2019-rladies-melbourne/","section":"talk","summary":"How I took one sad plot and made it better, and what I learned from it.","tags":["oz2019","xaringan","ggplot2","data visualization"],"title":"Take a Sad Plot \u0026 Make It Better","type":"talk"},{"authors":null,"categories":["website"],"content":"RStudio‚Äôs mission is:\n ‚ÄúTo equip everyone, regardless of means, to participate in a global economy that rewards data literacy.‚Äù\n Our education team supports this mission broadly by supporting people who want to learn R (or learn new things in R), and those who want to teach them. This website is designed for both. This website was built with Hugo, using a theme I developed and maintain. I worked with my former intern, Desir√©e De Leon, to create the original artwork we used for the website.\n","date":1569283200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569283200,"objectID":"7956a6683268e6c427dd5011aea929ce","permalink":"https://maggie-98.github.io/project/education.rstudio.com/","publishdate":"2019-09-24T00:00:00Z","relpermalink":"/project/education.rstudio.com/","section":"project","summary":"All about learning and teaching data science","tags":["website","R","blogdown","education"],"title":"education.rstudio.com","type":"project"},{"authors":["alison"],"categories":null,"content":"   ","date":1568275200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560676801,"objectID":"7db42ee4ca85715118c9128ccb6e1d09","permalink":"https://maggie-98.github.io/talk/2019-rmed-rmd4medicine/","publishdate":"2019-06-16T00:00:00Z","relpermalink":"/talk/2019-rmed-rmd4medicine/","section":"talk","summary":"Using R Markdown in an end-to-end workflow to go from data to manuscript","tags":["rmarkdown","workshop"],"title":"R Markdown for Medicine Workshop","type":"talk"},{"authors":null,"categories":["workshop"],"content":"Starting with a mock clinical trial dataset, we‚Äôll use R Markdown to combine prose, R code, and figures and tables created with R code into a nicely formatted and reproducible final manuscript.\nFor the 2019 R / Medicine conference.\n","date":1568246400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568246400,"objectID":"ea2b240cefb50edff80e97e5f008c094","permalink":"https://maggie-98.github.io/project/rmd4medicine/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/project/rmd4medicine/","section":"project","summary":"A four-hour workshop that will take you on a tour of how to get from data to manuscript using R Markdown.","tags":["R","R Markdown","workshop"],"title":"R Markdown for Medicine","type":"project"},{"authors":["alison"],"categories":["talk"],"content":"   Data science educators have a unique opportunity to teach students the skills they need in their future careers. We know that practical skills matter, like being able to wrangle, explore, analyze, and visualize data (preferably using code), but what is easy to overlook is teaching students how to communicate about data science with other people. Being able to communicate about data, code, and insights gained are important skills we can strengthen in the classroom to make a real impact on students. I will talk about three ways to help strengthen data science communication skills that matter: self-reflection, iteration, and broadcasting. Self-reflection involves asking students to reflect on concepts and/or code that they struggled with to increase engagement with materials and independent problem-solving. Iteration involves revisiting old concepts/code, identifying areas for improvement, and making them better, either independently or in collaboration with peers or other experts/advanced users. Broadcasting involves practice (practice, practice, practice) ‚Äúwrapping up‚Äù code with words into coherent narratives about what a data analysis or visualization means.\n","date":1564434001,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560922981,"objectID":"3fe48e633a761d0dd08d01a2df86f7cc","permalink":"https://maggie-98.github.io/talk/2019-jsm-talk-ds/","publishdate":"2019-06-15T00:00:00Z","relpermalink":"/talk/2019-jsm-talk-ds/","section":"talk","summary":"Practical advice for educators to strengthen data science communication skills in the classroom","tags":["talk","oz2019"],"title":"Teaching Students to Talk about Data Science","type":"talk"},{"authors":["alison"],"categories":["blogdown"],"content":"A hands-on workshop to creating a personal website using blogdown and the Hugo Academic theme.\nFour daily 1-hour sessions (see slides) plus 30-60 minutes of homework for 3 nights.\nSee the project link for all the days of the summer of blogdown.\n","date":1560416400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560416400,"objectID":"f993b93e584a8991b1b6df85dc1e1f89","permalink":"https://maggie-98.github.io/talk/2019-summer-of-blogdown-04/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2019-summer-of-blogdown-04/","section":"talk","summary":"Putting the finishing touches on your blogdown site","tags":["workshop","blogdown"],"title":"Summer of blogdown: Day 04","type":"talk"},{"authors":["alison"],"categories":["blogdown"],"content":"A hands-on workshop to creating a personal website using blogdown and the Hugo Academic theme.\nFour daily 1-hour sessions (see slides) plus 30-60 minutes of homework for 3 nights.\nSee the project link for all the days of the summer of blogdown.\n","date":1560330000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560330000,"objectID":"da4243485df7ef2af3d3ee1b97863edb","permalink":"https://maggie-98.github.io/talk/2019-summer-of-blogdown-03/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2019-summer-of-blogdown-03/","section":"talk","summary":"Keeping up with your content","tags":["workshop","blogdown"],"title":"Summer of blogdown: Day 03","type":"talk"},{"authors":["alison"],"categories":["blogdown"],"content":"A hands-on workshop to creating a personal website using blogdown and the Hugo Academic theme.\nFour daily 1-hour sessions (see slides) plus 30-60 minutes of homework for 3 nights.\nSee the project link for all the days of the summer of blogdown.\n","date":1560243600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560243600,"objectID":"84cb1149e2260c4101c6da2cf93f1db1","permalink":"https://maggie-98.github.io/talk/2019-summer-of-blogdown-02/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2019-summer-of-blogdown-02/","section":"talk","summary":"Personalizing your blogdown site","tags":["workshop","blogdown"],"title":"Summer of blogdown: Day 02","type":"talk"},{"authors":["alison"],"categories":["blogdown"],"content":"A hands-on workshop to creating a personal website using blogdown and the Hugo Academic theme.\nFour daily 1-hour sessions (see slides) plus 30-60 minutes of homework for 3 nights.\nSee the project link for all the days of the summer of blogdown.\n","date":1560157200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560157200,"objectID":"ed19e7a8b14a76fc134cf524da3ca879","permalink":"https://maggie-98.github.io/talk/2019-summer-of-blogdown-01/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/2019-summer-of-blogdown-01/","section":"talk","summary":"Create and deploy our first blogdown site \"out-of-the-box\"","tags":["workshop","blogdown"],"title":"Summer of blogdown: Day 01","type":"talk"},{"authors":["alison"],"categories":["talk"],"content":"\n\n\n\n","date":1559203200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560676801,"objectID":"98f6f544cd94a10de629ea88b6f899ac","permalink":"https://maggie-98.github.io/talk/2019-sdss-blogdown/","publishdate":"2019-05-30T08:00:00Z","relpermalink":"/talk/2019-sdss-blogdown/","section":"talk","summary":"Why and how to teach students to create their own website","tags":["blogdown","xaringan"],"title":"Using blogdown to Connect Beyond the Classroom","type":"talk"},{"authors":["alison"],"categories":["hugo","blogdown"],"content":" \u0026ldquo;Just a spoonful of Hugo helps the blog go down.\u0026rdquo;\n  me, only somewhat kidding  In this series, I\u0026rsquo;m sharing small spoonfuls of Hugo that I have learned that hopefully can help you get your site UP (and even better- more efficient, more streamlined, more automated). You can read the previous posts about my \u0026ldquo;Spoonful of Hugo\u0026rdquo; series about Hugo archetypes, Hugo versions, and Hugo page bundles.\nThe following are a few steps that I always start with to troubleshoot any blogdown/Hugo/Netlify problems. These steps would solve what I would anecdotally estimate as ~50% of blogdown problems that I see posted in the GitHub repository and on the community site.\n#1: Update Hugo    Figure 1: Don't be like this\n If things have gone south and you are getting Hugo errors when you use the \u0026ldquo;Serve Site\u0026rdquo; Addin locally, it is possible that you need to update your version of Hugo. From R, you can check your Hugo version with blogdown:\nblogdown::hugo_version()  Then you can reference your Hugo theme to find the minimum version of Hugo required by your theme:\nFigure 2: Check your theme's minimum Hugo version\n You can go higher than the minimum version though, so it\u0026rsquo;s good practice to update your Hugo, again from within R:\nblogdown:: update_hugo()  Check your version again post-update:\nblogdown::hugo_version()  ## [1] '0.79.0'  If you are using Netlify to build your site using Hugo, you\u0026rsquo;ll want this version to match that- the best way to do that is with a netlify.toml file.\n#2: Change the baseurl    Open up your config.toml file and look for the baseurl field, usually pretty close to the top. Here is mine^[Yes that\u0026rsquo;s right, I don\u0026rsquo;t have a trailing slash- read on for why I can get away with this.]:\nbaseurl = \u0026quot;https://alison.rbind.io\u0026quot;  Now if you are just starting with Hugo and don\u0026rsquo;t actually have a domain name yet, try taking the advice that blogdown automatically prints out for you:\nWarning: You should change the \u0026quot;baseurl\u0026quot; option in config.toml from https://example.org to your actual domain; if you do not have a domain, set \u0026quot;baseurl\u0026quot; to \u0026quot;/\u0026quot;  But be careful here- you shouldn\u0026rsquo;t leave it as \u0026ldquo;/\u0026quot;- once you do have your domain name you should update the baseurl as \u0026ldquo;/\u0026rdquo; is a not a valid URL.\nCare to know more?    Here is a quote from the person who writes the Hugo docs:\n \u0026ldquo;\u0026hellip;the only purpose for the baseurl field in the config is to define the full base URL of your website for deployment purposes.\u0026rdquo; - @ rdwatters\n The main error that would happen without the trailing slash in the past is that you would end up with a site where the theme\u0026rsquo;s CSS would be all wrong. This was probably because the theme designer used code like this buried in a layout file:\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;{{ .Site.BaseURL }}css/style.css\u0026quot;/\u0026gt;  Now, if you set baseurl = \u0026quot;http://mysite.com\u0026quot; but only rendered locally, things would look just peachy, because the default local server already included the trailing slash. So, the link in the html file would be^[https://discourse.gohugo.io/t/how-not-to-specify-url-site/5691/5]:\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;http://localhost:1313/css/style.css\u0026quot;\u0026gt;  But, at build, the link in the html file would turn into:\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;http://mysite.comcss/style.css\u0026quot;\u0026gt;  Which creates sites that look like this:\nFigure 3: Hugo tranquil peak theme\n  GitHub issue #369\nFigure 4: Hugo universal theme\n  GitHub issue #131\n GitHub issue #114\nHowever, Hugo authors and theme developers have largely been moving towards using relative URLs instead of the baseurl to build paths. This was based on public advice voiced by the Hugo authors on the discourse forum. For example:\n \u0026ldquo;The recommended way to reference resources is to use either relURL or absURL template funcs, which handles the slash issues.\u0026quot;- @ bep\n Following that advice, a more up-to-date theme would have code that looks like this buried in a layout file:\n\u0026lt;link rel=\u0026quot;stylesheet\u0026quot; href=\u0026quot;{{ \u0026quot;css/style.css\u0026quot; | relURL }}\u0026quot;/\u0026gt; ‚Üí  Bottom line? If your theme uses relURL or absURL to link to site resources like CSS, JavaScript, or static images, then whether or not you include a trailing slash in your baseurl should not matter at all.\nAnd here is some tough love about your theme: if the most recent version does still require the trailing slash in the baseurl to \u0026ldquo;work\u0026rdquo; out of the box, I would seriously consider switching themes. This is a pretty good \u0026ldquo;canary in the coal mine\u0026rdquo; test regarding how up-to-date the theme author is, and how well the theme you have chosen adheres to Hugo templating best practices. If you are having pain with this now, it is likely not the only thing that will be painful about working with your theme.\n#3: Netlify drag-and-drop    If you can render your site locally but your published site looks different, try the drag-and-drop method:\nUse the \u0026ldquo;Serve Site\u0026rdquo; Addin, then drag-and-drop the public/ folder straight into Netlify. What does this do? You can now see your public site\u0026hellip;that you built\u0026hellip;with your local version of Hugo. Netlify is doing none of the site building here.\nOne of the first benefits of this approach is that it ensures that you are able to actually generate a public/ folder locally! I have seen folks struggle to deploy the wrong repo. This simple step can force you to make sure to use the \u0026ldquo;Serve Site\u0026rdquo; Addin to generate the public/ folder, and that the repo you are trying to link to Netlify actually contains a Hugo site because you must physically move the public/ folder. But this method can also help you diagnose other problems too.\nIf your public/ folder does not render on Netlify, you have work to do locally. I can\u0026rsquo;t tell you what it is as it can be a number of things, but you can be sure that your problem is not just the Netlify build- it is your local build too.\nIf your public/ folder does render perfectly on Netlify, but you are getting a Netlify build error, then you likely have a Hugo version problem. It might be that the version you are running locally is more recent than the version run by Netlify by default to actually build your site. The good news is there is a quick fix for this! The solution is to upgrade the Hugo version Netlify is using- see my advice here for how to do that.\nIf you are happy with how your site looks but you are missing content and/or seeing old deleted content, then you may need the next few strategies to troubleshoot.\n#4: Torch public/    When you are seeing very weird things locally, try deleting your local public/ folder. Then serve site again. Sometimes it can get \u0026ldquo;junked up\u0026rdquo;. I\u0026rsquo;ve found that sometimes deleted content can be a little sticky. As recommended in the blogdown book:\n \u0026ldquo;you are strongly recommended to delete the /public/ directory before you rebuild the site for publishing every time, because Hugo never deletes it\u0026rdquo;\n Also, this has a bonus of reinforcing for you exactly what the \u0026ldquo;Serve Site\u0026rdquo; Addin does - it regenerates the public/ folder. This is also the folder that, if you are using Netlify to build your site, is in your .gitignore file because Netlify (+ Hugo) generates this file \u0026ldquo;fresh\u0026rdquo; with each push to your GitHub repository.\n#5: Peruse public/    When you notice weird things, try actually looking inside public/- don\u0026rsquo;t be afraid to spelunk around in there! If you are seeing something wrong with your site, try to figure out how blogdown/Hugo is processing and rendering your content. This folder can tell you a lot! Keep in mind that your local public/ folder will still contain future/draft/expired content if you used the \u0026ldquo;Serve Site\u0026rdquo; Addin.\n#6: Back to the future    Figure 5: Where are my posts?\n If your site renders beautifully locally, and your drag-and-drop site from public/ looks the same, but you are missing key content when you actually deploy to Netlify using a Hugo build, you may have inadvertently stumbled into a Hugo date time warp. This is a fairly common gotcha. Try using the drag-and-drop method again, this time first delete public/, then instead of using the \u0026ldquo;Serve Site\u0026rdquo; Addin, run this in your console:\nblogdown::build_site(local = FALSE)  Plop this new public folder in Netlify to see what your site will look like when it is actually published. What does this show you? Your local Hugo build (read: your public/ folder generated by \u0026ldquo;Serve Site\u0026rdquo;) differs by design in 3 important ways from your deployed site built by Netlify/Hugo. By default, Hugo will not publish:\n  Content with a future publishDate value\n  Content with draft: true status\n  Content with a past expiryDate value\n  You can see that these are defaults. The behavior of the \u0026ldquo;Serve Site\u0026rdquo; Addin is also documented in the blogdown book:\n \u0026ldquo;This is for you to preview draft and future posts locally.\u0026rdquo;\n Blogdown\u0026rsquo;s build_site(local = FALSE) differs from the \u0026ldquo;Serve Site\u0026rdquo; Addin in that it will not render draft, future, or expired content. So your public/ folder from build_site(local = FALSE) shows you exactly what Netlify should publish. Seeing it can help you troubleshoot why some content was showing up locally but not when you publish.\nThe defaults are pretty sensible and nice to have, as you can still put these kinds of content under version control, and hence collaborate with other team members on the content without having the content publish (or expire) until you say so.\nTo show content that Hugo was hiding, you\u0026rsquo;ll want to edit some YAML fields in the individual offending content files. For example, in the YAML of an individual content file (like a blog post), if you want to un-draft it, add or change this key/value:\ntitle: 'A Spoonful of Hugo: Troubleshooting your Build' author: \u0026quot;Alison Hill\u0026quot; date: '2019-03-04' draft: false  Alternatively, if you want to date something in the future (like to advertise the date of an upcoming talk) but publish now, you can use the publishDate field. The publishDate field is a newer addition to Hugo (\u0026gt;= v0.54.0) which, if left unset, will default to the date field, which means in the individual content file YAML you can do:\ntitle: 'A Spoonful of Hugo: Get excited!!' author: \u0026quot;Alison Hill\u0026quot; date: '2025-03-04' publishDate: '2019-03-04'  Hopefully these 6 things can help you get unstuck. If not, the RStudio community forums are a great place to ask questions!\n","date":1551657600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551657600,"objectID":"aa0f651524120ccd927bd29105287d10","permalink":"https://maggie-98.github.io/post/2019-03-04-hugo-troubleshooting/","publishdate":"2019-03-04T00:00:00Z","relpermalink":"/post/2019-03-04-hugo-troubleshooting/","section":"post","summary":"A few troubleshooting strategies to save your sanity","tags":["blogdown"],"title":"A Spoonful of Hugo: Troubleshooting Your Build","type":"post"},{"authors":["alison"],"categories":["hugo","blogdown"],"content":" \u0026ldquo;Just a spoonful of Hugo helps the blog go down.\u0026rdquo;\n  me, only somewhat kidding  In this series, I\u0026rsquo;m sharing small spoonfuls of Hugo that I have learned that hopefully can help you get your site UP (and even better- more efficient, more streamlined, more automated). You can read the previous posts about my \u0026ldquo;Spoonful of Hugo\u0026rdquo; series about Hugo archetypes and Hugo versions.\nThis is my third post in this series and it is breaking news.\nHugo Page Bundles    Well, not really breaking news, but you still may not know about it! Hugo v0.32 introduced a new feature called Page Bundles, as a way to organize the content files. Blogdown users rejoice that Davis Vaughn posted an issue on the rstudio/blogdown repo to enable this option, which Yihui added shortly before rstudio::conf 2019 üéâ. Here is the snippet from the NEWS.md:\n \u0026ldquo;One benefit of using a page bundle instead of a normal page is that you can put resource files associated with the post (such as images) under the same directory of the post itself. This means you no longer have to put them under the static/ directory, which has been quite confusing to Hugo beginners.\u0026rdquo;\n What does a blogdown/Hugo site begin to look like without page bundles? I think here is a representative example from tidyverse.org (sorry tidyverse team- it\u0026rsquo;s not you, it\u0026rsquo;s the old Hugo).\nFor this team, they need an image for every post, which gets out of control pretty fast. Also, some ended up in static/ too, organized by post (which I have done on my own blog, though not well or consistently).\nWhat would it look like to use page bundles?\ncontent/ ‚îú‚îÄ‚îÄ about ‚îÇ ‚îú‚îÄ‚îÄ index.md ‚îú‚îÄ‚îÄ posts ‚îÇ ‚îú‚îÄ‚îÄ 2015-07-23-hi-world ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ bakers.csv ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ image1.jpg ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ image2.png ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ index.Rmd ‚îÇ ‚îî‚îÄ‚îÄ 2015-07-24-bye-world ‚îÇ ‚îî‚îÄ‚îÄ index.Rmd  One could call this bundled file structure \u0026ldquo;tidier\u0026rdquo; üç±.\nIn the above, after serving site, index.html files also get added to the bundle. In Hugo\u0026rsquo;s terms, these are leaf bundles. The resource files allowed in a bundle include page and non-page items like images, pdf, .csv files, etc.\nThis is instead of:\ncontent/ ‚îú‚îÄ‚îÄ about ‚îÇ ‚îú‚îÄ‚îÄ index.md ‚îú‚îÄ‚îÄ posts ‚îÇ ‚îú‚îÄ‚îÄ 2015-07-23-hi-world.Rmd ‚îÇ ‚îú‚îÄ‚îÄ bakers.csv ‚îÇ ‚îú‚îÄ‚îÄ image1.jpg ‚îÇ ‚îú‚îÄ‚îÄ image2.png ‚îÇ ‚îî‚îÄ‚îÄ 2015-07-24-bye-world.Rmd  When you create a new bundled post, the actual content of the post goes in the index file of a page bundle. So:\n# not bundled post post/2015-07-23-hi-world.Rmd # bundled post post/2015-07-24-bye-world/index.Rmd  Bundle Me, blogdown!    First, read the previous post on setting up a netlify.toml file. Since using Hugo page bundles depends on Hugo v0.32 or higher, you should go ahead and update hugo then update your netlify.toml with your updated version:\nblogdown::update_hugo() blogdown::hugo_version()  Now, let\u0026rsquo;s use the usethis package.\nProject-specific .Rprofile    First, I\u0026rsquo;m going to demo here how to create a project-specific .Rprofile file- but know that you can do a user-level .Rprofile file too.\n# install.packages(\u0026quot;usethis\u0026quot;) # uncomment this to install usethis::edit_r_profile(scope = \u0026quot;project\u0026quot;)  These helpful messages should print to your console: please note the \u0026ldquo;restart\u0026rdquo; reminder\u0026hellip;\n\u0026gt; usethis::edit_r_profile(scope = \u0026quot;project\u0026quot;) ‚óè Restart R for changes to take effect ‚úî Setting active project to '/Users/alison/rprojs/alison.rbind.io' ‚óè Modify '.Rprofile'  Now you could add this to your file:\n# in .Rprofile of the website project if (file.exists(\u0026quot;~/.Rprofile\u0026quot;)) { base::sys.source(\u0026quot;~/.Rprofile\u0026quot;, envir = environment()) } options(blogdown.new_bundle = TRUE)  The first code chunk above is from the blogdown book, where we describe a workaround for loading both user and project .Rprofile files (since R technically only reads one startup profile file).\nIf you don\u0026rsquo;t want this, you could add the blogdown options to your user .Rprofile instead using:\nusethis::edit_r_profile(scope = \u0026quot;user\u0026quot;)  Heck, while you are at it, you could set a bunch of options to make your blogdown life easier:\n# in .Rprofile of the website project if (file.exists(\u0026quot;~/.Rprofile\u0026quot;)) { base::sys.source(\u0026quot;~/.Rprofile\u0026quot;, envir = environment()) } options( blogdown.author = \u0026quot;Alison Hill\u0026quot;, blogdown.ext = \u0026quot;.Rmd\u0026quot;, blogdown.subdir = \u0026quot;post\u0026quot;, blogdown.yaml.empty = TRUE, blogdown.new_bundle = TRUE, blogdown.title_case = TRUE )  For the blogdown-specific options, any of these prepopulate content in your \u0026ldquo;New Post\u0026rdquo; Addin (I told you to use this here). There is a handy table from the blogdown book, summarized here:\n blogdown.author = author of new posts blogdown.ext = default extension of new posts (can also be \u0026ldquo;.md\u0026rdquo; or \u0026ldquo;.Rmarkdown\u0026rdquo;) blogdown.subdir = theme-specific, you need to know your theme and content folder here blogdown.yaml.empty = I told you to do that here blogdown.new_bundle = what this whole post is about! blogdown.title_case = \u0026ldquo;nEed More coFFee\u0026rdquo; \u0026ndash;\u0026gt; \u0026ldquo;Need More Coffee\u0026rdquo; (it tidies all your post titles to title case)  The Newline Thing    Here is a massive .Rprofile gotcha: this file must end with a blank line. So make sure you add an empty line at the end of the file, then save it, and restart your R session.\nWant to make your general R life easier in the future? Follow Yihui\u0026rsquo;s advice and do this in RStudio to ensure that all source files end with a newline:\nUse Bundles    After restarting R, try using the \u0026ldquo;New Post\u0026rdquo; Addin, this time with feeling. There is still one more gotcha though. Use the Addin to create your new bundled post. The only catch is that once you are looking at your exciting new post, you should delete the slug in the YAML (I posted an issue about this here).\nThe reason is that you want the link to your post to be:\nhttp://alison.rbind.io/post/2019-02-21-hugo-page-bundles/\nIf you include the slug, the link to your post will be:\nhttp://alison.rbind.io/post/2019-02-21-hugo-page-bundles/hugo-page-bundles\nAnother option is to update your config.toml file with permalinks like Yihui suggests (but beware: this will change all your past links as well, requiring some Netlify redirects):\n[permalinks] post = \u0026quot;/:year/:month/:day/:slug/\u0026quot;  The default here from Hugo was /post/:year-:month-:day-:slug/:slug/.\nA small note: if you want to add relative links from a blog post to another post in your same blog. So [this](/post/2019-02-19-hugo-archetypes/) becomes this.\nNow, add images and data files to your ‚ù§Ô∏è's content! But you may want to do one more thing\u0026hellip;\nUpdate Metadata    If you are anything like me, you may draft a blog post then come back to it later. For example, I started this post 2 days ago, but want to publish it today, 2020-12-20. The cool thing that was already built-in to blogdown is the \u0026ldquo;Update Metadata\u0026rdquo; Addin. With your blog post open (it should be called index.Rmd)^[If no post is open, you will get an error: Warning message: The current document does not seem to contain YAML metadata], click on Addins and select \u0026ldquo;Update Metadata\u0026rdquo;. You should see a window like this:\nCheck the box to rename the file if the date has changed. RStudio will tell you your file has been deleted- which is technically true since the folder was renamed, but don\u0026rsquo;t panic!\nClick YES. The index.Rmd file that is now open should have an updated date field in the YAML. In your RStudio file viewer, you may want to click on \u0026ldquo;content\u0026rdquo; at this point then navigate back to view your post- then you will then see that the folder name now has an updated date too.\n","date":1550707200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550707200,"objectID":"8247953d60638c36223f67010de8d1ce","permalink":"https://maggie-98.github.io/post/2019-02-21-hugo-page-bundles/","publishdate":"2019-02-21T00:00:00Z","relpermalink":"/post/2019-02-21-hugo-page-bundles/","section":"post","summary":"Why (and how) you should use Hugo's new page bundles feature","tags":["blogdown"],"title":"A Spoonful of Hugo: Page Bundles","type":"post"},{"authors":["alison"],"categories":["blogdown","netlify","hugo"],"content":" \u0026ldquo;Just a spoonful of Hugo helps the blog go down.\u0026rdquo;\n  me, only somewhat kidding  You can read the previous post about my \u0026ldquo;Spoonful of Hugo\u0026rdquo; series here. In this series, I\u0026rsquo;m sharing small spoonfuls of Hugo that I have learned that hopefully can help you get your site UP (and even better- more efficient, more streamlined, more automated).\nThis is my second post in this series, and it is a relatively quick one. Just do this. This one is a no-brainer.\n Thanks to Mara Averick for alerting me that with Hugo version 0.54.0 and onward, there is a trailing zero at the end of Hugo versions now. So for versions before 0.54.0, use the format: 0.53; for later versions use 0.54.0 (0.54 will not work).   Use Netlify to Deploy    First, you\u0026rsquo;ll need to use Netlify! I am a very happy Netlify user and currently have approximately 33 sites deployed. To setup a new account, navigate to Netlify and click on the Sign Up link.\nSign up with GitHub to connect your GitHub and Netlify accounts (as shown below).\nIf you use a different version control service, select GitLab or BitBucket instead.\nThe last step is to use the Netlify UI in browser do New Site from Git \u0026gt; pick your repo. You\u0026rsquo;ll be prompted to fill in these fields, they are probably already filled in correctly for you:\nThe next part is the advanced build settings:\nSee that pro tip about the netlify.toml? Let\u0026rsquo;s do that! You can leave these fields as is.\nWhy netlify.toml?    In their Build Gotchas:\n \u0026ldquo;If your build works locally, the next debugging step is to ensure the package versions we use to build match yours. You can find the settings for these in the Build Settings doc. That‚Äôs the leading cause of build failure.\u0026rdquo;\n Yes that is right- package version mismatches are the leading cause of build failure with Netlify. What does this look like for blogdown users? This means that you are running a version of Hugo locally that doesn\u0026rsquo;t match the version that Netlify is using to build your site. Most of the time, you are using a more recent version of Hugo than the one Netlify uses. This means that the files your theme relies on may be using newer Hugo functions that were introduced in later Hugo versions- functions that Netlify won\u0026rsquo;t be able to find working from an older Hugo version. You\u0026rsquo;ll get all the build errors.\nYou can check your local Hugo version by running this code in your R console:\nblogdown::hugo_version()  ## [1] '0.79.0'  Now, we want Netlify to use this same version of Hugo when it builds your site. You can do this two ways:\n Do this in your browser (üëé) Do this in your project root directory in a netlify.toml file (üëç)  Add the netlify.toml File    Adding this file means that team members can see for themselves what version of Hugo you are running- if it is buried in the Netlify UI, you can\u0026rsquo;t see that information unless you sift through the public build logs (no thanks). Making the file as plain text in the root of your blogdown project directory means that:\n it is version controlled (yay!) and other people who use/learn from/contribute to your blog can actually reproduce your site with the same site configuration. Bonus: you can set the Hugo versions for branch deploys too.  Here is an example from my own netlify.toml file^[the leading zero matters for Hugo versions, so 0.53 works but .53 will not. For versions \u0026gt;= 0.54.0, the trailing zero also matters, so 0.54.0 works but 0.54 will not.]:\n[build] publish = \u0026quot;public\u0026quot; command = \u0026quot;hugo\u0026quot; [context.production.environment] HUGO_VERSION = \u0026quot;0.54.0\u0026quot; # if older, use format: 0.53 (no trailing zero) HUGO_ENV = \u0026quot;production\u0026quot; HUGO_ENABLEGITINFO = \u0026quot;true\u0026quot; [context.branch-deploy.environment] HUGO_VERSION = \u0026quot;0.54.0\u0026quot; # if older, use format: 0.53 (no trailing zero) [context.deploy-preview.environment] HUGO_VERSION = \u0026quot;0.54.0\u0026quot;  You can leave off the last two chunk if you don\u0026rsquo;t want to use branch deploys or preview deploys, but I ‚ù§Ô∏è these two Netlify features and encourage you to try them out. I\u0026rsquo;ve starting drafting individual blog posts and tutorials in branches, and then I can see them rendered and share them for feedback without asking collaborators to clone and build the repository locally. It is lovely. Every branch and pull request gets a link üéâ.\nSo add this file to your blogdown site repo and push to GitHub.\nNote that, according to the Netlify docs:\n \u0026ldquo;During a build, the following ordering determines which context covers a particular deploy: UI settings are overridden if a netlify.toml file is present in the root folder of the repo and there exists a setting for the same property/redirect/header in the toml file.\u0026rdquo;\n If you look in your site\u0026rsquo;s Netlify deploy log, you should see entries like this:\n7:47:13 PM: Found netlify.toml. Overriding site configuration 7:47:13 PM: Starting build script 7:47:13 PM: Installing dependencies 7:47:14 PM: Started restoring cached node version 7:47:17 PM: Finished restoring cached node version 7:47:18 PM: v8.15.0 is already installed. 7:47:19 PM: Now using node v8.15.0 (npm v6.4.1) 7:47:19 PM: Attempting ruby version 2.3.6, read from environment 7:47:20 PM: Using ruby version 2.3.6 7:47:20 PM: Using PHP version 5.6 7:47:20 PM: Installing Hugo 0.54.0  Success!\n","date":1550620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550620800,"objectID":"9ad19405c52567816b65535d9ba42dec","permalink":"https://maggie-98.github.io/post/2019-02-19-hugo-netlify-toml/","publishdate":"2019-02-20T00:00:00Z","relpermalink":"/post/2019-02-19-hugo-netlify-toml/","section":"post","summary":"Why you should use a netlify.toml file in your blogdown site","tags":["blogdown","netlify","hugo"],"title":"A Spoonful of Hugo: The netlify.toml File","type":"post"},{"authors":["alison"],"categories":["hugo","blogdown"],"content":" \u0026ldquo;Just a spoonful of Hugo helps the blog go down.\u0026rdquo;\n  me, only somewhat kidding  As a happy blogdown user, a common story I hear from other #rstats users is that you try to change one little thing in Hugo, and the whole site breaks. Here be dragons for folks who aren\u0026rsquo;t web developers.\nI\u0026rsquo;m here to tell you that there are small spoonfuls of Hugo that can help you get your site UP (and even better- more efficient, more streamlined, more automated), even if you are not in the least bit interested in transitioning into a career in web development üòè.\nMy Project    The education team at RStudio needs a website and we have a short wishlist:\n We want something we can maintain ourselves, We want to look consistent with other RStudio sites on the outside, and We want to be consistent on the inside so that we can get help if/when we need it.  This led me to the current tidyverse.org blogdown site. I wanted to make a copy of the site then customize for the education team, but I noticed that the source code for the site didn\u0026rsquo;t make it easy for me to copy the structure of the site and edit only the content of the site. This is one of the real strengths of Hugo, so I embarked on a learning adventure.\n via GIPHY\n As a result, I have been living and breathing Hugo lately. As in, my husband now recognizes Mike Dane\u0026rsquo;s voice. You may not have have met Mike yet, but he appears in all the video tutorials in the Hugo docs. His screencasts have been really helpful to me, like this one on templating. I\u0026rsquo;ve also spent a lot of time actually reading the docs (which are pretty good!), reading posts and answers on the Hugo discourse community site, and spelunking around inside the actual source code for two very well structured Hugo sites:\n The actual Hugo site: https://github.com/gohugoio/hugoDocs The rOpenSci site: https://github.com/ropensci/roweb2  I\u0026rsquo;ll be using this post and other later posts to share some of the things I\u0026rsquo;ve learned about Hugo along the way. Mainly breadcrumbs to myself, but I hope these help other people too.\nFor reference, I\u0026rsquo;m using Hugo via the blogdown R package, and within the RStudio IDE. These are my blogdown and Hugo versions:\npackageVersion(\u0026quot;blogdown\u0026quot;)  ## [1] '0.21.61'  blogdown::hugo_version()  ## [1] '0.79.0'  tl;dr: A Teaspoon of Archetypes      Add custom archetypes as .md files to your project root directory (do not touch the archetypes folder in your themes/archetypes folder).\n If you don\u0026rsquo;t have that as an empty folder in your project root, make one, then add your archetype files to it. If you are making a new blogdown site, I recommend using these options to keep your empty directories^[These setup options are newish to the blogdown package: https://github.com/rstudio-education/arm-workshop-rsc2019/issues/8]:  library(blogdown) new_site(theme = \u0026quot;jpescador/hugo-future-imperfect\u0026quot;, sample = TRUE, theme_example = TRUE, empty_dirs = TRUE, # this! to_yaml = TRUE)  (\\#fig:proj-wizard)Using the RStudio Project Wizard\n   Use the \u0026ldquo;New Post\u0026rdquo; Addin in RStudio to create any and all new content for your site (not just posts!). Be sure to use the handy dropdown menu to select from all the possible archetypes. Also, careful about the subdirectory here- some themes use blog, others use news, articles, or posts.\n  Your archetypes, while only markdown files, can include R code. When you use the Addin, be sure to choose R Markdown (.Rmd) as the format so that you can run the code.\n Don\u0026rsquo;t miss this great blog post by my friend and the great educator Leo Collado-Torres on archetypes.    A Tablespoon of Archetypes    One of the easiest things you can do for yourself is customize your site\u0026rsquo;s archetypes. From the Hugo docs:\n \u0026ldquo;Archetypes are templates used when creating new content.\u0026rdquo;\n Right away when I cloned the tidyverse site, I noticed that there were instructions for how to contribute a new article (or blog post) in the README.md and in a separate CONTRIBUTING.md file. Then I noticed this open GitHub issue from Mara Averick (the tidyverse developer advocate) titled \u0026ldquo;Fix README/CONTRIBUTING so there\u0026rsquo;s one source of mechanical info?\u0026rdquo;.\nI also noticed that there was no project root folder called archetypes, which is where you would store your custom site archetype files as .md files. In fact, there is no theme folder as you might expect either, which is where you could view the default theme archetypes. Let\u0026rsquo;s look at some from other Hugo themes:\n  The default Hugo theme for blogdown, Lithium, has just one archetype: default.md\n--- title: '' date: '' ---    In contrast, the Hugo Academic theme has A LOT: https://github.com/gcushen/hugo-academic/tree/master/archetypes; here is the content of the one for new posts:\n+++ title = \u0026quot;{{ replace .Name \u0026quot;-\u0026quot; \u0026quot; \u0026quot; | title }}\u0026quot; subtitle = \u0026quot;\u0026quot; # Add a summary to display on homepage (optional). summary = \u0026quot;\u0026quot; date = {{ .Date }} draft = false # Authors. Comma separated list, e.g. `[\u0026quot;Bob Smith\u0026quot;, \u0026quot;David Jones\u0026quot;]`. authors = [] # Tags and categories # For example, use `tags = []` for no tags, or the form `tags = [\u0026quot;A Tag\u0026quot;, \u0026quot;Another Tag\u0026quot;]` for one or more tags. tags = [] categories = [] # Projects (optional). # Associate this post with one or more of your projects. # Simply enter your project's folder or file name without extension. # E.g. `projects = [\u0026quot;deep-learning\u0026quot;]` references # `content/project/deep-learning/index.md`. # Otherwise, set `projects = []`. # projects = [\u0026quot;internal-project\u0026quot;] # Featured image # To use, add an image named `featured.jpg/png` to your page's folder. [image] # Caption (optional) caption = \u0026quot;\u0026quot; # Focal point (optional) # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight focal_point = \u0026quot;\u0026quot; +++    A quick note: you may have noticed differences in both the content between these two files but also the structure. The first is a YAML file, the second is a TOML file. For blogdown users, you may want to use YAML. This is also why I recommend when you set up your site to use the to_yaml = TRUE option (in the Project Wizard from figure 1, check the \u0026ldquo;Convert all metadata to YAML\u0026rdquo; box; otherwise, the exampleSite will contain TOML instead of YAML)^[If you end up with TOML in your content files, run this R code: hugo_convert(to = \u0026quot;YAML\u0026quot;, unsafe = TRUE)].\nIf you read the original tidyverse CONTRIBUTING.md file, the instructions include a fair bit of R code that I would guess means a lot of copying and pasting into new posts. For example, the R Markdown setup chunk and the code for using usethis::use_tidy_thanks() for package releases. I studied the contributing guidelines, and parsed three different \u0026ldquo;kinds\u0026rdquo; of articles that are commonly contributed, each with a different archetype:\n  The default.md- this is just for plain old markdown posts and basically sets up the YAML of the post to be the same as it is now (currently, there is no archetype dictating the content- it is pulling from a project-level .Rprofile).\n  A default-rmarkdown.md which should only be used with an R Markdown post and provides only the setup chunk at the top.\n  A package-release.md which also should only be used with an R Markdown post and adds the usethis::use_tidy_thanks() code chunk (this is pseudo-code so the default chunk option is set to eval = FALSE).\n  So I drafted a pull request that adds these three archetypes to the GitHub repository for the tidyverse.org. Here is the \u0026ldquo;after\u0026rdquo; Addin view:\nHere\u0026rsquo;s hoping Hugo archetypes make some things about adding new content to your site easier. There is no Hugo involved, other than realizing that Hugo will look first in your themes/\u0026lt;THEME-NAME\u0026gt;/archetypes/ folder, then in your project root archetypes/ folder next. DO NOT TOUCH any files in your themes/ directory.^[Trust me on this one- if you ever want to update your site this will make that process way harder.]\nYou may want to set up archetypes for your blogdown site if you have a \u0026ldquo;signature\u0026rdquo; R setup chunk that loads your preferred knitr chunk options, common libraries you always load at setup like tidyverse, ggplot2 themes you prefer (theme_minimal() FTW), etc. This may be especially helpful if you have multiple team members contributing to a single site and you want their posts to have a uniform setup. Then archetypes can be a real time- and sanity-saver. Get more ideas from Leo\u0026rsquo;s blog post on archetypes. You can also make directory based archetypes if you use Hugo page bundles, which is a topic of a future post.\n","date":1550534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550534400,"objectID":"96f40179e82d4209f4b096e29128f9fe","permalink":"https://maggie-98.github.io/post/2019-02-19-hugo-archetypes/","publishdate":"2019-02-19T00:00:00Z","relpermalink":"/post/2019-02-19-hugo-archetypes/","section":"post","summary":"Why you should use Hugo archetypes in your blogdown site","tags":["blogdown"],"title":"A Spoonful of Hugo: Archetypes","type":"post"},{"authors":["alison"],"categories":null,"content":"\n\n\n\n","date":1547568000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560676801,"objectID":"08000c474d9d861f3646b4929c648330","permalink":"https://maggie-98.github.io/talk/2019-rsc-blogdown/","publishdate":"2019-01-15T16:00:00Z","relpermalink":"/talk/2019-rsc-blogdown/","section":"talk","summary":"Making websites in R Markdown","tags":["blogdown","rmarkdown","workshop"],"title":"Meet blogdown","type":"talk"},{"authors":["alison"],"categories":null,"content":"\n\n\n\n","date":1547560800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560676801,"objectID":"5eb87ad8f04a55de4b00e604d81cc5ab","permalink":"https://maggie-98.github.io/talk/2019-rsc-bookdown/","publishdate":"2019-01-15T14:00:00Z","relpermalink":"/talk/2019-rsc-bookdown/","section":"talk","summary":"Making books in R Markdown","tags":["bookdown","rmarkdown","workshop"],"title":"Meet bookdown","type":"talk"},{"authors":["alison"],"categories":null,"content":"\n\n\n\n","date":1547550000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560676801,"objectID":"cfd02b0f77af223114478b426428ded0","permalink":"https://maggie-98.github.io/talk/2019-rsc-flexdashboard/","publishdate":"2019-01-15T11:00:00Z","relpermalink":"/talk/2019-rsc-flexdashboard/","section":"talk","summary":"Making dashboards in R Markdown","tags":["flexdashboard","rmarkdown","workshop"],"title":"Meet flexdashboard","type":"talk"},{"authors":["alison"],"categories":null,"content":"\n\n\n\n","date":1547542800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560676801,"objectID":"1c019db57970056312c4dafa0db58d3e","permalink":"https://maggie-98.github.io/talk/2019-rsc-xaringan/","publishdate":"2019-01-15T09:00:00Z","relpermalink":"/talk/2019-rsc-xaringan/","section":"talk","summary":"Making slides in R Markdown","tags":["xaringan","rmarkdown","workshop"],"title":"Meet xaringan","type":"talk"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"98ce4cbc06beb227d5e4c75070a62253","permalink":"https://maggie-98.github.io/project/hugo-graphite/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/project/hugo-graphite/","section":"project","summary":"A Hugo theme for RStudio teams (Education, Tidyverse, Tidymodels)","tags":["hugo","software"],"title":"Hugo Graphite","type":"project"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"6087c0ef875554f4409ac52928d79279","permalink":"https://maggie-98.github.io/projects/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/projects/","section":"","summary":"See some of the projects I have worked on","tags":null,"title":"Projects","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"https://maggie-98.github.io/about/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/about/","section":"","summary":"A little more about me and how to get in touch","tags":null,"title":"Resume","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"3960dd3bdc6f629fb800d1d2aaa7224f","permalink":"https://maggie-98.github.io/resume/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/resume/","section":"","summary":"More about my work experience","tags":null,"title":"Resume","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"65de3680a280f6bf29dc34fe1adad5a6","permalink":"https://maggie-98.github.io/talks/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/talks/","section":"","summary":"Upcoming and recent talks / workshops","tags":null,"title":"Talks \u0026 Workshops","type":"widget_page"},{"authors":null,"categories":["talk"],"content":"Using one dataset from The Great British Bake Off, I show eleven ways to visualize one dataset using eleven different versions of \u0026ldquo;tidy data.\u0026rdquo; Take-away messages:\n Tidy data is the start of your data wrangling journey, not the end There is not a single \u0026ldquo;tidy\u0026rdquo; version of a dataset Tidy data does make you more nimble!  ","date":1540828800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540828800,"objectID":"6c60d3595393f78550cfb351664ee016","permalink":"https://maggie-98.github.io/talk/2018-uo-plotoff/","publishdate":"2018-10-29T16:00:00Z","relpermalink":"/talk/2018-uo-plotoff/","section":"talk","summary":"One dataset from 'The Great British Bake Off', visualized eleven ways.","tags":["xaringan","ggplot2","data visualization"],"title":"Data Visualization in the Tidyverse","type":"talk"},{"authors":["alison"],"categories":["readr","readxl","data import"],"content":" A shorter version of this blog post now appears as an article vignette for the readxl package, thank you to Jenny Bryan for the invitation!   A problem I run up against a lot when working with other people\u0026rsquo;s data is having multiple header rows in the source data file. I like to use readr functions to read in rectangular data like .csv and .tsv files, but if you skip rows at import using the skip argument, you lose the header row as well, which usually has column names. The problem I often have is that the header row has column names that I want to keep, but I\u0026rsquo;d like to skip the second row (or more), which has some junk in it. Usually this row is some kind of data dictionary inserted between the row of column names and the actual data.\nIn this post, I\u0026rsquo;ll walk through a solution to this problem, using the readr package. You can also watch along in the video.\n  Warning!: I made a mistake when I said readr uses the first 100 rows of your data to predict column types- it uses the first 1000 rows.\n  Download stickers.csv\n Being sticker rich    This dataset is from an article published in PLOS ONE called \u0026ldquo;Being Sticker Rich: Numerical Context Influences Children‚Äôs Sharing Behavior\u0026rdquo;. In this study, children (ages 3‚Äì11) received a small (12, ‚Äústicker poor‚Äù) or large (30, ‚Äústicker rich‚Äù) number of stickers, and were then given the opportunity to share their windfall with either one or multiple anonymous recipients. This type of experimental design is a version of the Dictator Game.\nThe main research questions the authors explored were: do the number of available resources and/or the number of potential recipients alter the likelihood of a child donating and/or the amount they donate? But, in order to answer this question, we have to be able to read in the data! Luckily, these lovely developmental psychologists opted to share their data on the Harvard Dataverse as a tab-delimited file.\nIf you download the file, you can open it up in a plain text editor. You can also open it with Microsoft Excel. Read in the file    Let\u0026rsquo;s start by creating a variable called link to store the link to the data file.\n# create variable to store url link \u0026lt;- \u0026quot;https://dataverse.harvard.edu/api/access/datafile/2712105\u0026quot;  The file has a .tab extension, so we know it is tab-delimited. This means that the right readr function for reading this file is read_tsv. Since we stored our link already as a character string, that is the only argument to the read_tsv function.\n#install.packages(\u0026quot;readr\u0026quot;) library(readr) # load the readr package stickers \u0026lt;- read_tsv(link) # spec()  Now, we know the second row of data is wonky, but how can we see that in R? There are a number of ways we can go spelunking around into our data file. The easiest to print it. Since we used readr, we have a tibble, which nicely prints to screen.\nstickers  # # A tibble: 402 x 18 # SubjectNumber Condition NumberStickers NumberEnvelopes Gender Agemonths # \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; # 1 [Included Sa‚Ä¶ 1=12:1; ‚Ä¶ 1=12; 2=30 1=1 recipient;‚Ä¶ 1=fem‚Ä¶ NA # 2 1 1 1 1 1 36 # 3 2 1 1 1 2 36 # 4 3 1 1 1 2 36 # 5 4 1 1 1 1 36 # 6 5 1 1 1 2 36 # 7 6 1 1 1 2 36 # 8 7 2 1 2 1 36 # 9 8 2 1 2 2 36 # 10 9 3 2 1 2 36 # # ‚Ä¶ with 392 more rows, and 12 more variables: Ageyears \u0026lt;dbl\u0026gt;, Agegroups \u0026lt;chr\u0026gt;, # # `Subject'sEnvelope` \u0026lt;chr\u0026gt;, LeftEnvelope \u0026lt;chr\u0026gt;, RightEnvelope \u0026lt;chr\u0026gt;, # # `absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)` \u0026lt;chr\u0026gt;, # # `PercentGiven(Outof100percent)` \u0026lt;chr\u0026gt;, Giveornot \u0026lt;chr\u0026gt;, # # LargerEnvelopeabs \u0026lt;chr\u0026gt;, LargeEnvelopepercent \u0026lt;chr\u0026gt;, # # SmallerEnvelopeabs \u0026lt;chr\u0026gt;, SmallEnvelopepercent \u0026lt;chr\u0026gt;  Unfortunately, dplyr::glimpse can\u0026rsquo;t help us much, because we have one variable name that is ridiculously long (absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)). We\u0026rsquo;ll fix that with dplyr::rename.\nlibrary(dplyr) glimpse(stickers)  # Rows: 402 # Columns: 18 # $ SubjectNumber \u0026lt;chr\u0026gt; ‚Ä¶ # $ Condition \u0026lt;chr\u0026gt; ‚Ä¶ # $ NumberStickers \u0026lt;chr\u0026gt; ‚Ä¶ # $ NumberEnvelopes \u0026lt;chr\u0026gt; ‚Ä¶ # $ Gender \u0026lt;chr\u0026gt; ‚Ä¶ # $ Agemonths \u0026lt;dbl\u0026gt; ‚Ä¶ # $ Ageyears \u0026lt;dbl\u0026gt; ‚Ä¶ # $ Agegroups \u0026lt;chr\u0026gt; ‚Ä¶ # $ `Subject'sEnvelope` \u0026lt;chr\u0026gt; ‚Ä¶ # $ LeftEnvelope \u0026lt;chr\u0026gt; ‚Ä¶ # $ RightEnvelope \u0026lt;chr\u0026gt; ‚Ä¶ # $ `absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)` \u0026lt;chr\u0026gt; ‚Ä¶ # $ `PercentGiven(Outof100percent)` \u0026lt;chr\u0026gt; ‚Ä¶ # $ Giveornot \u0026lt;chr\u0026gt; ‚Ä¶ # $ LargerEnvelopeabs \u0026lt;chr\u0026gt; ‚Ä¶ # $ LargeEnvelopepercent \u0026lt;chr\u0026gt; ‚Ä¶ # $ SmallerEnvelopeabs \u0026lt;chr\u0026gt; ‚Ä¶ # $ SmallEnvelopepercent \u0026lt;chr\u0026gt; ‚Ä¶  More options:\nhead(stickers)  # # A tibble: 6 x 18 # SubjectNumber Condition NumberStickers NumberEnvelopes Gender Agemonths # \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; # 1 [Included Sa‚Ä¶ 1=12:1; ‚Ä¶ 1=12; 2=30 1=1 recipient;‚Ä¶ 1=fem‚Ä¶ NA # 2 1 1 1 1 1 36 # 3 2 1 1 1 2 36 # 4 3 1 1 1 2 36 # 5 4 1 1 1 1 36 # 6 5 1 1 1 2 36 # # ‚Ä¶ with 12 more variables: Ageyears \u0026lt;dbl\u0026gt;, Agegroups \u0026lt;chr\u0026gt;, # # `Subject'sEnvelope` \u0026lt;chr\u0026gt;, LeftEnvelope \u0026lt;chr\u0026gt;, RightEnvelope \u0026lt;chr\u0026gt;, # # `absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)` \u0026lt;chr\u0026gt;, # # `PercentGiven(Outof100percent)` \u0026lt;chr\u0026gt;, Giveornot \u0026lt;chr\u0026gt;, # # LargerEnvelopeabs \u0026lt;chr\u0026gt;, LargeEnvelopepercent \u0026lt;chr\u0026gt;, # # SmallerEnvelopeabs \u0026lt;chr\u0026gt;, SmallEnvelopepercent \u0026lt;chr\u0026gt;  tail(stickers)  # # A tibble: 6 x 18 # SubjectNumber Condition NumberStickers NumberEnvelopes Gender Agemonths # \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; # 1 396 1 1 1 2 136 # 2 397 4 2 2 1 136 # 3 398 1 1 1 1 137 # 4 399 1 1 1 2 137 # 5 400 4 2 2 2 139 # 6 401 3 2 1 1 143 # # ‚Ä¶ with 12 more variables: Ageyears \u0026lt;dbl\u0026gt;, Agegroups \u0026lt;chr\u0026gt;, # # `Subject'sEnvelope` \u0026lt;chr\u0026gt;, LeftEnvelope \u0026lt;chr\u0026gt;, RightEnvelope \u0026lt;chr\u0026gt;, # # `absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)` \u0026lt;chr\u0026gt;, # # `PercentGiven(Outof100percent)` \u0026lt;chr\u0026gt;, Giveornot \u0026lt;chr\u0026gt;, # # LargerEnvelopeabs \u0026lt;chr\u0026gt;, LargeEnvelopepercent \u0026lt;chr\u0026gt;, # # SmallerEnvelopeabs \u0026lt;chr\u0026gt;, SmallEnvelopepercent \u0026lt;chr\u0026gt;  names(stickers)  # [1] \u0026quot;SubjectNumber\u0026quot; # [2] \u0026quot;Condition\u0026quot; # [3] \u0026quot;NumberStickers\u0026quot; # [4] \u0026quot;NumberEnvelopes\u0026quot; # [5] \u0026quot;Gender\u0026quot; # [6] \u0026quot;Agemonths\u0026quot; # [7] \u0026quot;Ageyears\u0026quot; # [8] \u0026quot;Agegroups\u0026quot; # [9] \u0026quot;Subject'sEnvelope\u0026quot; # [10] \u0026quot;LeftEnvelope\u0026quot; # [11] \u0026quot;RightEnvelope\u0026quot; # [12] \u0026quot;absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)\u0026quot; # [13] \u0026quot;PercentGiven(Outof100percent)\u0026quot; # [14] \u0026quot;Giveornot\u0026quot; # [15] \u0026quot;LargerEnvelopeabs\u0026quot; # [16] \u0026quot;LargeEnvelopepercent\u0026quot; # [17] \u0026quot;SmallerEnvelopeabs\u0026quot; # [18] \u0026quot;SmallEnvelopepercent\u0026quot;  # View()  Now we are ready to diagnose the problem!\nProblem: the first row is not really data. It is metadata about the variables, and it is screwing up readr\u0026rsquo;s ability to predict our column types.\nSolution: we\u0026rsquo;ll use readr and the read_tsv() function to read in the data twice. In Step 1, we\u0026rsquo;ll create a character vector of the column names only. In Step 2, we\u0026rsquo;ll read in the actual data and skip the multiple header rows at the top. When we do this, we lose the column names, so we use the character vector of column names we created in Step 1 instead.\nRead in the file (again)    Step 1    Goal: we want to read in the first row only and save it as a character vector called sticker_names. This row contains the correct column names that we\u0026rsquo;ll need in Step 2.\nsticker_names \u0026lt;- link %\u0026gt;% read_tsv(n_max = 0) %\u0026gt;% # default: col_names = TRUE rename(stickersgiven = 'absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)') %\u0026gt;% names() sticker_names  # [1] \u0026quot;SubjectNumber\u0026quot; \u0026quot;Condition\u0026quot; # [3] \u0026quot;NumberStickers\u0026quot; \u0026quot;NumberEnvelopes\u0026quot; # [5] \u0026quot;Gender\u0026quot; \u0026quot;Agemonths\u0026quot; # [7] \u0026quot;Ageyears\u0026quot; \u0026quot;Agegroups\u0026quot; # [9] \u0026quot;Subject'sEnvelope\u0026quot; \u0026quot;LeftEnvelope\u0026quot; # [11] \u0026quot;RightEnvelope\u0026quot; \u0026quot;stickersgiven\u0026quot; # [13] \u0026quot;PercentGiven(Outof100percent)\u0026quot; \u0026quot;Giveornot\u0026quot; # [15] \u0026quot;LargerEnvelopeabs\u0026quot; \u0026quot;LargeEnvelopepercent\u0026quot; # [17] \u0026quot;SmallerEnvelopeabs\u0026quot; \u0026quot;SmallEnvelopepercent\u0026quot;  glimpse(sticker_names)  # chr [1:18] \u0026quot;SubjectNumber\u0026quot; \u0026quot;Condition\u0026quot; \u0026quot;NumberStickers\u0026quot; \u0026quot;NumberEnvelopes\u0026quot; ...  Step 2    Goal: we want to read in all the rows except for the first two rows, which contained the variable names and variable descriptions. We want to save this as stickers, and set the column names to the sticker_names object we created in Step 1.\nstickers \u0026lt;- link %\u0026gt;% read_tsv(skip = 2, col_names = sticker_names) glimpse(stickers)  # Rows: 401 # Columns: 18 # $ SubjectNumber \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12‚Ä¶ # $ Condition \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 3, 3‚Ä¶ # $ NumberStickers \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2‚Ä¶ # $ NumberEnvelopes \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1‚Ä¶ # $ Gender \u0026lt;dbl\u0026gt; 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1‚Ä¶ # $ Agemonths \u0026lt;dbl\u0026gt; 36, 36, 36, 36, 36, 36, 36, 36, 36, 3‚Ä¶ # $ Ageyears \u0026lt;dbl\u0026gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3‚Ä¶ # $ Agegroups \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶ # $ `Subject'sEnvelope` \u0026lt;dbl\u0026gt; 7, 12, 4, 7, 12, 8, 8, 11, 26, 30, 12‚Ä¶ # $ LeftEnvelope \u0026lt;dbl\u0026gt; 5, 0, 8, 5, 0, 4, 2, 1, 4, 0, 18, 18,‚Ä¶ # $ RightEnvelope \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 2, 0, NA, NA,‚Ä¶ # $ stickersgiven \u0026lt;dbl\u0026gt; 5, 0, 8, 5, 0, 4, 4, 1, 4, 0, 18, 18,‚Ä¶ # $ `PercentGiven(Outof100percent)` \u0026lt;dbl\u0026gt; 0.42, 0.00, 0.67, 0.42, 0.00, 0.33, 0‚Ä¶ # $ Giveornot \u0026lt;dbl\u0026gt; 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0‚Ä¶ # $ LargerEnvelopeabs \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 2, 1, NA, NA,‚Ä¶ # $ LargeEnvelopepercent \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 0.5000000, 1.‚Ä¶ # $ SmallerEnvelopeabs \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 2, 0, NA, NA,‚Ä¶ # $ SmallEnvelopepercent \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 0.5000000, 0.‚Ä¶  Fin!    All together now: the final solution!\n# load packages library(readr) library(dplyr) # create variable to store url link \u0026lt;- \u0026quot;https://dataverse.harvard.edu/api/access/datafile/2712105\u0026quot; # read in column names only sticker_names \u0026lt;- link %\u0026gt;% read_tsv(n_max = 0) %\u0026gt;% # default: col_names = TRUE rename(stickersgiven = 'absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)') %\u0026gt;% names() # read in data, set column names stickers \u0026lt;- link %\u0026gt;% read_tsv(skip = 2, col_names = sticker_names)  Addendum    For good measure, I would add a final step to everything above and use janitor::clean_names() to put all the variable names into snake case. So my final final solution is here:\n# load packages library(readr) library(dplyr) library(janitor) # create variable to store url link \u0026lt;- \u0026quot;https://dataverse.harvard.edu/api/access/datafile/2712105\u0026quot; # read in column names only sticker_names \u0026lt;- link %\u0026gt;% read_tsv(n_max = 0) %\u0026gt;% # default: col_names = TRUE rename(stickersgiven = 'absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)') %\u0026gt;% names() # read in data, set column names stickers \u0026lt;- link %\u0026gt;% read_tsv(skip = 2, col_names = sticker_names) %\u0026gt;% clean_names()  stickers  # # A tibble: 401 x 18 # subject_number condition number_stickers number_envelopes gender agemonths # \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; # 1 1 1 1 1 1 36 # 2 2 1 1 1 2 36 # 3 3 1 1 1 2 36 # 4 4 1 1 1 1 36 # 5 5 1 1 1 2 36 # 6 6 1 1 1 2 36 # 7 7 2 1 2 1 36 # 8 8 2 1 2 2 36 # 9 9 3 2 1 2 36 # 10 10 3 2 1 2 36 # # ‚Ä¶ with 391 more rows, and 12 more variables: ageyears \u0026lt;dbl\u0026gt;, agegroups \u0026lt;dbl\u0026gt;, # # subjects_envelope \u0026lt;dbl\u0026gt;, left_envelope \u0026lt;dbl\u0026gt;, right_envelope \u0026lt;dbl\u0026gt;, # # stickersgiven \u0026lt;dbl\u0026gt;, percent_given_outof100percent \u0026lt;dbl\u0026gt;, giveornot \u0026lt;dbl\u0026gt;, # # larger_envelopeabs \u0026lt;dbl\u0026gt;, large_envelopepercent \u0026lt;dbl\u0026gt;, # # smaller_envelopeabs \u0026lt;dbl\u0026gt;, small_envelopepercent \u0026lt;dbl\u0026gt;  glimpse(stickers)  # Rows: 401 # Columns: 18 # $ subject_number \u0026lt;dbl\u0026gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, ‚Ä¶ # $ condition \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 3, 3, ‚Ä¶ # $ number_stickers \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, ‚Ä¶ # $ number_envelopes \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, ‚Ä¶ # $ gender \u0026lt;dbl\u0026gt; 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, ‚Ä¶ # $ agemonths \u0026lt;dbl\u0026gt; 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,‚Ä¶ # $ ageyears \u0026lt;dbl\u0026gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ‚Ä¶ # $ agegroups \u0026lt;dbl\u0026gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶ # $ subjects_envelope \u0026lt;dbl\u0026gt; 7, 12, 4, 7, 12, 8, 8, 11, 26, 30, 12, ‚Ä¶ # $ left_envelope \u0026lt;dbl\u0026gt; 5, 0, 8, 5, 0, 4, 2, 1, 4, 0, 18, 18, 0‚Ä¶ # $ right_envelope \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 2, 0, NA, NA, N‚Ä¶ # $ stickersgiven \u0026lt;dbl\u0026gt; 5, 0, 8, 5, 0, 4, 4, 1, 4, 0, 18, 18, 0‚Ä¶ # $ percent_given_outof100percent \u0026lt;dbl\u0026gt; 0.42, 0.00, 0.67, 0.42, 0.00, 0.33, 0.3‚Ä¶ # $ giveornot \u0026lt;dbl\u0026gt; 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, ‚Ä¶ # $ larger_envelopeabs \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 2, 1, NA, NA, N‚Ä¶ # $ large_envelopepercent \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 0.5000000, 1.00‚Ä¶ # $ smaller_envelopeabs \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 2, 0, NA, NA, N‚Ä¶ # $ small_envelopepercent \u0026lt;dbl\u0026gt; NA, NA, NA, NA, NA, NA, 0.5000000, 0.00‚Ä¶  Bonus data dictionary    As an extra bonus, when you do have extra header rows, you can create a data dictionary using the gather() function from the tidyr package.\nlibrary(tidyr) stickers_dict \u0026lt;- read_tsv(link, n_max = 1) %\u0026gt;% rename(stickersgiven = 'absolutenumberofstickersgiven(Conditions1or3:Outof12;Conditions2or4:Outof30)') %\u0026gt;% clean_names() %\u0026gt;% gather(variable_name, variable_description) stickers_dict  # # A tibble: 18 x 2 # variable_name variable_description # \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; # 1 subject_number [Included Sample Only] # 2 condition 1=12:1; 2=12:2, 3=30:1, 4=30:2 # 3 number_stickers 1=12; 2=30 # 4 number_envelopes 1=1 recipient; 2=2 recipients # 5 gender 1=female; 2=male # 6 agemonths \u0026lt;NA\u0026gt; # 7 ageyears \u0026lt;NA\u0026gt; # 8 agegroups 1=3-4yrs; 2=5-6yrs; 3=7-8yrs; 4=9-11yrs # 9 subjects_envelope How many stickers did the child keep for themselves ‚Ä¶ # 10 left_envelope 1 recipient conditions: How many stickers the subjec‚Ä¶ # 11 right_envelope 1 recipient conditions: N/A; 2 recipient conditions:‚Ä¶ # 12 stickersgiven Regardless of condition, the number of stickers the ‚Ä¶ # 13 percent_given_outof100‚Ä¶ Regardless of condition, the proportion of stickers ‚Ä¶ # 14 giveornot 1=Donated 1 or more stickers to the recipient(s); 0=‚Ä¶ # 15 larger_envelopeabs Raw number of stickers (out of 30: Condition 2 or 4 ‚Ä¶ # 16 large_envelopepercent Proportion of stickers (out of 100%; Condition 2 or ‚Ä¶ # 17 smaller_envelopeabs Raw number of stickers (out of 30: Condition 2 or 4 ‚Ä¶ # 18 small_envelopepercent Proportion of stickers (out of 100%; Condition 2 or ‚Ä¶  Useful resources     Great blog post from Lisa DeBruine using readxl to read in data with multiple header rows (including those with merged cells!): https://debruine.github.io/multirow_headers.html This GitHub issue with Hadley\u0026rsquo;s response that solved all my problems: https://github.com/tidyverse/readr/issues/179 My original tweet when I discovered this trick!  Neat #rstats #readr #tidyverse solution to read data when 1st row is header + 2nd row is junk, thanks @hadleywickham https://t.co/5TuH7vNaID pic.twitter.com/woZ3HuECge\n\u0026mdash; Alison Presmanes Hill (@apreshill) September 4, 2017  ","date":1531008000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531008000,"objectID":"7c2b6054d04c05d84663766f280f75df","permalink":"https://maggie-98.github.io/post/2018-02-23-read-multiple-header-rows/","publishdate":"2018-07-08T00:00:00Z","relpermalink":"/post/2018-02-23-read-multiple-header-rows/","section":"post","summary":"Using the readr package to sidestep a common problem","tags":null,"title":"Read Data with Multiple Header Rows into R","type":"post"},{"authors":null,"categories":null,"content":"My blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n   ","date":1530140400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530140400,"objectID":"53e892b8b41cc4caece1cfd5ef21d6e7","permalink":"https://maggie-98.github.io/license/","publishdate":"2018-06-28T00:00:00+01:00","relpermalink":"/license/","section":"","summary":"My blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n   ","tags":null,"title":"LICENSE: CC-BY-SA","type":"page"},{"authors":["alison"],"categories":["talk","keynote"],"content":"Inspired by the book ‚ÄúBig Magic: Creative Living Beyond Fear‚Äù by Elizabeth Gilbert, Alison will talk about the five essential ingredients needed to creatively learn R and why these elements are also essential for advanced users to take their R skills to the next level. You will hear practical advice for when, where, and how to start a project in R, and how your learning can add value- both to your own knowledge and to contribute to the larger community of R learners. Along the way, she will share recommended resources and evidence-based strategies for project-based learning. Alison‚Äôs background working with both new and advanced R users gives her a unique perspective on this topic.\n","date":1527926400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527926400,"objectID":"e8b18e62901e2d79bdd538bbccd58051","permalink":"https://maggie-98.github.io/talk/2018-cascadia-bigmagic/","publishdate":"2018-06-02T08:00:00Z","relpermalink":"/talk/2018-cascadia-bigmagic/","section":"talk","summary":"Inspired by the book ‚ÄúBig Magic: Creative Living Beyond Fear‚Äù by Elizabeth Gilbert, Alison will talk about the five essential ingredients needed to creatively learn R and why these elements are also essential for advanced users to take their R skills to the next level. ","tags":["R"],"title":"Big Magic with R: Creative Learning Beyond Fear","type":"talk"},{"authors":null,"categories":["talk"],"content":"Join us on April 6 for a walk-through of how to take a sad plot and make it better by Alison Hill, who co-teaches the CS631 Data Visualization course. Alison will take us through one plot‚Äôs life cycle, from a sad Powerpoint slide to an Excel chart and finally to the finished product made with the ggplot2 package in R. We will discuss why each version of the plot fails in different ways, how each iteration improved on the last one, and which data visualization principles are at work in the final plot to communicate a clear scientific story.\nFollowing this, Eric Earl (Senior RA in the DCAN Labs) will show a case study of visualization in neuroimaging research.\n","date":1523030400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1523030400,"objectID":"33ce306b07956cfb4961cb90296e01f2","permalink":"https://maggie-98.github.io/talk/2018-ohsu-sad-plot-better/","publishdate":"2018-04-06T16:00:00Z","relpermalink":"/talk/2018-ohsu-sad-plot-better/","section":"talk","summary":"Join us on April 6 for a walk-through of how to take a sad plot and make it better by Alison Hill.","tags":["xaringan","ggplot2","data visualization"],"title":"Take a Sad Plot \u0026 Make It Better","type":"talk"},{"authors":["Eric Feczko","Nadir Balba","Oscar Miranda-Dominguez","Michaela Cordova","Sarah Karalunas","Lourdes Irwin","Damion Demeter","alison","Beth Hoover Langhorst","Julia Grieser Painter","Jan van Santen","Eric Fombonne","Joel Nigg","Damien Fair"],"categories":null,"content":"","date":1513728000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513728000,"objectID":"dbc47f036e165ec68800b8c89a360f76","permalink":"https://maggie-98.github.io/publication/2017-subtyping/","publishdate":"2017-12-20T00:00:00Z","relpermalink":"/publication/2017-subtyping/","section":"publication","summary":"DSM-5 Autism Spectrum Disorder (ASD) comprises a set of neurodevelopmental disorders characterized by deficits in social communication and interaction and repetitive behaviors or restricted interests, and may both affect and be affected by multiple cognitive mechanisms. This study attempts to identify and characterize cognitive subtypes within the ASD population using a random forest (RF) machine learning classification model. We trained our model on measures from seven tasks that reflect multiple levels of information processing. 47 ASD diagnosed and 58 typically developing (TD) children between the ages of 9 and 13 participated in this study. Our RF model was 72.7% accurate, with 80.7% specificity and 63.1% sensitivity. Using the RF model, we measured the proximity of each subject to every other subject, generating a distance matrix between participants. This matrix was then used in a community detection algorithm to identify subgroups within the ASD and TD groups, revealing 3 ASD and 4 TD putative subgroups with unique behavioral profiles. We then examined differences in functional brain systems between diagnostic groups and putative subgroups using resting-state functional connectivity magnetic resonance imaging (rsfcMRI). Chi-square tests revealed a significantly greater number of between group differences (p ","tags":null,"title":"Subtyping cognitive profiles in Autism Spectrum Disorder using a random forest algorithm","type":"publication"},{"authors":["alison"],"categories":["rladies","xaringan"],"content":"So, you are doing an R-Ladies presentation\u0026hellip;that\u0026rsquo;s awesome!\nThe short version    I made an R-Ladies theme for xaringan slides. My original tweet about it:\nif you want to use @xieyihui\u0026#39;s awesome #xaringan package for #rstats slides but want more #Rladies flavor, there is now a built-in theme for that (with code highlighting)! Thanks to the awesome @RLadiesGlobal starter kit. Update the CSS in your YAML to use üßôüèΩ‚Äç‚ôÄÔ∏èüßû‚Äç‚ôÄÔ∏è pic.twitter.com/YnlGSVAMsl\n\u0026mdash; Alison Presmanes Hill (@apreshill) November 29, 2017  The way to use the theme is to update the YAML like so:\noutput: xaringan::moon_reader: css: [\u0026quot;default\u0026quot;, \u0026quot;rladies\u0026quot;, \u0026quot;rladies-fonts\u0026quot;]  Make sure your version of xaringan is up-to-date.\nBelow is a demo slide deck using the theme.\n (view the source .Rmd on GitHub)\nThe longer story    I recommend Yihui\u0026rsquo;s xaringan package for slides. This is an R package, available through GitHub, for creating slideshows with remark.js through R Markdown. This means that you can:\n write all your slides in Markdown text include chunks of R code and rendered output like plots, results, tables, etc. in your slides use git for version control and share your GitHub repository  This makes xaringan ideal for an R-Ladies presentation!^[If you are new to xaringan, don\u0026rsquo;t miss the wiki!]\nTo use the package, you\u0026rsquo;ll need the devtools package installed so that you can use the install_github function. Then do:\ndevtools::install_github('yihui/xaringan')  As Yihui points out in the documentation, if you use RStudio, you can use the menu to navigate to File -\u0026gt; New File -\u0026gt; R Markdown -\u0026gt; From Template -\u0026gt; Ninja Presentation, and you will see an R Markdown example.\nI first used xaringan a few months ago. I was working with Yihui on the blogdown book, and had signed up to lead a workshop for the Portland R User group. Obviously, such a workshop could not have powerpoint slides, so it seemed like the perfect time to learn xaringan.\nFor my workshop, I made a simple website for the newly founded R-Ladies PDX using blogdown (Thanks to Augustina and Deeksha, our fearless organizers). So naturally, my slides needed more purple.\nLuckily, the R-Ladies run a tight ship- they have a starter kit on GitHub that details all the pretty purples they like.\nAbout a month after I did the R-Ladies blogdown workshop, I saw this blog post by Yihui:\nFirst, I thought this was such a cool idea and I hope more people make and submit themes. Then I realized, I had already made a theme! I submitted a pull request^[Yihui\u0026rsquo;s technical instructions for contributors section of that blog post has been revised and is very detailed], Yihui helped me make some edits to the CSS files to make them more parsimonious with the default theme, I electronically signed a contributor agreement, and now the theme is there for you all to enjoy and use! You use the theme by editing the YAML:\noutput: xaringan::moon_reader: css: [\u0026quot;default\u0026quot;, \u0026quot;rladies\u0026quot;, \u0026quot;rladies-fonts\u0026quot;]  If you use the theme and you are on twitter, I\u0026rsquo;d love to see it- please mention me on twitter!\nExamples!\n My blogdown workshop slides: \u0026ldquo;Up and running with blogdown\u0026rdquo; (view the source .Rmd on GitHub)     Jessica Minnier\u0026rsquo;s slides for \u0026ldquo;Building Shiny Apps: With Great Power Comes Great Responsibility\u0026rdquo;   ","date":1513555200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513555200,"objectID":"096021454702b101a852c4aa506879e4","permalink":"https://maggie-98.github.io/post/2017-12-18-r-ladies-presentation-ninja/","publishdate":"2017-12-18T00:00:00Z","relpermalink":"/post/2017-12-18-r-ladies-presentation-ninja/","section":"post","summary":"A guide to using the R-Ladies xaringan slide theme","tags":["xaringan"],"title":"R-Ladies Presentation Ninja","type":"post"},{"authors":["Yihui Xie","alison","Amber Thomas"],"categories":null,"content":"","date":1513209600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513209600,"objectID":"e61ec371d9b93f524d235b910de6db2a","permalink":"https://maggie-98.github.io/publication/2017-blogdown/","publishdate":"2017-12-14T00:00:00Z","relpermalink":"/publication/2017-blogdown/","section":"publication","summary":"blogdown: Creating Websites with R Markdown provides a practical guide for creating websites using the blogdown package in R. In this book, we show you how to use dynamic R Markdown documents to build static websites featuring R code (or other programming languages) with automatically rendered output such as graphics, tables, analysis results, and HTML widgets. The blogdown package is also suitable for technical writing with elements such as citations, footnotes, and LaTeX math. This makes blogdown an ideal platform for any website designed to communicate information about data science, data analysis, data visualization, or R programming. Note that blogdown is not just for blogging or sites about R; it can also be used to create general-purpose websites. By default, blogdown uses Hugo, a popular open-source static website generator, which provides a fast and flexible way to build your site content to be shared online. Other website generators like Jekyll and Hexo are also supported.","tags":null,"title":"blogdown: Creating Websites with R Markdown","type":"publication"},{"authors":["alison","Robin Champieux"],"categories":null,"content":"   The landscape of scientific communication is changing dramatically. Diverse stakeholders, including major funders and universities are demonstrating a growing interest and investment in open scientific principles and practices. Researchers, students, and the institutions that support them are needing to navigate new expectations, workflows, and policies against a backdrop of relatively unchanged means and measures of scientific success.\nSound complicated? Join us on December 8th from 3:00 to 4:00 PM for a panel discussion with OHSU leaders and early career researchers on the evolving landscape of scientific communication. We‚Äôll explore the drivers behind the calls for ‚Äúopenness‚Äù, what this means in practice, and the real world compatibility and tensions between open science and student, researcher, and institutional success.\nConfirmed panelists include:\nDr. Gary Westbrook, Vollum Institute Senior Scientist and Director of the Neuroscience Graduate Program\nDr. Bita Moghaddam, Chair of the Department of Behavioral Neuroscience\nDr. Abhinav Nellore, Assistant Professor, Biomedical Engineering and the Department of Surgery\nDr. Alison Hill, Associate Professor, Center for Spoken Language Understanding\nThe panel will be followed by food, drinks, and two hands on workshops from 4:00 - 5:30:\n  In this workshop, Dr. Alison Hill and Robin Champieux demonstrated tools and methods for building transparency within a lab, and onboarding new graduate students and postdocs. We provided a template GitHub repository and code of conduct designed to facilitate a healthy and productive learning and research environment. You are encouraged to use these tools to communicate expectations, document protocols, receive feedback, and facilitate the long-term value of students‚Äô and trainees‚Äô contributions.\nLabhub is a work in progress. We created this repository as an education and demonstration tool for faculty, postdocs, and students curious about how documentation, open science workflows, and tools like Github can contribute to a healthy and productive research environment. Your ideas and contributions are welcome!\n","date":1512748800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512748800,"objectID":"e2b1e3fcba5c5c2ec1b871257195e565","permalink":"https://maggie-98.github.io/talk/2017-ohsu-labhub/","publishdate":"2017-12-08T16:00:00Z","relpermalink":"/talk/2017-ohsu-labhub/","section":"talk","summary":"An OHSU Open Science Workshop on tools and methods for building transparency within a lab","tags":["science","research","workshop"],"title":"Labhub Workshop","type":"talk"},{"authors":["alison","Robin Champieux"],"categories":["workshop"],"content":"In this workshop, Dr. Alison Hill and Robin Champieux demonstrated tools and methods for building transparency within a lab, and onboarding new graduate students and postdocs. We provided a template GitHub repository and code of conduct designed to facilitate a healthy and productive learning and research environment. You are encouraged to use these tools to communicate expectations, document protocols, receive feedback, and facilitate the long-term value of students‚Äô and trainees‚Äô contributions.\nLabhub is a work in progress. We created this repository as an education and demonstration tool for faculty, postdocs, and students curious about how documentation, open science workflows, and tools like Github can contribute to a healthy and productive research environment. Your ideas and contributions are welcome!\n","date":1505347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505347200,"objectID":"dbaf5ab3004c725a12e63f0af4c06422","permalink":"https://maggie-98.github.io/project/labhub/","publishdate":"2017-09-14T00:00:00Z","relpermalink":"/project/labhub/","section":"project","summary":"An OHSU Open Science Workshop on tools and methods for building transparency within a lab","tags":["github","reproducibility","workshop"],"title":"Labhub","type":"project"},{"authors":["alison"],"categories":["workshop"],"content":"We will cover:\n The blogdown R package Hugo themes Adding content to personalize your site Posting Don\u0026rsquo;t want to blog? / just want to knit? Customizing themes Troubleshooting common problems Deployment options and recommendations Domain options available through RStudio/rbind  If you are planning on attending this workshop, please click on the HTML link above for how to prepare before the workshop.\n  ","date":1505347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505347200,"objectID":"f2d9412f829afe4928c20110edfaad02","permalink":"https://maggie-98.github.io/project/up-running-blogdown/","publishdate":"2017-09-14T00:00:00Z","relpermalink":"/project/up-running-blogdown/","section":"project","summary":"A workshop to get up and running with blogdown, GitHub, and Netlify","tags":["R","blogdown","workshop"],"title":"Up \u0026 Running with blogdown","type":"project"},{"authors":["alison"],"categories":null,"content":"See project links for more details.\n","date":1505347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505347200,"objectID":"82e1d8e9d70283ba32db6f4a0467d19f","permalink":"https://maggie-98.github.io/talk/2017-pdxr-blogdown/","publishdate":"2017-09-14T00:00:00Z","relpermalink":"/talk/2017-pdxr-blogdown/","section":"talk","summary":"Join me for a workshop to get you up and running with your own personal website. If you are looking to start your own site, come learn how to do it for free using using R, RStudio, and the blogdown R package.","tags":["blogdown","workshop"],"title":"Up \u0026 Running with blogdown","type":"talk"},{"authors":["alison"],"categories":["blogdown","hugo","netlify"],"content":" Greetings from the future!\nA lot has changed about blogdown, Hugo, and the Academic theme (now Wowchemy) since the time this post was written.\nAn updated tutorial can now be found here üéâ\n  Read up on blogdown    Before you start, I recommend reading the following:\n  blogdown: Creating Websites with R Markdown by Yihui Xie and Amber Thomas  Making a Website Using blogdown, Hugo, and GitHub pages also by Amber Thomas  I also found this comment by Eric Nantz, the creator of the R-Podcast, in the rbind/support issues section on GitHub to be helpful:\n  https://github.com/rbind/support/issues/12  Caveats, disclaimers, etc.    Even with all the great resources I listed above, getting myself up and running took a few tries, so in this post I\u0026rsquo;m passing along what ended up working for me. Everyone\u0026rsquo;s mileage may vary, though, depending on your operating system and your approach. About me: I am a macOS user, and I use R, RStudio, Git (usually via GitLab, sometimes via GitHub), and terminal regularly, so I\u0026rsquo;m assuming familiarity here with all of these. If that is not you, here are some places to get started:\n For Git: Happy Git with R by Jenny Bryan et al. For RStudio: DataCamp\u0026rsquo;s Working with the RStudio IDE (free) by Garrett Grolemund For Terminal: The Command Line Murder Mystery by Noah Veltman, and The UNIX Workbench by Sean Kross  I also have Xcode and Homebrew installed- you will probably need these to download Hugo. If you don\u0026rsquo;t have either but are on a mac, this link may help:\n  How to install Xcode, Homebrew, Git, RVM, Ruby \u0026amp; Rails on Mac OS X   Finally, I did not want to learn more about a lot of things! For instance, the nitty gritty of static site generators and how domain names work. I am a new mom, and just in the process of writing all this up, I filled up my tea mug twice with ice cold water, and filled my water bottle with scalding hot water. So, where offered, I followed the advice of Yihui and Amber. For example:\n  \u0026ldquo;Considering the cost and friendliness to beginners, we currently recommend Netlify.\u0026quot; Sold.  \u0026ldquo;If you are not familiar with domain names or do not want to learn more about them, an option for your consideration is a free subdomain *.rbind.io offered by RStudio, Inc.\u0026quot;. Done.  In GitHub      Go online to your GitHub account, and create a new repository (check to initialize with a README but don\u0026rsquo;t add .gitignore- this will be taken care of later). For naming your repo, consider your future deployment plan:\n If you are going to use Netlify to host the site, you can name this repository anything you want!     You can see some of the repo names used by members of the rbind organization here.   * If you want to host your site as a [GitHub Page](https://pages.github.com), you should name your repository `yourgithubusername.github.io` (so mine would have been `apreshill.github.io`). If you are going this route, I suggest you follow [Amber's instructions](https://proquestionasker.github.io/blog/Making_Site/) instead of mine!   Go to the main page of your new repository, and under the repository name, click the green Clone or download button.\n  In the Clone with HTTPs section, click on the clipboard icon to copy the clone URL for your new repository. You\u0026rsquo;ll paste this text into terminal in the next section.\n  In terminal    Now you will clone your remote repository and create a local copy on your computer so you can sync between the two locations (using terminal or your alternative command line tool for a Windows machine).\n  Use cd to navigate into the directory where you want your repo to be\n  Once there, type: git clone [paste]. So my command looked like this:\n  git clone https://github.com/apreshill/apreshill.git  And this is what printed to my terminal window:\nCloning into 'apreshill'... remote: Counting objects: 3, done. remote: Compressing objects: 100% (2/2), done. remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), done. Checking connectivity... done.  Close terminal, you are done in there.  In RStudio     Install blogdown from your RStudio console. If you already have devtools installed like I did, you can just use the second line below:  if (!requireNamespace(\u0026quot;devtools\u0026quot;)) install.packages(\u0026quot;devtools\u0026quot;) devtools::install_github(\u0026quot;rstudio/blogdown\u0026quot;)  Install Hugo using the blogdown package helper function:  blogdown::install_hugo() # or library(blogdown) install_hugo()   This is where my instructions diverge from Ed\u0026rsquo;s- he states that blogdown won\u0026rsquo;t create a website in your root folder because the README.md file is already there. I didn\u0026rsquo;t find that to be the case- I tested this with a new site as well. If one way doesn\u0026rsquo;t work for you, try the other!   Use the top menu buttons in RStudio to select File -\u0026gt; New Project -\u0026gt; Existing Directory, then browse to the directory on your computer where your GitHub repo is and click on the Create Project button.  Now you should be \u0026ldquo;in\u0026rdquo; your project in RStudio. If you are using git for version control, edit your *gitignore file. This file should be viewable in your file viewer pane in RStudio. Below is what it should look like: the first four lines will automatically be in this file if you have set up your RStudio Project, but if you plan to use Netlify to deploy, you need to add the public/ line ( read about here.)  .Rproj.user .Rhistory .RData .Ruserdata blogdown .DS_Store # if a windows user, Thumbs.db instead public/ # if using Netlify  Build your site in RStudio    Now you can finally build your site using the blogdown::new_site() function. But first you should at least think about themes\u0026hellip;\nPicking a theme    There are over 90 Hugo themes. So I went back to the blogdown book. Thankfully, Yihui and Amber offer \u0026ldquo;to save you some time, we list a few themes below that match our taste\u0026hellip;\u0026quot;. Huzzah- I went with hugo-academic! Whatever theme you choose, you\u0026rsquo;ll need to pick one of 3 ways to make your new site:\n If you are happy with the default theme, which is the lithium theme, you can use:  blogdown::new_site() # default theme is lithium  If you want a theme other than the default, you can specify the theme at the same time as you call the new_site function:  # for example, create a new site with the academic theme blogdown::new_site(theme = \u0026quot;gcushen/hugo-academic\u0026quot;, theme_example = TRUE)  If instead you want to add the theme later (like I did, because I didn\u0026rsquo;t see the above example until it was too late!), you can do this:  library(blogdown) new_site() # default theme is lithium # need to stop serving so can use the console again install_theme(\u0026quot;gcushen/hugo-academic\u0026quot;, theme_example = TRUE, update_config = TRUE)   Now is a good time to re-read about blogdown::serve_site() and how LiveReload works (and how it blocks your R console by default)   I recommend setting theme_example = TRUE- some themes won\u0026rsquo;t provide an example site, but the academic theme did and I found it helpful to see. You can always delete the example content.\nUpdate project options    In your project in RStudio, go to the top menu bar of RStudio and select Tools -\u0026gt; Project Options and update following Yihui and Amber\u0026rsquo;s instructions.\nEdit your configurations    Relevant reading:\n  blogdown book chapter on configuration  Additional detail from Amber You can also view my config.toml file  Now, edit the baseurl in your config.toml file. The URL should always end with a / trailing slash. At this point, you probably haven\u0026rsquo;t deployed your site yet, so to view it locally you can use the Serve Site add-in, or run the blogdown::serve_site function. Both of these baseurls worked for me when viewing locally:\nbaseurl = \u0026quot;https://example.com/\u0026quot; baseurl = \u0026quot;/\u0026quot;   Make sure that the baseurl =  listed ends with a trailing slash /!   Go ahead and edit all the other elements in the config.toml file now as you please- this is how you personalize your site!\nAddins \u0026amp; workflow    Relevant reading:\n  blogdown book chapter on the RStudio IDE  Addins: use them- you won\u0026rsquo;t need the blogdown library loaded in the console if you use the Addins. My workflow in RStudio at this point (again, just viewing locally because we haven\u0026rsquo;t deployed yet) works best like this:\n Open the RStudio project for the site Use the Serve Site add-in (only once due to the magic of LiveReload) View site in the RStudio viewer pane, and open in a new browser window while I work Select existing files to edit using the file pane in RStudio After making changes, click the save button (don\u0026rsquo;t knit!)- the console will reload, the viewer pane will update, and if you hit refresh in the browser your local view will also be updated When happy with changes, add/commit/push changes to GitHub  Having blogdown::serve_site running locally with LiveReload is especially useful as you can immediately see if you have totally screwed up. For example, in editing my about.md file, this error popped up in my console after making a change and I was able to fix the error right away:\nStarted building sites ... ERROR 2017/06/08 16:22:34 failed to parse page metadata for home/about.md: (18, 6): missing comma Error: Error building site: Errors reading pages: Error: failed to parse page metadata for home/about.md: (18, 6): missing comma for about.md  The above workflow is only for editing existing files or posts, but not for creating new posts. For that, read on\u0026hellip;\nPosting    Relevant reading:\n  blogdown book chapter on RStudio IDE  blogdown book chapter on output formats: on .md versus .Rmd posts  Additional detail from Amber on adding a blog post  Bottom line:\nUse the New Post addin. But, you need the console to do this, so you have to stop blogdown::serve_site by clicking on the red Stop button first. The Addin is a Shiny interface that runs this code in your console: blogdown:::new_post_addin(). So, your console needs to be unblocked for it to run. You also need to be \u0026ldquo;in\u0026rdquo; your RStudio project or it won\u0026rsquo;t work.\nDraft posts    Relevant reading:\n  blogdown book chapter on building a website for local preview  Whether you do a markdown or R Markdown post (see below), you should know that in the YAML front matter of your new file, you can add draft: TRUE and you will be able to preview your post using blogdown::serve_site(), but conveniently your post will not show up on your deployed site until you set it to false. Because this is a function built into Hugo, all posts (draft or not) will still end up in your GitHub repo though.\nNew markdown posts    Pick one of 2 methods:\n Use the New Post addin and with the radio button at the bottom select Format: Markdown (recommended) Use the console to author a new .md post:  blogdown::new_post() blogdown::new_post(ext = '.md') # md is the default!  Here are the ?new_post arguments:\nnew_post(title, kind = \u0026quot;\u0026quot;, open = interactive(), author = getOption(\u0026quot;blogdown.author\u0026quot;), categories = NULL, tags = NULL, date = Sys.Date(), file = NULL, slug = NULL, title_case = getOption(\u0026quot;blogdown.title_case\u0026quot;), subdir = getOption(\u0026quot;blogdown.subdir\u0026quot;, \u0026quot;post\u0026quot;), ext = getOption(\u0026quot;blogdown.ext\u0026quot;, \u0026quot;.md\u0026quot;))   Remember to use the Serve Site addin again so that you can immediately view your changes with every save using LiveReload.   New R Markdown (.Rmd) posts    Again, you have your choice of one of 2 methods:\n Use the New Post addin and with the radio button at the bottom select Format: R Markdown (.Rmd) (recommended) Use the console to author a new .Rmd post:  blogdown::new_post(ext = '.Rmd') # md is the default!  After you edit your .Rmd post, in addition to saving the changes in your .Rmd file, you must use blogdown::serve_site- this is how the output html file needs to be generated.\n Do not knit your .Rmd posts- use blogdown::serve_site instead. If you happen to hit the knit button, just Serve Site again to rewrite the .html file.   Ultimately, your YAML front matter looks something like this; note that some but not all features of rmarkdown::html_document are supported in blogdown:\n--- title: \u0026quot;My Awesome Post\u0026quot; author: \u0026quot;John Doe\u0026quot; date: \u0026quot;2017-02-14\u0026quot; output: blogdown::html_page: toc: true toc_depth: 1 number_sections: true fig_width: 6 ---   Remember to use the Serve Site addin again so that you can immediately view your changes with every save using LiveReload and your .html file is properly output.   Adding images to a post    If you want to include an image that is not a figure created from an R chunk, the recommended method is to:\n Add the image to your /static/img/ folder, then Reference the image using the relative file path as follows:  ![my-image](/img/my-image.png)  Deploy in Netlify    Deploying in Netlify through GitHub is smooth. Yihui and Amber give some beginner instructions, but Netlify is so easy, I recommend that you skip dragging your public folder in and instead automate the process through GitHub.\n  When you are ready to deploy, commit your changes and push to GitHub, then go online to Netlify.\n  Click on the Sign Up button and sign up using your existing GitHub account (no need to create another account)\n  Log in, and select: New site from Git -\u0026gt; Continuous Deployment: GitHub.\n  From there, Netlify will allow you to select from your existing GitHub repositories. You\u0026rsquo;ll pick the repo you\u0026rsquo;ve been working from with blogdown, then you\u0026rsquo;ll configure your build. This involves specifying two important things: the build command and the publish directory (this should be public).\n More about the build command from Netlify: \u0026ldquo;For Hugo hosting, hugo will build and deploy with the version 0.17 of hugo. You can specify a specific hugo release like this: hugo_0.15. Currently 0.13, 0.14, 0.15, 0.16, 0.17, 0.18 and 0.19 are supported. For version 0.20 and above, you‚Äôll need to create a Build environment variable called HUGO_VERSION and set it to the version of your choice.\u0026quot; I opted for the former, and specified hugo_0.19.    You can check your hugo version in terminal using the command hugo version. This is what my output looked like, so I could run version 0.20 if I wanted to through Netlify, but I went with 0.19 and it works just fine.\n$ hugo version Hugo Static Site Generator v0.20.7 darwin/amd64 BuildDate: 2017-05-08T18:37:40-07:00  Netlify will deploy your site and assign you a random subdomain name of the form random-word-12345.netlify.com. Mine was particularly unfortunate, with the random word garbage-collector-janice. You should know that you can change this; I changed mine to apreshill.netlify.com.\n Anytime you change your subdomain name, you need to update the baseurl in your config.toml file (so I changed mine to baseurl = \u0026ldquo;https://apreshill.netlify.com/\u0026quot;).   At this point, you should be up and running with blogdown, GitHub, and Netlify, but here are some ideas if you want to go further\u0026hellip;\nGoing further    Custom CSS    I like to tinker with default theme settings like colors and fonts. Every Hugo theme is structured a little differently, but if you are interested, you can check out my custom css to see how I customized the academic theme, which provides a way to link to a custom CSS file in the config.toml file:\n # Link custom CSS and JS assets # (relative to /static/css and /static/js respectively) custom_css = [\u0026quot;blue.css\u0026quot;]  Formspree    I used Formspree to make a contact form, which is an online service (managed on GitHub) that allows you to add an HTML form to your static site. No registration, just use the form and confirm your email address once. I added the following code into my contact widget:\n\u0026lt;form action=\u0026quot;https://formspree.io/your@email.com\u0026quot; method=\u0026quot;POST\u0026quot;\u0026gt; \u0026lt;label for=\u0026quot;name\u0026quot;\u0026gt;Your name: \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;name\u0026quot; required=\u0026quot;required\u0026quot; placeholder=\u0026quot;here\u0026quot;\u0026gt;\u0026lt;br\u0026gt; \u0026lt;label for=\u0026quot;email\u0026quot;\u0026gt;Your email: \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026quot;email\u0026quot; name=\u0026quot;_replyto\u0026quot; required=\u0026quot;required\u0026quot; placeholder=\u0026quot;here\u0026quot;\u0026gt;\u0026lt;br\u0026gt; \u0026lt;label for=\u0026quot;message\u0026quot;\u0026gt;Your message:\u0026lt;/label\u0026gt;\u0026lt;br\u0026gt; \u0026lt;textarea rows=\u0026quot;4\u0026quot; name=\u0026quot;message\u0026quot; id=\u0026quot;message\u0026quot; required=\u0026quot;required\u0026quot; class=\u0026quot;form-control\u0026quot; placeholder=\u0026quot;I can't wait to read this!\u0026quot;\u0026gt;\u0026lt;/textarea\u0026gt; \u0026lt;input type=\u0026quot;hidden\u0026quot; name=\u0026quot;_next\u0026quot; value=\u0026quot;/html/thanks.html\u0026quot; /\u0026gt; \u0026lt;input type=\u0026quot;submit\u0026quot; value=\u0026quot;Send\u0026quot; name=\u0026quot;submit\u0026quot; class=\u0026quot;btn btn-primary btn-outline\u0026quot;\u0026gt; \u0026lt;input type=\u0026quot;hidden\u0026quot; name=\u0026quot;_subject\u0026quot; value=\u0026quot;Website message\u0026quot; /\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;_gotcha\u0026quot; style=\u0026quot;display:none\u0026quot; /\u0026gt; \u0026lt;/form\u0026gt;  *.rbind.io domain names    You may want a different domain name than the one provided by Netlify. I opted for a free subdomain *.rbind.io offered by RStudio. To do the same, head over to the rbind/support GitHub page and open a new issue. All you need to do is let them know what your Netlify subdomain name is (*.netlify.com), and what you want your subdomain name to be (*.rbind.io). The awesome rbind support team will help you take it from there!\n Again, you will need to update the baseurl in your config.toml file to reflect your new rbind subdomain name (so mine is baseurl = \u0026ldquo;https://alison.rbind.io/\u0026quot;).   Have fun!    Lastly, don\u0026rsquo;t forget to just have fun with it. Happy blogdowning!\nvia GIPHY\n","date":1497225600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1497225600,"objectID":"c91b934917d1b356d8afc526c9c29af7","permalink":"https://maggie-98.github.io/post/2017-06-12-up-and-running-with-blogdown/","publishdate":"2017-06-12T00:00:00Z","relpermalink":"/post/2017-06-12-up-and-running-with-blogdown/","section":"post","summary":"A guide to getting up and running with blogdown, GitHub, and Netlify","tags":["blogdown"],"title":"Up \u0026 Running with blogdown","type":"post"},{"authors":["Heather MacFarlane","Kyle Gorman","Rosemary Ingham","alison","Katina Papadakis","Geza Kiss","Jan van Santen"],"categories":null,"content":"","date":1489536000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1489536000,"objectID":"d0febf90eefe4dcc6d7064596e6aa73e","permalink":"https://maggie-98.github.io/publication/2017-mazes-asd-sli/","publishdate":"2017-03-15T00:00:00Z","relpermalink":"/publication/2017-mazes-asd-sli/","section":"publication","summary":"Deficits in social communication, particularly pragmatic language, are characteristic of individuals with autism spectrum disorder (ASD). Speech disfluencies may serve pragmatic functions such as cueing speaking problems. Previous studies have found that speakers with ASD differ from typically developing (TD) speakers in the types and patterns of disfluencies they produce, but fail to provide sufficiently detailed characterizations of the methods used to categorize and quantify disfluency, making cross-study comparison difficult. In this study we propose a simple schema for classifying major disfluency types, and use this schema in an exploratory analysis of differences in disfluency rates and patterns among children with ASD compared to TD and language impaired (SLI) groups. 115 children ages 4‚Äì8 participated in the study (ASD = 51; SLI = 20; TD = 44), completing a battery of experimental tasks and assessments. Measures of morphological and syntactic complexity, as well as word and disfluency counts, were derived from transcripts of the Autism Diagnostic Observation Schedule (ADOS). High inter-annotator agreement was obtained with the use of the proposed schema. Analyses showed ASD children produced a higher ratio of content to filler disfluencies than TD children. Relative frequencies of repetitions, revisions, and false starts did not differ significantly between groups. TD children also produced more cued disfluencies than ASD children.","tags":null,"title":"Quantitative Analysis of Disfluency in Children with Autism Spectrum Disorder or Language Impairment","type":"publication"},{"authors":["alison","Julianne Myers"],"categories":["workshop"],"content":"   ","date":1466726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1466726400,"objectID":"8866480774ff76cdefb63292ac3cefd7","permalink":"https://maggie-98.github.io/project/code-your-graph/","publishdate":"2016-06-24T00:00:00Z","relpermalink":"/project/code-your-graph/","section":"project","summary":"A workshop on visualizing your data with ggplot2 and matplotlib","tags":["workshop","dataviz","ggplot2","R"],"title":"Code Your Graph Workshop","type":"project"},{"authors":["alison","Julianne Myers"],"categories":null,"content":"   ","date":1466726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1466726400,"objectID":"59403374a7f27f5117bf0f8cd8b03611","permalink":"https://maggie-98.github.io/talk/2016-ohsu-dataviz/","publishdate":"2016-06-24T00:00:00Z","relpermalink":"/talk/2016-ohsu-dataviz/","section":"talk","summary":"A workshop on visualizing your data with ggplot2 and matplotlib","tags":["workshop","dataviz","ggplot2"],"title":"Code Your Graph Workshop","type":"talk"},{"authors":null,"categories":["workshop"],"content":"This two-day workshop is designed for those who want to take their R Markdown skills to the next level. We‚Äôll talk about many low-level details in the rmarkdown package and the whole R Markdown ecosystem. The two goals of this workshop are: 1) learn how to fully customize R Markdown output (HTML, LaTeX/PDF, Word, and PowerPoint); and 2) learn more about existing R Markdown extensions in the ecosystem, such as flexdashboard, bookdown, blogdown, pkgdown, xaringan, rticles, and learnr. We will also talk about how to use or develop new language engines (languages that are not R), how to develop HTML widgets, and integrate Shiny with R Markdown.\nSee the workshop website for more, and links to individual slides below.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"2a508153b3ae9e46d1a6cb1beb8234e0","permalink":"https://maggie-98.github.io/project/advanced-r-markdown/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/advanced-r-markdown/","section":"project","summary":"A two-day workshop for those who want to take their R Markdown skills to the next level","tags":["workshop","R","blogdown","xaringan","bookdown","flexdashboard","rmarkdown"],"title":"Advanced R Markdown","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"03abe4930dc106758dc82a0471258e90","permalink":"https://maggie-98.github.io/project/bakeoff/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/bakeoff/","section":"project","summary":"An R data package with data from ‚ÄúThe Great British Bake Off‚Äù","tags":["R","software"],"title":"Bakeoff","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"c7297892dd13604a0e171a4f21c6c629","permalink":"https://maggie-98.github.io/project/blogdown-book/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/blogdown-book/","section":"project","summary":"A practical guide for creating websites using the blogdown package in R","tags":["book","blogdown","R"],"title":"blogdown: Creating Websites with R Markdown","type":"project"},{"authors":["alison"],"categories":["course"],"content":"Part of a year-long curricula on open science, data, and research practice for incoming graduate students in the biomedical sciences, developed in collaboration with OHSU School of MedicineGraduate Studies. This course was offered at Oregon Health \u0026amp; Science University to graduate students in the biomedical sciences.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"3268a7560699d900640de270156a615f","permalink":"https://maggie-98.github.io/project/ohsu-biostats/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/ohsu-biostats/","section":"project","summary":"A 12-week introductory course that teaches students how to gain and communicate insights from biomedical data","tags":["course","tidyverse","rmarkdown","statistics","R"],"title":"Introduction to Data Wrangling, Analysis, \u0026 Communication","type":"project"},{"authors":["Steven Bedrick","Jackie Wirz","alison"],"categories":["course"],"content":"This was a 12-week course with weekly 1.5 hour hands-on labs using R and the ggplot2 package. This course (CS631) was co-developed with Drs. Steven Bedrick and Jackie Wirz. This team-taught course was offered at Oregon Health \u0026amp; Science University to graduate students in the biomedical sciences.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d7447220a709e62094ac089f26b871b6","permalink":"https://maggie-98.github.io/project/ohsu-dataviz/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/ohsu-dataviz/","section":"project","summary":"A 12-week introduction to data visualization with hands-on labs using R and ggplot2","tags":["course","ggplot2","blogdown","xaringan","rmarkdown","R"],"title":"Principles \u0026 Practice of Data Visualization","type":"project"},{"authors":["alison"],"categories":["course"],"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"b7ca2ef5063f3da9344fc8dec2700774","permalink":"https://maggie-98.github.io/project/ohsu-cs-stats/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/ohsu-cs-stats/","section":"project","summary":"A 12-week introduction to fundamental concepts underlying statistical data display, analysis, inference, and statistical decision making","tags":["course","tidyverse","rmarkdown","statistics","R"],"title":"Probability \u0026 Statistics for Scientists and Engineers","type":"project"},{"authors":null,"categories":null,"content":" Here is a demo slide deck using the theme:\n ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8d6ba21091d606cade645e86b4496282","permalink":"https://maggie-98.github.io/project/rladies-xaringan/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/rladies-xaringan/","section":"project","summary":"An RLadies theme for slides made with the xaringan R package","tags":["R"],"title":"RLadies xaringan theme","type":"project"},{"authors":null,"categories":["workshop"],"content":"Four daily 1-hour sessions plus 30-60 minutes of homework for 3 nights. See links to each day\u0026rsquo;s materials, including slides and homeworks, below.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d4b87317e523839f6c2f27b04d660073","permalink":"https://maggie-98.github.io/project/summer-of-blogdown/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/summer-of-blogdown/","section":"project","summary":"A week of the blogdown R package for RStudio's summer 2019 interns","tags":["R","blogdown","workshop"],"title":"Summer of blogdown","type":"project"},{"authors":["alison","Katharine Zuckerman","Eric Fombonne"],"categories":null,"content":"","date":1455840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1455840000,"objectID":"0b6a054d394b57b2726a4664b37d577a","permalink":"https://maggie-98.github.io/publication/2016-primer-on-asd/","publishdate":"2016-02-19T00:00:00Z","relpermalink":"/publication/2016-primer-on-asd/","section":"publication","summary":"In this chapter, we review existing prevalence estimates for ASDs since 2000 and discuss methodological factors impacting the estimation of prevalence and the interpretation of changes in prevalence estimates over time. Possible explanations for an increase in the prevalence of ASD within and across populations are considered. Increases in ASD diagnostic rates cannot currently be attributed to a true increase in the incidence of ASD due to multiple confounding factors. It remains to be seen how changes to diagnostic criteria introduced in the DSM-5 will impact estimates of ASD prevalence going forward.","tags":null,"title":"Epidemiology of autism spectrum disorders","type":"publication"},{"authors":["Kyle Gorman","Lindsay Olson","alison","Rebecca Lunsford","Peter A. Heeman","Jan P. H. van Santen"],"categories":null,"content":"","date":1453420800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1453420800,"objectID":"09b001253620028175a8ded4912e712c","permalink":"https://maggie-98.github.io/publication/2016-uh-and-um-asd-sli/","publishdate":"2016-01-22T00:00:00Z","relpermalink":"/publication/2016-uh-and-um-asd-sli/","section":"publication","summary":"Atypical pragmatic language is often present in individuals with autism spectrum disorders (ASD), along with delays or deficits in structural language. This study investigated the use of the ‚Äúfillers‚Äù uh and um by children ages 4‚Äì8 during the autism diagnostic observation schedule. Fillers reflect speakers‚Äô difficulties with planning and delivering speech, but they also serve communicative purposes, such as negotiating control of the floor or conveying uncertainty. We hypothesized that children with ASD would use different patterns of fillers compared to peers with typical development or with specific language impairment (SLI), reflecting differences in social ability and communicative intent. Regression analyses revealed that children in the ASD group were much less likely to use um than children in the other two groups. Filler use is an easy-to-quantify feature of behavior that, in concert with other observations, may help to distinguish ASD from SLI.","tags":null,"title":"Uh and Um in Children With Autism Spectrum Disorders or Language Impairment","type":"publication"},{"authors":["alison","Katharine E. Zuckerman","Eric Fombonne"],"categories":null,"content":"METHODS: Participants were 5053 children with confirmed diagnosis of ASD in the Autism Speaks Autism Treatment Network. Measured values for weight and height were used to calculate BMI percentiles; Centers for Disease Control and Prevention criteria for BMI for gender and age were used to define overweight and obesity (85th and 95th percentiles, respectively).\nRESULTS: In children age 2 to 17 years, 33.6% were overweight and 18% were obese. Compared with a general US population sample, rates of unhealthy weight were significantly higher among children with ASDs ages 2 to 5 years and among those of non-Hispanic white origin. Multivariate analyses revealed that older age, Hispanic or Latino ethnicity, lower parent education levels, and sleep and affective problems were all significant predictors of obesity.\nCONCLUSIONS: Our results indicate that the prevalence of unhealthy weight is significantly greater among children with ASD compared with the general population, with differences present as early as ages 2 to 5 years. Because obesity is more prevalent among older children in the general population, these findings raise the question of whether there are different trajectories of weight gain among children with ASDs, possibly beginning in early childhood.\n","date":1441238400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441238400,"objectID":"159c707438c6bc3dd89b73a846e84007","permalink":"https://maggie-98.github.io/publication/2015-obesity-in-asd-multisite/","publishdate":"2015-09-03T00:00:00Z","relpermalink":"/publication/2015-obesity-in-asd-multisite/","section":"publication","summary":"Overweight and obesity are increasingly prevalent in the general pediatric population. Evidence suggests that children with autism spectrum disorders (ASDs) may be at elevated risk for unhealthy weight. We identify the prevalence of overweight and obesity in a multisite clinical sample of children with ASDs and explore concurrent associations with variables identified as risk factors for unhealthy weight in the general population. ","tags":null,"title":"Obesity and Autism","type":"publication"},{"authors":["alison","Jan van Santen","Kyle Gorman","Beth Hoover Langhorst","Eric Fombonne"],"categories":null,"content":"","date":1434240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1434240000,"objectID":"9b8a3141e9c30d4d6f012c4b05642832","permalink":"https://maggie-98.github.io/publication/2015-memory-in-li-asd/","publishdate":"2015-06-14T00:00:00Z","relpermalink":"/publication/2015-memory-in-li-asd/","section":"publication","summary":"Background: A subgroup of young children with autism spectrum disorders (ASD) have significant language impairments (phonology, grammar, vocabulary), although such impairments are not considered to be core symptoms of and are not unique to ASD. Children with specific language impairment (SLI) display similar impairments in language. Given evidence for phenotypic and possibly etiologic overlap between SLI and ASD, it has been suggested that language-impaired children with ASD (ASD + language impairment, ALI) may be characterized as having both ASD and SLI. However, the extent to which the language phenotypes in SLI and ALI can be viewed as similar or different depends in part upon the age of the individuals studied. The purpose of the current study is to examine differences in memory abilities, specifically those that are key ‚Äúmarkers‚Äù of heritable SLI, among young school-age children with SLI, ALI, and ALN (ASD + language normal). Methods: In this cross-sectional study, three groups of children between ages 5 and 8 years participated: SLI (n = 18), ALI (n = 22), and ALN (n = 20). A battery of cognitive, language, and ASD assessments was administered as well as a nonword repetition (NWR) test and measures of verbal memory, visual memory, and processing speed. Results: NWR difficulties were more severe in SLI than in ALI, with the largest effect sizes in response to nonwords with the shortest syllable lengths. Among children with ASD, NWR difficulties were not associated with the presence of impairments in multiple ASD domains, as reported previously. Verbal memory difficulties were present in both SLI and ALI groups relative to children with ALN. Performance on measures related to verbal but not visual memory or processing speed were significantly associated with the relative degree of language impairment in children with ASD, supporting the role of verbal memory difficulties in language impairments among early school-age children with ASD. Conclusions: The primary difference between children with SLI and ALI was in NWR performance, particularly in repeating two- and three-syllable nonwords, suggesting that shared difficulties in early language learning found in previous studies do not necessarily reflect the same underlying mechanisms.","tags":null,"title":"Memory in language-impaired children with and without autism","type":"publication"},{"authors":["alison","Katharine Zuckerman","Eric Fombonne"],"categories":null,"content":"","date":1433894400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433894400,"objectID":"a74fffb3b5bb1b85c72e901b096bac30","permalink":"https://maggie-98.github.io/publication/2015-translational/","publishdate":"2015-06-10T00:00:00Z","relpermalink":"/publication/2015-translational/","section":"publication","summary":"In this chapter, we review existing prevalence estimates for autism spectrum disorders (ASDs) since 2000 and discuss methodological factors impacting the estimation of prevalence and the interpretation of changes in prevalence estimates over time. Possible explanations for an increase in the prevalence of ASD within and across populations are considered. Increases in ASD diagnostic rates cannot currently be attributed to a true increase in the incidence of ASD due to multiple confounding factors. It remains to be seen how changes to diagnostic criteria introduced in the DSM-5 will impact estimates of ASD prevalence going forward.","tags":null,"title":"Epidemiology of autism spectrum disorders","type":"publication"},{"authors":["alison","Katherine E. Zuckerman","Arlene D. Hagen","Daniel J. Kriz","Susanne W. Duvall","Jan van Santen","Joel Nigg","Damien Fair","Eric Fombonne"],"categories":null,"content":"","date":1403395200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1403395200,"objectID":"ba3062d9d35a8a913fc48e7637ea70fe","permalink":"https://maggie-98.github.io/publication/2014-aggression-in-asd/","publishdate":"2014-06-22T00:00:00Z","relpermalink":"/publication/2014-aggression-in-asd/","section":"publication","summary":"Aggressive behavior problems (ABP) are frequent yet poorly understood in children with autism spectrum disorders (ASD) and are likely to co-vary significantly with comorbid problems. We examined the prevalence and sociodemographic correlates of ABP in a clinical sample of children with ASD (N = 400; 2‚Äì16.9 years). We also investigated whether children with ABP experience more intensive medical interventions, greater impairments in behavioral functioning, and more severe comorbid problems than children with ASD who do not have ABP. One in four children with ASD had Child Behavior Checklist scores on the Aggressive Behavior scale in the clinical range (T-scores = 70). Sociodemographic factors (age, gender, parent education, race, ethnicity) were unrelated to ABP status. The presence of ABP was significantly associated with increased use of psychotropic drugs and melatonin, lower cognitive functioning, lower ASD severity, and greater comorbid sleep, internalizing, and attention problems. In multivariate models, sleep, internalizing, and attention problems were most strongly associated with ABP. These comorbid problems may hold promise as targets for treatment to decrease aggressive behavior and proactively identify high-risk profiles for prevention.","tags":null,"title":"Aggressive Behavior Problems in Children with Autism Spectrum Disorders: Prevalence and Correlates in a Large Clinical Sample","type":"publication"},{"authors":["alison","Katharine Zuckerman","Eric Fombonne"],"categories":null,"content":"","date":1393804800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1393804800,"objectID":"27f62fe82863f321b72f90826a502f9e","permalink":"https://maggie-98.github.io/publication/2014-handbook/","publishdate":"2014-03-03T00:00:00Z","relpermalink":"/publication/2014-handbook/","section":"publication","summary":"Since 1966, over 80 epidemiological surveys of autism spectrum disorders (ASDs) have been conducted in more than 20 countries. In this chapter, we review existing prevalence estimates for ASDs and discuss methodological factors impacting the estimation of prevalence and the interpretation of changes in prevalence estimates over time. Possible explanations for an increase in the prevalence of ASD within and across populations are considered. Increases in ASD diagnostic rates cannot currently be attributed to a true increase in the incidence of ASD due to multiple confounding factors. It remains to be seen how changes to diagnostic criteria introduced in the DSM-5 will impact estimates of ASD prevalence going forward.","tags":null,"title":"Epidemiology of autism spectrum disorders","type":"publication"},{"authors":["Katharine E. Zuckerman","alison","Kimberly Guion","Lisa Voltolina","Eric Fombonne"],"categories":null,"content":"","date":1391299200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1391299200,"objectID":"ef04d4e41554e20028cbe353dc2912ab","permalink":"https://maggie-98.github.io/publication/2014-obesity-in-asd-oregon/","publishdate":"2014-02-02T00:00:00Z","relpermalink":"/publication/2014-obesity-in-asd-oregon/","section":"publication","summary":"Autism Spectrum Disorders (ASDs) and childhood obesity (OBY) are rising public health concerns. This study aimed to evaluate the prevalence of overweight (OWT) and OBY in a sample of 376 Oregon children with ASD, and to assess correlates of OWT and OBY in this sample. We used descriptive statistics, bivariate, and focused multivariate analyses to determine whether socio-demographic characteristics, ASD symptoms, ASD cognitive and adaptive functioning, behavioral problems, and treatments for ASD were associated with OWT and OBY in ASD. Overall 18.1 % of children met criteria for OWT and 17.0 % met criteria for OBY. OBY was associated with sleep difficulties, melatonin use, and affective problems. Interventions that consider unique needs of children with ASD may hold promise for improving weight status among children with ASD.","tags":null,"title":"Overweight and Obesity: Prevalence and Correlates in a Large Clinical Sample of Children with Autism Spectrum Disorder","type":"publication"},{"authors":["alison","Eric Fombonne"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"8a79d2607d7d3103cc12100012e71247","permalink":"https://maggie-98.github.io/publication/2014-asd-epidemiology-in-practice/","publishdate":"2014-01-01T00:00:00Z","relpermalink":"/publication/2014-asd-epidemiology-in-practice/","section":"publication","summary":"In this selective review of the literature, we present the most recent prevalence estimates for autism spectrum disorder (ASD) and discuss the limitations and challenges in interpreting changes in prevalence estimates over time. Increases in ASD prevalence estimates cannot currently be attributed to a true increase in the incidence of ASD due to multiple confounding factors. These include broader diagnostic criteria and a greater awareness of ASD. The current average prevalence of ASD is approximately 66/10,000, which translates to approximately 1 in 152 children a ected, with males consistently outnumbering females by about 5:1. Several recent studies have reported higher estimates ranging from 147 (one in 68) to 264 (one in 38) per 10,000. This is in sharp contrast to the  gures of about 1-5/10,000 quoted in earlier studies that used a narrow de nition of autistic disorder and were not inclusive of all disorders falling onto the autism spectrum. It remains to be seen how changes to diagnostic criteria introduced in the DSM-5 will impact estimates of ASD prevalence.","tags":null,"title":"Epidemiology of Autism Spectrum Disorder","type":"publication"},{"authors":["Jan P. H. van Santen","Richard W. Sproat","alison"],"categories":null,"content":"","date":1365724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1365724800,"objectID":"053861617f3b4a9dad6296b5cbe8ea21","permalink":"https://maggie-98.github.io/publication/2013-repetitive-speech-in-asd-sli/","publishdate":"2013-04-12T00:00:00Z","relpermalink":"/publication/2013-repetitive-speech-in-asd-sli/","section":"publication","summary":"We report on an automatic technique for quantifying two types of repetitive speech: repetitions of what the child says him/herself (self-repeats) and of what is uttered by an interlocutor (echolalia). We apply this technique to a sample of 111 children between the ages of four and eight: 42 typically developing children (TD), 19 children with specific language impairment (SLI), 25 children with autism spectrum disorders (ASD) plus language impairment (ALI), and 25 children with ASD with normal, non-impaired language (ALN). The results indicate robust differences in echolalia between the TD and ASD groups as a whole (ALN + ALI), and between TD and ALN children. There were no significant differences between ALI and SLI children for echolalia or self-repetitions. The results confirm previous findings that children with ASD repeat the language of others more than other populations of children. On the other hand, self-repetition does not appear to be significantly more frequent in ASD, nor does it matter whether the child‚Äôs echolalia occurred within one (immediate) or two turns (near-immediate) of the adult‚Äôs original utterance. Furthermore, non-significant differences between ALN and SLI, between TD and SLI, and between ALI and TD are suggestive that echolalia may not be specific to ALN or to ASD in general. One important innovation of this work is an objective fully automatic technique for assessing the amount of repetition in a transcript of a child‚Äôs utterances.","tags":null,"title":"Quantifying Repetitive Speech in Autism Spectrum Disorders and Language Impairment","type":"publication"},{"authors":["Kristina M. Zosuls","Carol Lynn Martin","Diane N. Ruble","Cindy F. Miller","Bridget M. Gaertner","Dawn E. England","alison"],"categories":null,"content":"","date":1297123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1297123200,"objectID":"4fc09d6b6c9a5931644746dad6d8415a","permalink":"https://maggie-98.github.io/publication/2011-gender-attitudes/","publishdate":"2011-02-08T00:00:00Z","relpermalink":"/publication/2011-gender-attitudes/","section":"publication","summary":"Widespread gender segregation, evident throughout elementary school, seems to imply that girls and boys have negative feelings and thoughts about one another, and classic theories of inter-group processes support this idea. However, research has generally overlooked children‚Äôs feelings and perceptions about gender-related interpersonal interactions. This paper investigates the nature of children‚Äôs attitudes about same- and other-gender peers, and explores how those attitudes relate to the expectancies and beliefs children hold about same- and other-gender peer interactions. Children (N = 98 fifth graders) completed questionnaires assessing their global liking of own- and other-gender peers (Yee \u0026 Brown, 1994), positive and negative attitudes about own- and other-gender peers, and outcome expectancies related to interacting with own- and other-gender peers. Results indicated that rather than being characterized by out-group negativity, children‚Äôs inter-group gender attitudes are best characterized by an in-group positivity bias. Children‚Äôs positive and negative affective attitudes were also significantly associated with outcome expectancies. In contrast, global liking of own- and other- gender peers was less predictive of outcome expectancies. Thus, the greater specificity of the affective attitude measures appeared to be a more predictive and potentially fruitful gauge of children‚Äôs feelings about own- and other-gender peers. Results are discussed in terms of the need for finer grained and more extensive studies of children‚Äôs gender-related feelings and cognitions about own- and other-gender peers.","tags":null,"title":"‚ÄòIt‚Äôs Not That We Hate You‚Äô: Understanding Children‚Äôs Gender Attitudes and Expectancies About Peer Relationships","type":"publication"},{"authors":["alison","Tedra A. Walden","Wendy L. Stone","Paul J. Yoder"],"categories":null,"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167609600,"objectID":"10ead64306e34e2ab8a84ae656109223","permalink":"https://maggie-98.github.io/publication/2007-rja-in-sibs/","publishdate":"2007-01-01T00:00:00Z","relpermalink":"/publication/2007-rja-in-sibs/","section":"publication","summary":"We compared responding to joint attention (RJA) in younger siblings of children with ASD (SIBS- ASD; n = 46) and younger siblings of children developing typically (SIBS-TD; n = 35). Children were tested between 12 and 23 months of age in a situation in which an experimenter directed the child‚Äôs attention to one of 8 targets. Each child responded to 10 different combinations of verbal and nonverbal cues containing varying levels of attention-specifying information. SIBS-ASD had significantly lower overall RJA scores than SIBS-TD. Moderately redundant cues were most difficult for SIBS-ASD relative to SIBS-TD; adding a point to moderately redundant cues improved RJA for SIBS-ASD, bringing them to a level of RJA commensurate with SIBS-TD.","tags":null,"title":"Effects of Different Attentional Cues on Responding to Joint Attention in Younger Siblings of Children with Autism Spectrum Disorders","type":"publication"},{"authors":["David P. McCabe","alison","Chuck L. Robertson","Anderson D. Smith"],"categories":null,"content":"","date":1101859200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1101859200,"objectID":"50e433a91dedcaad69f93848c53ab186","permalink":"https://maggie-98.github.io/publication/2004-false-memories/","publishdate":"2004-12-01T00:00:00Z","relpermalink":"/publication/2004-false-memories/","section":"publication","summary":"We examined the effect of item-specific and relational encoding instructions on false recognition in two experiments in which the DRM paradigm was used (Deese, 1959; Roediger \u0026 McDermott, 1995). Type of encoding (item-specific or relational) was manipulated between subjects in Experiment 1 and within subjects in Experiment 2. Decision-based explanations (e.g., the distinctiveness heuristic) predict reductions in false recognition in between-subjects designs, but not in within-subjects designs, because they are conceptualized as global shifts in decision criteria. Memory-based explanations predict reductions in false recognition in both designs, resulting from enhanced recollection of item-specific details. False recognition was reduced following item-specific encoding instructions in both experiments, favoring a memory-based explanation. These results suggest that providing unique cues for the retrieval of individual studied items results in enhanced discrimination between those studied items and critical lures. Conversely, enhancing the similarity of studied items results in poor discrimination among items within a particular list theme. These results are discussed in terms of the item-specific/relational framework (Hunt \u0026 McDaniel, 1993).","tags":null,"title":"Item-specific Processing Reduces False Memories","type":"publication"}]